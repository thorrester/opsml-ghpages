{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"A Universal Artifact Registration System for Machine Learning"},{"location":"#what-is-it","title":"What is it?","text":"<p><code>OpsML</code> provides tooling that enables data science and engineering teams to better govern and manage their machine learning projects and artifacts by providing a standardized and universal registration system and repeatable patterns for tracking, versioning and storing ML artifacts.</p>"},{"location":"#why","title":"Why?","text":"<p>The core focus of <code>OpsML</code> is artifact registration, management and governance. After using various open-source and vendor tooling to manage different aspects of the machine learning project lifecycle, we found that we were still spending ample time gluing different tooling together in order to adequately govern, manage and deploy artifacts. Moreover, machine learning currently lacks a universal standard for artifact registration and governance, which makes managing machine learning projects and systems challenging. And given how expansive the machine learning tooling ecosystem is, and how each tool tends to have it's own way of saving, storing and tracking artifacts, we decided to build <code>OpsML</code> with the goal of providing a common framework."},{"location":"#features","title":"Features:","text":"<ul> <li> <p>Simple Design: Standardized design that can easily be incorporated into existing projects.</p> </li> <li> <p>Cards: Track, version and store a variety of ML artifacts via cards (data, models, runs, projects) and a SQL-based card registry system. Think <code>trading cards for machine learning</code>.</p> </li> <li> <p>Type Checking: Strongly typed and type checking for data and model artifacts.</p> </li> <li> <p>Support: Robust support for a variety of ML and data libraries.</p> </li> <li> <p>Automation: Automated processes including onnx model conversion, metadata creation and production packaging.</p> </li> </ul>"},{"location":"#incorporate-into-existing-workflows","title":"Incorporate into Existing Workflows","text":"<p>Add quality control to your ML projects with little effort! With <code>opsml</code>, data and models are represented as <code>cards</code> and stored in a <code>card registry</code>. This allows for easy versioning, tracking and storage of ML artifacts. </p>"},{"location":"#our-goal","title":"Our Goal","text":"<p>Our goal is 2-fold. (1) We want to provide a simple and consistent interface for managing and tracking ML artifacts that is easy for DSs to use and incorporate, and (2) we want to inject quality control by providing standardized interfaces to DSs that automate the creation and governance of ML artifacts for our engineers.</p>"},{"location":"#why-use-opsml-vs-other-open-source-or-vendor-tooling","title":"Why Use OpsML vs other open source or vendor tooling?","text":"<p>With the plethora of available ML tooling it can be difficult to decide which tooling to use. The following are some reasons why you might want to use <code>Opsml</code> and why we created it.</p> <ul> <li>Need for a consistent and standardized ML workflow to use in your organization</li> <li>Not enthusiastic about vendor lock-in or paying a vendor to use an SDK and UI but still need to create and maintain your own infrastructure</li> <li>You want to use a tool that is open source and continually developed</li> <li>You want all artifacts to be given the same priority (no more treating data as less of a priority than models)</li> <li>Don't want to worry about implementation details (how to version, store and track artifacts)</li> <li>You'd like to have auto-generated metadata that meets engineering standards and can be used in production</li> <li>You want to be able to share artifacts and workflows across teams</li> </ul>"},{"location":"#nitty-gritty-details-and-opsml","title":"Nitty Gritty Details and OpsML","text":"<ul> <li>Supports streaming (can use big data and models!) </li> <li>Supports a variety of storage backends (local, gcs, s3) </li> <li>Supports a variety of databases (sqlite, postgres, mysql)</li> <li>Supports many ML and data libraries (sklearn, pytorch, tensorflow, huggingface, xgboost, lightgbm, catboost, polars, pandas, numpy, pyarrow, onnx, etc.)</li> <li>Can create your own interfaces if we're missing anything!</li> <li>Supports semantic versioning for all cards</li> <li>Type checking for all interfaces</li> <li>Strongly typed codebase </li> </ul> <p>To get started using <code>OpsML</code>, check out the installation and quickstart guides.</p>"},{"location":"#supported-libraries","title":"Supported Libraries","text":"<p><code>Opsml</code> is designed to work with a variety of ML and data libraries. The following libraries are currently supported:</p>"},{"location":"#data-libraries","title":"Data Libraries","text":"Name Opsml Implementation Pandas <code>PandasData</code> Polars <code>PolarsData</code> Torch <code>TorchData</code> Arrow <code>ArrowData</code> Numpy <code>NumpyData</code> Sql <code>SqlData</code> Text <code>TextDataset</code> Image <code>ImageDataset</code>"},{"location":"#model-libraries","title":"Model Libraries","text":"Name Opsml Implementation Example Sklearn <code>SklearnModel</code> link LightGBM <code>LightGBMModel</code> link XGBoost <code>XGBoostModel</code> link CatBoost <code>CatBoostModel</code> link Torch <code>TorchModel</code> link Torch Lightning <code>LightningModel</code> link TensorFlow <code>TensorFlowModel</code> link HuggingFace <code>HuggingFaceModel</code> link VowpalWabbit `VowpalWabbitModel`` link"},{"location":"#contributing","title":"Contributing","text":"<p>If you'd like to contribute, be sure to check out our contributing guide! If you'd like to work on any outstanding items, check out the <code>roadmap</code> section in the docs and get started </p> <p>Thanks goes to these phenomenal projects and people and people for creating a great foundation to build from!</p> <p> </p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#poetry","title":"Poetry","text":"<pre><code>poetry add opsml\n</code></pre>"},{"location":"installation/#pip","title":"Pip","text":"<pre><code>pip install opsml\n</code></pre>"},{"location":"installation/#optional-dependencies","title":"Optional Dependencies","text":"<p><code>Opsml</code> is designed to work with a variety of 3rd-party integrations depending on your use-case.</p> <p>Types of extras that can be installed:</p> <ul> <li> <p>Postgres: Installs postgres pyscopg2 dependency to be used with <code>Opsml</code> <pre><code>poetry add \"opsml[postgres]\"\n</code></pre></p> </li> <li> <p>Server: Installs necessary packages for setting up a <code>Fastapi</code> based <code>Opsml</code> server   <pre><code>poetry add \"opsml[server]\"\n</code></pre></p> </li> <li> <p>GCP with mysql: Installs mysql and gcsfs to be used with <code>Opsml</code> <pre><code>poetry add \"opsml[gcs,mysql]\"\n</code></pre></p> </li> <li> <p>GCP with mysql(cloud-sql): Installs mysql and cloud-sql gcp dependencies to be used with <code>Opsml</code> <pre><code>poetry add \"opsml[gcp_mysql]\"\n</code></pre></p> </li> <li> <p>GCP with postgres: Installs postgres and gcsgs to be used with <code>Opsml</code> <pre><code>poetry add \"opsml[gcs,postgres]\"\n</code></pre></p> </li> <li> <p>GCP with postgres(cloud-sql): Installs postgres and cloud-sql gcp dependencies to be used with <code>Opsml</code> <pre><code>poetry add \"opsml[gcp_postgres]\"\n</code></pre></p> </li> <li> <p>AWS with postgres: Installs postgres and s3fs dependencies to be used with <code>Opsml</code> <pre><code>poetry add \"opsml[s3,postgres]\"\n</code></pre></p> </li> <li> <p>AWS with mysql: Installs mysql and s3fs dependencies to be used with <code>Opsml</code> <pre><code>poetry add \"opsml[s3,mysql]\"\n</code></pre></p> </li> </ul>"},{"location":"installation/#example-setup-for-gcs-storage-and-postgres-with-opsml-server","title":"Example setup for gcs storage and postgres with opsml server","text":"<pre><code>  poetry add \"opsml[gcs, postgres, server]\"\n</code></pre>"},{"location":"installation/#environment-variables","title":"Environment Variables","text":"<p><code>Opsml</code> requires 1 or 2 environment variables depending on if you are using it as an all-in-one interface (no proxy) or you are using it as an interface to interact with an <code>Opsml</code> server.</p> <ul> <li> <p>OPSML_TRACKING_URI: This is the sql tracking uri to your card registry database. If interacting with an <code>Opsml</code> server, this will be the http address of the server. If this variable is not set, it will default to a local <code>SQLite</code> connection.</p> </li> <li> <p>OPSML_STORAGE_URI: This is the storage uri to use for storing ml artifacts (models, data, figures, etc.). <code>Opsml</code> currently supports local file system, google cloud storage and amazon s3. If running <code>Opsml</code> as an all-in-one interface, this variable is required and will default to a local folder if not specified. If interacting with an <code>Opsml</code> server, this variable does not need to be set.</p> </li> </ul>"},{"location":"installation/#tldr-scenarios","title":"TLDR Scenarios","text":"<p>Server is already setup and I need to interact with it from the client side (notebook, python script, cli, etc.):</p> <ul> <li>Set <code>OPSML_TRACKING_URI</code> to the http address of the server</li> </ul> <p>I need to setup the Server:</p> <ul> <li>Set <code>OPSML_TRACKING_URI</code> to the sql tracking uri of your card registry database</li> <li>Set <code>OPSML_STORAGE_URI</code> to the storage uri of your choice</li> <li>Follow instructions in server docs</li> </ul>"},{"location":"quickstart/","title":"Quickstart","text":"<p>To get a quick feel for <code>Opsml</code>, run the following code in a new terminal. The following uses Mlflow as a UI interface and local storage and sqlite.</p>"},{"location":"quickstart/#start-local-server","title":"Start Local Server","text":"<pre><code>$ opsml-uvicorn-server\n\n...\n&lt;span style=\"color: green;\"&gt;INFO&lt;/span&gt;:     [INFO] Started server process\n&lt;span style=\"color: green;\"&gt;INFO&lt;/span&gt;:     [INFO] Waiting for application startup\n\n...\n&lt;span style=\"color: green;\"&gt;INFO&lt;/span&gt;:     [INFO] Application startup complete\n&lt;span style=\"color: green;\"&gt;INFO&lt;/span&gt;:     [INFO] Uvicorn running on http://0.0.0.0:8888\n</code></pre> <p>Next, open a new terminal and run the following python script. Make sure to set the <code>OPSML_TRACKING_URI</code> which tells <code>opsml</code> where to log experiments.</p>"},{"location":"quickstart/#run-initial-python-script","title":"Run Initial Python Script","text":"<pre><code>export OPSML_TRACKING_URI=${YOUR_TRACKING_URI}\n</code></pre> <pre><code># imports\nfrom sklearn.linear_model import LinearRegression\nfrom opsml import (\n    CardInfo,\n    CardRegistries,\n    DataCard,\n    DataSplit,\n    ModelCard,\n    PandasData,\n    SklearnModel,\n)\nfrom opsml.helpers.data import create_fake_data\n\n\ninfo = CardInfo(name=\"linear-regression\", repository=\"opsml\", user_email=\"user@email.com\")\nregistries = CardRegistries()\n\n\n#--------- Create DataCard ---------#\n\n# create fake data\nX, y = create_fake_data(n_samples=1000, task_type=\"regression\")\nX[\"target\"] = y\n\n# Create data interface\ndata_interface = PandasData(\n    data=X,\n    data_splits=[\n        DataSplit(label=\"train\", column_name=\"col_1\", column_value=0.5, inequality=\"&gt;=\"),\n        DataSplit(label=\"test\", column_name=\"col_1\", column_value=0.5, inequality=\"&lt;\"),\n    ],\n    dependent_vars=[\"target\"],\n)\n\n# Create and register datacard\ndatacard = DataCard(interface=data_interface, info=info)\nregistries.data.register_card(card=datacard)\n\n#--------- Create ModelCard ---------#\n\n# split data\ndata = datacard.split_data()\n\n# fit model\nreg = LinearRegression()\nreg.fit(data[\"train\"].X.to_numpy(), data[\"train\"].y.to_numpy())\n\n# create model interface\ninterface = SklearnModel(\n    model=reg,\n    sample_data=data[\"train\"].X.to_numpy(),\n    task_type=\"regression\",  # optional\n)\n\n# create modelcard\nmodelcard = ModelCard(\n    interface=interface,\n    info=info,\n    to_onnx=True,  # lets convert onnx\n    datacard_uid=datacard.uid,  # modelcards must be associated with a datacard\n)\nregistries.model.register_card(card=modelcard)\n</code></pre>"},{"location":"quickstart/#opsml-ui","title":"Opsml UI","text":"<p>Next, navigate to <code>OPSML_TRACKING_URI</code> and you should see the following:</p> <p> </p> <p>Click on the <code>linear-regression</code> card and you should see the following:</p> <p> </p> <p>Click on the <code>DataCard</code> button and you should see the following:</p> <p> </p>"},{"location":"quickstart/#download-your-model-via-cli","title":"Download your model via CLI","text":"<p>Try downloading your model via the CLI:</p> <p><pre><code>opsml-cli download-model --name 'linear-regression' --version '1.0.0'\n</code></pre> Here we are downloading the model with name <code>linear-regression</code> and version <code>1.0.0</code>. You could also provide the <code>uid</code> of the model instead of the name and version. By default, the cli command will download objects to the <code>models</code> directory. You will see both the model <code>joblib</code> file as well as the model's associated <code>metadata</code>. If you'd wish to download the <code>onnx</code> version of the model, you can add the <code>--onnx</code> flag to the command.</p> <pre><code>opsml-cli download-model --name 'linear-regression' --version '1.0.0' --onnx\n</code></pre>"},{"location":"cards/auditcard/","title":"AuditCard","text":"<p><code>AuditCards</code> serve a special purpose in <code>OpsML</code> and can be viewed as a card that contains governance, compliance, and ethical information about a particular model and its associated assets. Importantly, information contained in an <code>AuditCard</code> can be used be governing bodies and stakeholders to assess and approve a model for production.</p> <p><code>AuditCards</code> are created by instantiating the <code>AuditCard</code> class and passing in the required arguments. When working in python, you can list and answer questions as part of your normal workflow. However, the easiest and most intuitive way to create and update <code>AuditCards</code> is through the <code>OpsML</code> UI (Audit tab). </p>"},{"location":"cards/auditcard/#auditcard-audit-sections","title":"AuditCard Audit Sections","text":""},{"location":"cards/auditcard/#business","title":"Business","text":"In the Business Understanding section, various important aspects are addressed to clarify the purpose and objectives of an AI application. These questions help provide a comprehensive understanding of the business context: <ol> <li> <p>Business Objectives: The product owner's goals and intentions are identified. This helps in understanding what they aim to achieve with the AI application.</p> </li> <li> <p>Business Requirements: The specific requirements set by the product owner for the application are outlined. This includes factors like development costs, operational costs, staffing needs, and anticipated savings.</p> </li> <li> <p>KPIs (Key Performance Indicators): The KPIs that the product owner intends to improve with the application are determined. This includes the rationale behind selecting specific KPIs and how they will be measured.</p> </li> <li> <p>Business Processes: The impact of the application on various business processes is assessed. This involves understanding the criticality of affected processes, their relationships, and the significance of the application within these processes.</p> </li> <li> <p>Driver for Application Introduction: The underlying reasons that drove the decision to develop the application are identified. This can include factors like regulatory mandates, cost considerations, or the need to address new challenges.</p> </li> <li> <p>Framework Conditions: The readiness of the product owner to efficiently operate the system is evaluated. This includes factors such as staffing, infrastructure, user support, and quality assurance.</p> </li> <li> <p>Monetary Benefits: The financial benefits and cost-savings expected from using the application are examined to determine their reasonableness and feasibility.</p> </li> <li> <p>Qualifiable and Strategic Benefits: Any non-financial benefits derived from the application, such as improved processes or strategic advantages, are documented, along with their measurement capabilities.</p> </li> <li> <p>Value for Money: The evaluation of the system's cost-effectiveness and efficiency is checked to ensure compliance with recognized methods and requirements.</p> </li> <li> <p>Risk Analysis: The risks associated with the application, data preparation, and the processes it encompasses are analyzed. This includes identifying which risks to mitigate and which ones to accept, and assessing whether the benefits outweigh the risks and align with regulations.</p> </li> </ol> <p>These questions help stakeholders gain a clear understanding of the business context, goals, and risks associated with the AI application, facilitating better decision-making and project management.</p>"},{"location":"cards/auditcard/#data-understanding","title":"Data Understanding","text":"In the Data Understanding section, we delve into various aspects of data that are essential for the successful operation of the application. Here are concise descriptions of the key questions and their purposes: <ol> <li> <p>Data Processed by the Application: This question seeks to understand the types of data that the application works with, encompassing both the data it receives as input and the data it generates as output. It's about identifying the information the application handles.</p> </li> <li> <p>Data Sources: To gain insights into the reliability and relevance of data, it's important to identify the approved data sources, their freshness, reliability, and whether they are mandated to provide information.</p> </li> <li> <p>Technical/Operational Criteria for Data Selection: Understanding the rationale behind data selection, including why specific data sources were chosen and any alternative sources considered, helps in assessing the foundation of the application's data.</p> </li> <li> <p>Data Quality Assessment: To ensure data reliability, it's crucial to identify who assesses data quality, whether it's an ongoing process, the key aspects evaluated, the review process, and the defined quality criteria.</p> </li> <li> <p>Required Data Quality: Determining the level of data quality necessary for the application to meet its objectives and requirements helps align expectations and performance.</p> </li> <li> <p>Data Quality Thresholds: This question focuses on whether threshold values have been set for data quality and the reasons for choosing them, along with what actions are taken when data quality falls below or exceeds these thresholds.</p> </li> <li> <p>Documentation of Data Model Semantic: This question focuses on whether the meaning and structure of data have been clearly defined in the data model. This includes checking if the repository has established the interpretation of data, including any abbreviations or codes used, ensuring consistency and understanding in data usage.</p> </li> <li> <p>Data Subject to Security Requirements: This helps identify whether the application handles data subject to security regulations like FTC and the rationale behind using such data.</p> </li> <li> <p>Data Security Measures: To protect data, understanding the technical, organizational, and other security measures put in place by the product owner or developer is essential.</p> </li> </ol> <p>These questions assist in comprehensively assessing the data-related aspects of the application, ensuring data quality, security, and compliance with relevant regulations.</p>"},{"location":"cards/auditcard/#data-preparation","title":"Data Preparation","text":"In the Data Preparation section, the focus is on the process of getting the data ready for use in the application. Here are concise descriptions of the key questions and their purposes: <ol> <li> <p>Shortcomings in Data Quality: Identify and document any shortcomings in the quality of input data, including missing values, errors, inaccuracies, outdated information, and inconsistencies.</p> </li> <li> <p>Modification of Input Datasets: Understand the steps taken by the product owner, developer, or operator to address data quality issues, including whether modifications are made manually or automatically.</p> </li> <li> <p>Reporting Data Errors: Determine if data errors are reported to data suppliers and whether missing entries are replaced or ignored. Documenting data weaknesses for future benchmarking is also important.</p> </li> <li> <p>Documentation of Data Preparation: Learn how the data preparation process is documented and tracked during the operation of the application.</p> </li> <li> <p>Enhancement of Dataset Quality: Understand how data preparation improves dataset quality and how this impact is measured, including the criteria for benchmarking unprocessed and pre-processed data.</p> </li> <li> <p>Impact on Application Results: Assess whether the quality of data preparation affects the operation and results of the application, and how the application responds to differently cleansed data.</p> </li> <li> <p>Mapping Data Preparation in the Application: Learn how data preparation has been integrated into the development, testing, validation, and operation processes of the application.</p> </li> <li> <p>Monitoring Data Preparation Quality: Understand the quality assurance mechanisms in place for data preparation, including how quality assurance works, when it starts, and how its work is documented.</p> </li> <li> <p>Addressing Risks: Identify and address any risks associated with data preparation, as well as any risks related to the application and development environment that data preparation may mitigate.</p> </li> <li> <p>Data Management Framework: Learn about the framework conditions and responsibilities governing data management for the application, including applicable frameworks and structures.</p> </li> <li> <p>Data Management System: Understand the data management system used, such as SQL databases, NoSQL databases, data warehouses, or flat files, and how data is stored and maintained.</p> </li> </ol> <p>These questions are essential for ensuring that data used by the application is of high quality and that the data preparation process is well-documented and effective in enhancing data quality. They also address risk management and data management structures.</p>"},{"location":"cards/auditcard/#modeling","title":"Modeling","text":"In the Modeling section, the focus is on the data analysis methods and datasets used for training, validation, and testing in the application. Here are concise descriptions of the key questions and their purposes: <ol> <li> <p>Data Analysis Methods: Identify the data analysis methods used in the modeling process and the criteria for their selection. These methods can include frequent pattern mining, classification, cluster analysis, and outlier detection.</p> </li> <li> <p>Training Datasets: Gather information about the training datasets, including their scope, contents, and quality. Understanding the data used for model training is essential.</p> </li> <li> <p>Selection or Generation of Training Datasets: Learn how the training datasets were selected or generated and any tools or programs used in the process. Identify potential errors in the training data.</p> </li> <li> <p>Updating Training Datasets: Determine how the training datasets are updated during the system's life cycle, whether the model remains stable or is continuously refined with additional data, and the quality assurance processes in place.</p> </li> <li> <p>Validation Datasets: Collect information about the validation datasets, including scope, contents, and quality, to ensure the model's accuracy.</p> </li> <li> <p>Selection or Generation of Validation Datasets: Understand how validation datasets were selected or generated and the tools or programs used. Highlight potential errors in validation data.</p> </li> <li> <p>Updating Validation Datasets: Explore how validation datasets are updated during the system's life cycle, whether the model remains stable, and the quality assurance of the validation process.</p> </li> <li> <p>Test Datasets: Gather details about the test datasets, including scope, contents, and quality. This is essential for verifying model performance.</p> </li> <li> <p>Selection or Generation of Test Datasets: Learn about the process of selecting or generating test data and any tools or programs used. Identify potential errors in test data.</p> </li> <li> <p>Updating Test Datasets: Understand how test datasets are updated during the system's life cycle, whether the model remains stable, and the quality assurance of the testing process.</p> </li> <li> <p>Tracking Modeling and Testing: Collect information on how modeling, model validation, and model testing are documented, ensuring transparency in the process.</p> </li> <li> <p>Addressing Risks: Identify how the modeling process addresses any risks detected in the application, including the type of risk analysis conducted for modeling and related factors impacting the modeling process.</p> </li> </ol> <p>These questions help ensure that the modeling process is well-documented, and that the data used for training, validation, and testing is of high quality, aligning with the objectives of the application. Additionally, it addresses the proactive management of risks in the modeling process.</p>"},{"location":"cards/auditcard/#evaluation","title":"Evaluation","text":"In the Evaluation section, the focus is on assessing the performance and effectiveness of the model in the application. Here are concise descriptions of the key questions and their purposes: <ol> <li> <p>Validation Methods and Selection Criteria: Identify the validation methods used and the criteria for their selection. Understand how the model's quality has been reviewed, how decisions/forecasts have been tracked, and how the impact of individual criteria on decisions has been analyzed. Assess model fairness.</p> </li> <li> <p>Results of Model Validation and Evaluation: Gather information on the results of model validation, how they were documented and interpreted, and the traceability of the model's response. Evaluate the extent to which the model is sufficiently accurate and how potentially contradictory statements have been assessed. Consider the empirical data used for interpreting results, who reviewed the validation results, and how these results will be used for future validation exercises.</p> </li> <li> <p>Benchmarking Model Performance: Determine whether the model's performance has been benchmarked against alternative methods or models for data analysis. Understand the parameters used for benchmarking and the implications for model evaluation.</p> </li> <li> <p>Handling Faulty or Manipulated Datasets: Learn about the application's response to faulty or manipulated datasets at various stages, including training, validation, testing, and operational stages. Understand the results of exposing the model to such data.</p> </li> <li> <p>Accomplishing Objectives and Intended Purposes: Assess whether the initial objectives and impacts set by the product owner have been achieved. Understand how this achievement has been measured and whether additional objectives and impacts have been realized.</p> </li> </ol> <p>These questions are essential for evaluating the performance and effectiveness of the model, ensuring that it aligns with its intended purposes and objectives, and addressing potential risks and shortcomings in the modeling process.</p>"},{"location":"cards/auditcard/#deployment","title":"Deployment","text":"In the Deployment &amp; Monitoring section, the focus is on the deployment and ongoing monitoring of the application, including its integration into the system architecture and processes. Here are concise descriptions of the key questions and their purposes: <ol> <li> <p>Model Update Intervals: Determine at what intervals the model is updated to reflect current training data and whether the model is static or dynamic.</p> </li> <li> <p>Application Integration in System Architecture: Learn how the application is embedded in the surrounding system architecture, including system design, interfaces with other components, and dependencies on these components and their changes.</p> </li> <li> <p>Application Integration in Process Landscape: Understand how and when the application is integrated into the product owner's process landscape, considering incidents and framework conditions, and whether the conditions are consistent or vary.</p> </li> <li> <p>Human-Machine Interaction Features: Identify the major features of human-machine interaction in the application, including user influence, information communication, and the application's autonomy.</p> </li> <li> <p>Providing KPIs to Decision-Makers: Understand how key performance indicators (KPIs) of the application's decisions are provided to decision-makers, including the communication of decision quality or uncertainty.</p> </li> <li> <p>Application Performance Monitoring: Learn how and how often the performance of the application is monitored or reviewed during operation.</p> </li> <li> <p>Intervention Processes for Faulty Performance: Explore alternative intervention processes in case of faulty or poor system performance, considering dependencies on the application in business processes.</p> </li> <li> <p>User Qualifications: Understand the qualifications users of the application need, including their knowledge about the application's impact.</p> </li> <li> <p>User Overruling of Decisions: Determine how users can overrule decisions or proposals made by the application, and assess the level of autonomy granted to the application.</p> </li> <li> <p>Criteria for Application Decisions: Identify the criteria governing decisions or proposals submitted to the user and distinguish between those that are submitted and those that are not.</p> </li> <li> <p>Compliance with Laws and Regulations: Understand the extent to which the application complies with applicable laws and regulations and obtain assessments from various parties involved.</p> </li> <li> <p>Ethical Concerns: Explore any ethical concerns related to the use of the application, beyond statutory aspects.</p> </li> <li> <p>Understanding and Tracking Decisions: Assess the extent to which users can understand and track the decisions or proposals made by the application.</p> </li> <li> <p>Understanding How the Application Works: Determine if users have knowledge about the internal processes underlying the application.</p> </li> <li> <p>Protection from Misuse: Identify the steps taken to protect the application from potential misuse.</p> </li> <li> <p>Exploration of Misuse Types: Understand what types of misuse possibilities have been analyzed, and whether knowledge is limited to theoretical ideas.</p> </li> <li> <p>Exploration of Attacks: Learn if types of attacks on the application and embedded processes have been explored and addressed during the planning stage.</p> </li> <li> <p>Residual Risks: Understand the residual risks that still persist and require attention, and specify criteria for assessing their tolerability.</p> </li> <li> <p>Factors Impacting Reliability (System): Explore factors that impact the reliability of the overall system in which the application is embedded, and how these factors affect the application.</p> </li> <li> <p>Factors Impacting Reliability (Decisions/Proposals): Understand additional variables that may impact the reliability of the application's decisions, beyond the application's framework conditions.</p> </li> <li> <p>Avoiding Unequal Treatment: Determine the extent to which any unequal treatment of individuals, facts, or matters arising from using the application can be ruled out and how incidents are verified.</p> </li> <li> <p>Sustainability Considerations: Explore whether sustainability considerations, such as energy efficiency, have been taken into account in operating the AI components.</p> </li> </ol> <p>These questions are essential for ensuring the successful deployment and ongoing monitoring of the application, addressing issues related to ethics, compliance, misuse, and reliability, and considering sustainability aspects.</p>"},{"location":"cards/auditcard/#misc","title":"Misc","text":"In this section, various miscellaneous topics related to the AI project are addressed. Each topic provides insights into different aspects of the project's management and development: <ol> <li> <p>Demand and Change Management: Understand how demand and change management for developing the application/system have been designed, including the tools used, and the involvement of the product owner in managing changes and requirements.</p> </li> <li> <p>Software Development: Learn how software development is structured, including the tools, libraries, and methodologies used in the development process.</p> </li> <li> <p>Quality Assurance: Understand the structure of quality assurance, including the testing and acceptance processes, as well as how developer tests are designed to ensure the quality of the application.</p> </li> <li> <p>Project Management: Gain insights into the structure of project management, including the approaches and methods chosen for managing the AI project.</p> </li> <li> <p>Rollout: Understand how the application/system rollout is structured, whether it involves pilot users, a gradual rollout, or a big-bang approach, and what framework conditions are in place or still needed.</p> </li> <li> <p>Acceptance Management: Learn how staff, clients, and other stakeholders have been prepared for the application/system rollout and how their understanding and readiness for change have been promoted.</p> </li> <li> <p>Incident Management: Understand the procedures in place for users and operational units to report malfunctions and incidents to ensure prompt resolution.</p> </li> <li> <p>Change Management (Staff, Organization): Understand the changes in practices, procedures, human resources, and financial management associated with the rollout and how the organization and its staff have been prepared to adapt to these changes.</p> </li> </ol> <p>These miscellaneous topics cover important aspects of the AI project's management, development, quality assurance, and change management, ensuring a comprehensive understanding of the project's structure and processes.</p>"},{"location":"cards/auditcard/#audit-ui","title":"Audit UI","text":"<p>The recommended way to interact with <code>AuditCards</code> is through the UI.</p>"},{"location":"cards/auditcard/#find-your-model","title":"Find your model","text":"<p>Navigate to the model tab and find your specific model and version.</p> <p> </p>"},{"location":"cards/auditcard/#click-the-audit-link-and-fill-out-the-audit-form","title":"Click the Audit link and fill out the audit form","text":"<p>You can also upload and existing audit csv, download the current audit as a csv, and add comments via the comment button.</p> <p> </p>"},{"location":"cards/auditcard/#code-example","title":"Code Example","text":"<pre><code>from opsml import AuditCard, CardRegistry\n\n... # create model and data cards\n\nauditcard = AuditCard(\n    name=\"linear-regressor-audit\",\n    repository=\"my_repository\", \n    contact=\"contact\"\n)\n\n# add modelcard to auditcard\nauditcard.add_card(modelcard)\n\n\n# list questions\nauditcard.list_questions()\n\n# list by section\ncard.list_questions(section=\"business\")\n\n# answer question\ncard.answer_question(section=\"business\", question_nbr=1, response=\"response\")\n\n# register\naudit_registry = CardRegistry(\"audit\")\naudit_registry.register_card(auditcard)\n</code></pre>"},{"location":"cards/challenger/","title":"Challenger","text":"<p>One of the benefits to linking and tracking <code>ModelCards</code> along with various <code>Runcard</code> metrics is that it's relatively easy to compare different model versions via the <code>ModelChallenger</code> class.</p>"},{"location":"cards/challenger/#examples","title":"Examples","text":"<p>For examples please refer to <code>examples/challenger</code> for examples on how to compare registered model and un-registered models.</p>"},{"location":"cards/challenger/#docs","title":"Docs","text":""},{"location":"cards/challenger/#opsml.model.challenger.ModelChallenger","title":"<code>opsml.model.challenger.ModelChallenger</code>","text":"Source code in <code>opsml/model/challenger.py</code> <pre><code>class ModelChallenger:\n    def __init__(self, challenger: ModelCard):\n        \"\"\"\n        Instantiates ModelChallenger class\n\n        Args:\n            challenger:\n                ModelCard of challenger\n\n        \"\"\"\n        self._challenger = challenger\n        self._challenger_metric: Optional[Metric] = None\n        self._registries = CardRegistries()\n\n    @property\n    def challenger_metric(self) -&gt; Metric:\n        if self._challenger_metric is not None:\n            return self._challenger_metric\n        raise ValueError(\"Challenger metric not set\")\n\n    @challenger_metric.setter\n    def challenger_metric(self, metric: Metric) -&gt; None:\n        self._challenger_metric = metric\n\n    def _get_last_champion_record(self) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Gets the previous champion record\"\"\"\n\n        champion_records = self._registries.model.list_cards(\n            name=self._challenger.name,\n            repository=self._challenger.repository,\n        )\n\n        if not bool(champion_records):\n            return None\n\n        # indicates challenger has been registered\n        if self._challenger.version is not None and len(champion_records) &gt; 1:\n            return champion_records[1]\n\n        # account for cases where challenger is only model in registry\n        champion_record = champion_records[0]\n        if champion_record.get(\"version\") == self._challenger.version:\n            return None\n\n        return champion_record\n\n    def _get_runcard_metric(self, runcard_uid: str, metric_name: str) -&gt; Metric:\n        \"\"\"\n        Loads a RunCard from uid\n\n        Args:\n            runcard_uid:\n                RunCard uid\n            metric_name:\n                Name of metric\n\n        \"\"\"\n        runcard = cast(RunCard, self._registries.run.load_card(uid=runcard_uid))\n        metric = runcard.get_metric(name=metric_name)\n\n        if isinstance(metric, list):\n            metric = metric[0]\n\n        return metric\n\n    def _battle(self, champion: CardInfo, champion_metric: Metric, lower_is_better: bool) -&gt; BattleReport:\n        \"\"\"\n        Runs a battle between champion and current challenger\n\n        Args:\n            champion:\n                Champion record\n            champion_metric:\n                Champion metric from a runcard\n            lower_is_better:\n                Whether lower metric is preferred\n\n        Returns:\n            `BattleReport`\n\n        \"\"\"\n        if lower_is_better:\n            challenger_win = self.challenger_metric.value &lt; champion_metric.value\n        else:\n            challenger_win = self.challenger_metric.value &gt; champion_metric.value\n        return BattleReport.model_construct(\n            champion_name=str(champion.name),\n            champion_version=str(champion.version),\n            champion_metric=champion_metric,\n            challenger_metric=self.challenger_metric.model_copy(deep=True),\n            challenger_win=challenger_win,\n        )\n\n    def _battle_last_model_version(self, metric_name: str, lower_is_better: bool) -&gt; BattleReport:\n        \"\"\"Compares the last champion model to the current challenger\"\"\"\n\n        champion_record = self._get_last_champion_record()\n\n        if champion_record is None:\n            logger.info(\"No previous model found. Challenger wins\")\n\n            return BattleReport(\n                champion_name=\"No model\",\n                champion_version=\"No version\",\n                challenger_win=True,\n            )\n\n        runcard_id = champion_record.get(\"runcard_uid\")\n        if runcard_id is None:\n            raise ValueError(f\"No RunCard is associated with champion: {champion_record}\")\n\n        champion_metric = self._get_runcard_metric(runcard_uid=runcard_id, metric_name=metric_name)\n\n        return self._battle(\n            champion=CardInfo(\n                name=champion_record.get(\"name\"),\n                version=champion_record.get(\"version\"),\n            ),\n            champion_metric=champion_metric,\n            lower_is_better=lower_is_better,\n        )\n\n    def _battle_champions(\n        self,\n        champions: List[CardInfo],\n        metric_name: str,\n        lower_is_better: bool,\n    ) -&gt; List[BattleReport]:\n        \"\"\"Loops through and creates a `BattleReport` for each champion\"\"\"\n        battle_reports = []\n\n        for champion in champions:\n            champion_record = self._registries.model.list_cards(\n                info=champion,\n            )\n\n            if not bool(champion_record):\n                raise ValueError(f\"Champion model does not exist. {champion}\")\n\n            champion_card = champion_record[0]\n            runcard_uid = champion_card.get(\"runcard_uid\")\n            if runcard_uid is None:\n                raise ValueError(f\"No RunCard associated with champion: {champion}\")\n\n            champion_metric = self._get_runcard_metric(\n                runcard_uid=runcard_uid,\n                metric_name=metric_name,\n            )\n\n            # update name, repository and version in case of None\n            champion.name = champion.name or champion_card.get(\"name\")\n            champion.repository = champion.repository or champion_card.get(\"repository\")\n            champion.version = champion.version or champion_card.get(\"version\")\n\n            battle_reports.append(\n                self._battle(\n                    champion=champion,\n                    champion_metric=champion_metric,\n                    lower_is_better=lower_is_better,\n                )\n            )\n        return battle_reports\n\n    def challenge_champion(\n        self,\n        metric_name: MetricName,\n        metric_value: Optional[MetricValue] = None,\n        champions: Optional[List[CardInfo]] = None,\n        lower_is_better: Union[bool, List[bool]] = True,\n    ) -&gt; Dict[str, List[BattleReport]]:\n        \"\"\"\n        Challenges n champion models against the challenger model. If no champion is provided,\n        the latest model version is used as a champion.\n\n        Args:\n            champions:\n                Optional list of champion CardInfo\n            metric_name:\n                Name of metric to evaluate\n            metric_value:\n                Challenger metric value\n            lower_is_better:\n                Whether a lower metric value is better or not\n\n        Returns\n            `BattleReport`\n        \"\"\"\n\n        # validate inputs\n        inputs = ChallengeInputs(\n            metric_name=metric_name,\n            metric_value=metric_value,\n            lower_is_better=lower_is_better,\n        )\n\n        report_dict = {}\n\n        for name, value, _lower_is_better in zip(\n            inputs.metric_names,\n            inputs.metric_values,\n            inputs.thresholds,\n        ):\n            # get challenger metric\n            if value is None:\n                if self._challenger.metadata.runcard_uid is not None:\n                    self.challenger_metric = self._get_runcard_metric(\n                        self._challenger.metadata.runcard_uid, metric_name=name\n                    )\n                else:\n                    raise ValueError(\"Challenger and champions must be associated with a registered RunCard\")\n            else:\n                self.challenger_metric = Metric(name=name, value=value)\n\n            if champions is None:\n                report_dict[name] = [\n                    self._battle_last_model_version(\n                        metric_name=name,\n                        lower_is_better=_lower_is_better,\n                    )\n                ]\n\n            else:\n                report_dict[name] = self._battle_champions(\n                    champions=champions,\n                    metric_name=name,\n                    lower_is_better=_lower_is_better,\n                )\n\n        return report_dict\n</code></pre>"},{"location":"cards/challenger/#opsml.model.challenger.ModelChallenger.__init__","title":"<code>__init__(challenger)</code>","text":"<p>Instantiates ModelChallenger class</p> <p>Parameters:</p> Name Type Description Default <code>challenger</code> <code>ModelCard</code> <p>ModelCard of challenger</p> required Source code in <code>opsml/model/challenger.py</code> <pre><code>def __init__(self, challenger: ModelCard):\n    \"\"\"\n    Instantiates ModelChallenger class\n\n    Args:\n        challenger:\n            ModelCard of challenger\n\n    \"\"\"\n    self._challenger = challenger\n    self._challenger_metric: Optional[Metric] = None\n    self._registries = CardRegistries()\n</code></pre>"},{"location":"cards/challenger/#opsml.model.challenger.ModelChallenger.challenge_champion","title":"<code>challenge_champion(metric_name, metric_value=None, champions=None, lower_is_better=True)</code>","text":"<p>Challenges n champion models against the challenger model. If no champion is provided, the latest model version is used as a champion.</p> <p>Parameters:</p> Name Type Description Default <code>champions</code> <code>Optional[List[CardInfo]]</code> <p>Optional list of champion CardInfo</p> <code>None</code> <code>metric_name</code> <code>MetricName</code> <p>Name of metric to evaluate</p> required <code>metric_value</code> <code>Optional[MetricValue]</code> <p>Challenger metric value</p> <code>None</code> <code>lower_is_better</code> <code>Union[bool, List[bool]]</code> <p>Whether a lower metric value is better or not</p> <code>True</code> <p>Returns     <code>BattleReport</code></p> Source code in <code>opsml/model/challenger.py</code> <pre><code>def challenge_champion(\n    self,\n    metric_name: MetricName,\n    metric_value: Optional[MetricValue] = None,\n    champions: Optional[List[CardInfo]] = None,\n    lower_is_better: Union[bool, List[bool]] = True,\n) -&gt; Dict[str, List[BattleReport]]:\n    \"\"\"\n    Challenges n champion models against the challenger model. If no champion is provided,\n    the latest model version is used as a champion.\n\n    Args:\n        champions:\n            Optional list of champion CardInfo\n        metric_name:\n            Name of metric to evaluate\n        metric_value:\n            Challenger metric value\n        lower_is_better:\n            Whether a lower metric value is better or not\n\n    Returns\n        `BattleReport`\n    \"\"\"\n\n    # validate inputs\n    inputs = ChallengeInputs(\n        metric_name=metric_name,\n        metric_value=metric_value,\n        lower_is_better=lower_is_better,\n    )\n\n    report_dict = {}\n\n    for name, value, _lower_is_better in zip(\n        inputs.metric_names,\n        inputs.metric_values,\n        inputs.thresholds,\n    ):\n        # get challenger metric\n        if value is None:\n            if self._challenger.metadata.runcard_uid is not None:\n                self.challenger_metric = self._get_runcard_metric(\n                    self._challenger.metadata.runcard_uid, metric_name=name\n                )\n            else:\n                raise ValueError(\"Challenger and champions must be associated with a registered RunCard\")\n        else:\n            self.challenger_metric = Metric(name=name, value=value)\n\n        if champions is None:\n            report_dict[name] = [\n                self._battle_last_model_version(\n                    metric_name=name,\n                    lower_is_better=_lower_is_better,\n                )\n            ]\n\n        else:\n            report_dict[name] = self._battle_champions(\n                champions=champions,\n                metric_name=name,\n                lower_is_better=_lower_is_better,\n            )\n\n    return report_dict\n</code></pre>"},{"location":"cards/datacard/","title":"Overview","text":"<p>DataCards are used for storing, versioning, and tracking data. All DataCards require a <code>DataInterface</code> and optional metadata. See DataInterface for more information</p>"},{"location":"cards/datacard/#creating-a-card","title":"Creating a Card","text":"<pre><code># Data\nfrom sklearn.datasets import load_linnerud\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# Opsml\nfrom opsml import CardInfo, DataCard, CardRegistry, DataSplit, PandasData\n\ncard_info = CardInfo(name=\"linnerrud\", repository=\"opsml\", contact=\"user@email.com\")\ndata, target = load_linnerud(return_X_y=True, as_frame=True)\ndata[\"Pulse\"] = target.Pulse\n\n# Split indices\nindices = np.arange(data.shape[0])\n\n# usual train-val split\ntrain_idx, test_idx = train_test_split(indices, test_size=0.2, train_size=None)\n\ndata_interface = PandasData(\n    data=data,\n    dependent_vars=[\"Pulse\"],\n    # define splits\n    data_splits=[\n        DataSplit(label=\"train\", indices=train_idx),\n        DataSplit(label=\"test\", indices=test_idx),\n    ],\n)\n\ndata_card = DataCard(info=card_info, interface=data_interface)\n\n# splits look good\nsplits = data_card.split_data()\nprint(splits[\"train\"].X.head())\n\n\"\"\"   \n    Chins  Situps  Jumps\n0    5.0   162.0   60.0\n1    2.0   110.0   60.0\n2   12.0   101.0  101.0\n3   12.0   105.0   37.0\n4   13.0   155.0   58.0\n\"\"\"\n\ndata_registry = CardRegistry(registry_name=\"data\")\ndata_registry.register_card(card=data_card)\nprint(data_card.version)\n# &gt; 1.0.0\n</code></pre>"},{"location":"cards/datacard/#datacard-args","title":"DataCard Args","text":"<code>name</code>: <code>str</code> Name for the data (Required) <code>repository</code>: <code>str</code> repository data belongs to (Required) <code>contact</code>: <code>str</code> Email to associate with data (Required) <code>interface</code>: <code>DataInterface</code> DataInterface used to interact with data. See DataInterface for more information <code>metadata</code>: <code>DataCardMetadata</code> Optional DataCardMetadata used to store metadata about data. See DataCardMetadata for more information. If not provided, a default object is created. When registering a card, the metadata is updated with the latest information."},{"location":"cards/datacard/#docs","title":"Docs","text":""},{"location":"cards/datacard/#opsml.DataCard","title":"<code>opsml.DataCard</code>","text":"<p>             Bases: <code>ArtifactCard</code></p> <p>Create a DataCard from your data.</p> <p>Parameters:</p> Name Type Description Default <code>interface</code> <p>Instance of <code>DataInterface</code> that contains data</p> required <code>name</code> <p>What to name the data</p> required <code>repository</code> <p>Repository that this data is associated with</p> required <code>contact</code> <p>Contact to associate with data card</p> required <code>info</code> <p><code>CardInfo</code> object containing additional metadata. If provided, it will override any values provided for <code>name</code>, <code>repository</code>, <code>contact</code>, and <code>version</code>.</p> <p>Name, repository, and contact are required arguments for all cards. They can be provided directly or through a <code>CardInfo</code> object.</p> required <code>version</code> <p>DataCard version</p> required <code>uid</code> <p>Unique id assigned to the DataCard</p> required <p>Returns:</p> Type Description <p>DataCard</p> Source code in <code>opsml/cards/data.py</code> <pre><code>class DataCard(ArtifactCard):\n    \"\"\"Create a DataCard from your data.\n\n    Args:\n        interface:\n            Instance of `DataInterface` that contains data\n        name:\n            What to name the data\n        repository:\n            Repository that this data is associated with\n        contact:\n            Contact to associate with data card\n        info:\n            `CardInfo` object containing additional metadata. If provided, it will override any\n            values provided for `name`, `repository`, `contact`, and `version`.\n\n            Name, repository, and contact are required arguments for all cards. They can be provided\n            directly or through a `CardInfo` object.\n\n        version:\n            DataCard version\n        uid:\n            Unique id assigned to the DataCard\n\n    Returns:\n        DataCard\n\n    \"\"\"\n\n    interface: SerializeAsAny[Union[DataInterface, Dataset]]\n    metadata: DataCardMetadata = DataCardMetadata()\n\n    def load_data(self, **kwargs: Union[str, int]) -&gt; None:  # pylint: disable=differing-param-doc\n        \"\"\"\n        Load data to interface\n\n        Args:\n            kwargs:\n                Keyword arguments to pass to the data loader\n\n            ---- Supported kwargs for ImageData and TextDataset ----\n\n            split:\n                Split to use for data. If not provided, then all data will be loaded.\n                Only used for subclasses of `Dataset`.\n\n            batch_size:\n                What batch size to use when loading data. Only used for subclasses of `Dataset`.\n                Defaults to 1000.\n\n            chunk_size:\n                How many files per batch to use when writing arrow back to local file.\n                Defaults to 1000.\n\n                Example:\n\n                    - If batch_size=1000 and chunk_size=100, then the loaded batch will be split into\n                    10 chunks to write in parallel. This is useful for large datasets.\n\n        \"\"\"\n        from opsml.storage.card_loader import DataCardLoader\n\n        DataCardLoader(self).load_data(**kwargs)\n\n    def load_data_profile(self) -&gt; None:\n        \"\"\"\n        Load data to interface\n        \"\"\"\n        from opsml.storage.card_loader import DataCardLoader\n\n        DataCardLoader(self).load_data_profile()\n\n    def create_registry_record(self) -&gt; Dict[str, Any]:\n        \"\"\"\n        Creates required metadata for registering the current data card.\n        Implemented with a DataRegistry object.\n            Returns:\n            Registry metadata\n        \"\"\"\n        exclude_attr = {\"data\"}\n        return self.model_dump(exclude=exclude_attr)\n\n    def add_info(self, info: Dict[str, Union[float, int, str]]) -&gt; None:\n        \"\"\"\n        Adds metadata to the existing DataCard metadata dictionary\n\n        Args:\n            info:\n                Dictionary containing name (str) and value (float, int, str) pairs\n                to add to the current metadata set\n        \"\"\"\n\n        self.metadata.additional_info = {**info, **self.metadata.additional_info}\n\n    def create_data_profile(self, sample_perc: float = 1) -&gt; ProfileReport:\n        \"\"\"Creates a data profile report\n\n        Args:\n            sample_perc:\n                Percentage of data to use when creating a profile. Sampling is recommended for large dataframes.\n                Percentage is expressed as a decimal (e.g. 1 = 100%, 0.5 = 50%, etc.)\n\n        \"\"\"\n        assert isinstance(\n            self.interface, DataInterface\n        ), \"Data profile can only be created for a DataInterface subclasses\"\n        self.interface.create_data_profile(sample_perc, str(self.name))\n\n    def split_data(self) -&gt; Dict[str, Data]:\n        \"\"\"Splits data interface according to data split logic\"\"\"\n\n        assert isinstance(self.interface, DataInterface), \"Splitting is only support for DataInterface subclasses\"\n        if self.data is None:\n            self.load_data()\n\n        return self.interface.split_data()\n\n    @property\n    def data_splits(self) -&gt; List[DataSplit]:\n        \"\"\"Returns data splits\"\"\"\n        assert isinstance(self.interface, DataInterface), \"Data splits are only supported for DataInterface subclasses\"\n        return self.interface.data_splits\n\n    @property\n    def data(self) -&gt; Any:\n        \"\"\"Returns data\"\"\"\n        assert isinstance(\n            self.interface, DataInterface\n        ), \"Data attribute is only supported for DataInterface subclasses\"\n        return self.interface.data\n\n    @property\n    def data_profile(self) -&gt; Any:\n        \"\"\"Returns data profile\"\"\"\n        assert isinstance(self.interface, DataInterface), \"Data profile is only supported for DataInterface subclasses\"\n        return self.interface.data_profile\n\n    @property\n    def card_type(self) -&gt; str:\n        return CardType.DATACARD.value\n</code></pre>"},{"location":"cards/datacard/#opsml.DataCard.card_type","title":"<code>card_type: str</code>  <code>property</code>","text":""},{"location":"cards/datacard/#opsml.DataCard.create_data_profile","title":"<code>create_data_profile(sample_perc=1)</code>","text":"<p>Creates a data profile report</p> <p>Parameters:</p> Name Type Description Default <code>sample_perc</code> <code>float</code> <p>Percentage of data to use when creating a profile. Sampling is recommended for large dataframes. Percentage is expressed as a decimal (e.g. 1 = 100%, 0.5 = 50%, etc.)</p> <code>1</code> Source code in <code>opsml/cards/data.py</code> <pre><code>def create_data_profile(self, sample_perc: float = 1) -&gt; ProfileReport:\n    \"\"\"Creates a data profile report\n\n    Args:\n        sample_perc:\n            Percentage of data to use when creating a profile. Sampling is recommended for large dataframes.\n            Percentage is expressed as a decimal (e.g. 1 = 100%, 0.5 = 50%, etc.)\n\n    \"\"\"\n    assert isinstance(\n        self.interface, DataInterface\n    ), \"Data profile can only be created for a DataInterface subclasses\"\n    self.interface.create_data_profile(sample_perc, str(self.name))\n</code></pre>"},{"location":"cards/datacard/#opsml.DataCard.split_data","title":"<code>split_data()</code>","text":"<p>Splits data interface according to data split logic</p> Source code in <code>opsml/cards/data.py</code> <pre><code>def split_data(self) -&gt; Dict[str, Data]:\n    \"\"\"Splits data interface according to data split logic\"\"\"\n\n    assert isinstance(self.interface, DataInterface), \"Splitting is only support for DataInterface subclasses\"\n    if self.data is None:\n        self.load_data()\n\n    return self.interface.split_data()\n</code></pre>"},{"location":"cards/datacard/#opsml.DataCard.load_data","title":"<code>load_data(**kwargs)</code>","text":"<p>Load data to interface</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>Union[str, int]</code> <p>Keyword arguments to pass to the data loader</p> <code>{}</code> <code>split</code> <p>Split to use for data. If not provided, then all data will be loaded. Only used for subclasses of <code>Dataset</code>.</p> required <code>batch_size</code> <p>What batch size to use when loading data. Only used for subclasses of <code>Dataset</code>. Defaults to 1000.</p> required <code>chunk_size</code> <p>How many files per batch to use when writing arrow back to local file. Defaults to 1000.</p> <p>Example:</p> <pre><code>- If batch_size=1000 and chunk_size=100, then the loaded batch will be split into\n10 chunks to write in parallel. This is useful for large datasets.\n</code></pre> required Source code in <code>opsml/cards/data.py</code> <pre><code>def load_data(self, **kwargs: Union[str, int]) -&gt; None:  # pylint: disable=differing-param-doc\n    \"\"\"\n    Load data to interface\n\n    Args:\n        kwargs:\n            Keyword arguments to pass to the data loader\n\n        ---- Supported kwargs for ImageData and TextDataset ----\n\n        split:\n            Split to use for data. If not provided, then all data will be loaded.\n            Only used for subclasses of `Dataset`.\n\n        batch_size:\n            What batch size to use when loading data. Only used for subclasses of `Dataset`.\n            Defaults to 1000.\n\n        chunk_size:\n            How many files per batch to use when writing arrow back to local file.\n            Defaults to 1000.\n\n            Example:\n\n                - If batch_size=1000 and chunk_size=100, then the loaded batch will be split into\n                10 chunks to write in parallel. This is useful for large datasets.\n\n    \"\"\"\n    from opsml.storage.card_loader import DataCardLoader\n\n    DataCardLoader(self).load_data(**kwargs)\n</code></pre>"},{"location":"cards/metadata/","title":"Metadata","text":""},{"location":"cards/metadata/#card-metadata","title":"Card Metadata","text":"<p>Both <code>ModelCard</code> and <code>DataCard</code> objects have a <code>metadata</code> attribute that can be used to store information about the model. If not provided, a default object is created. When registering a card, the metadata is updated with the latest information. In addition to automatically generated attributes, the <code>metadata</code> object can be used to store custom information about the model like descriptions.</p>"},{"location":"cards/metadata/#user-defined-attributes-optional","title":"User-Defined Attributes (Optional)","text":"<code>description</code>: <code>Description</code> Description object for your model"},{"location":"cards/metadata/#description","title":"Description","text":"<p><code>Description</code> is a simple data structure that can be used to store extra descriptive information about your model or data.</p>"},{"location":"cards/metadata/#args","title":"Args","text":"<code>Summary</code>:  <code>Optional[str]</code> Summary text or pointer to a markdown file that describes the model or data <code>Sample Code</code>: <code>Optional[str]</code> Sample code that can be used to load and run the model or data <code>Notes</code>: <code>Optional[str]</code> Any additional information not captured by the other attributes"},{"location":"cards/metadata/#example","title":"Example","text":"<pre><code>from opsml import ModelCard, ModelCardMetadata\nfrom opsml.types import Description, ModelCardMetadata\n\n# logic for datacard or modelcard\n...\n\nmodelcard = ModelCard(\n  name=\"my_model\",\n  repository=\"my_repo\",\n  contact=\"user\",\n  interface=interface,\n  datacard_uid=datacard.uid,\n  metadata=ModelCardMetadata(description=Description(summary=\"my_summary.md\")\n  )\n)\n</code></pre>"},{"location":"cards/metadata/#docs","title":"Docs","text":""},{"location":"cards/metadata/#opsml.types.Description","title":"<code>opsml.types.Description</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>opsml/types/extra.py</code> <pre><code>class Description(BaseModel):\n    summary: Optional[str] = None\n    sample_code: Optional[str] = None\n    Notes: Optional[str] = None\n\n    @field_validator(\"summary\", mode=\"before\")\n    @classmethod\n    def load_summary(cls, summary: Optional[str]) -&gt; Optional[str]:\n        if summary is None:\n            return summary\n\n        if \".md\" in summary.lower():\n            try:\n                mkdwn_path = FileUtils.find_filepath(name=summary)\n                with open(mkdwn_path, \"r\", encoding=\"utf-8\") as file_:\n                    summary = file_.read()\n\n            except IndexError as idx_error:\n                logger.info(f\"Could not load markdown file {idx_error}\")\n\n        return summary\n</code></pre>"},{"location":"cards/metadata/#opsml.types.ModelCardMetadata","title":"<code>opsml.types.ModelCardMetadata</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Create modelcard metadata</p> <p>Parameters:</p> Name Type Description Default <code>interface_type</code> <p>Type of interface</p> required <code>description</code> <p>Description for your model</p> required <code>data_schema</code> <p>Data schema for your model</p> required <code>runcard_uid</code> <p>RunCard associated with the ModelCard</p> required <code>pipelinecard_uid</code> <p>Associated PipelineCard</p> required <code>auditcard_uid</code> <p>Associated AuditCard</p> required Source code in <code>opsml/types/model.py</code> <pre><code>class ModelCardMetadata(BaseModel):\n    \"\"\"Create modelcard metadata\n\n    Args:\n        interface_type:\n            Type of interface\n        description:\n            Description for your model\n        data_schema:\n            Data schema for your model\n        runcard_uid:\n            RunCard associated with the ModelCard\n        pipelinecard_uid:\n            Associated PipelineCard\n        auditcard_uid:\n            Associated AuditCard\n    \"\"\"\n\n    interface_type: str = \"\"\n    description: Description = Description()\n    data_schema: DataSchema = DataSchema()\n    runcard_uid: Optional[str] = None\n    pipelinecard_uid: Optional[str] = None\n    auditcard_uid: Optional[str] = None\n\n    model_config = ConfigDict(protected_namespaces=(\"protect_\",))\n</code></pre>"},{"location":"cards/metadata/#opsml.types.DataCardMetadata","title":"<code>opsml.types.DataCardMetadata</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Create a DataCard metadata</p> <p>Parameters:</p> Name Type Description Default <code>description</code> <p>Description for your data</p> required <code>feature_map</code> <p>Map of features in data (inferred when converting to pyarrow table)</p> required <code>feature_descriptions</code> <p>Dictionary of features and their descriptions</p> required <code>additional_info</code> <p>Dictionary of additional info to associate with data (i.e. if data is tokenized dataset, metadata could be {\"vocab_size\": 200})</p> required <code>data_uri</code> <p>Location where converted pyarrow table is stored</p> required <code>runcard_uid</code> <p>Id of RunCard that created the DataCard</p> required <code>pipelinecard_uid</code> <p>Associated PipelineCard</p> required <code>uris</code> <p>DataCardUris object containing all uris associated with DataCard</p> required Source code in <code>opsml/types/data.py</code> <pre><code>class DataCardMetadata(BaseModel):\n    \"\"\"Create a DataCard metadata\n\n    Args:\n        description:\n            Description for your data\n        feature_map:\n            Map of features in data (inferred when converting to pyarrow table)\n        feature_descriptions:\n            Dictionary of features and their descriptions\n        additional_info:\n            Dictionary of additional info to associate with data\n            (i.e. if data is tokenized dataset, metadata could be {\"vocab_size\": 200})\n        data_uri:\n            Location where converted pyarrow table is stored\n        runcard_uid:\n            Id of RunCard that created the DataCard\n        pipelinecard_uid:\n            Associated PipelineCard\n        uris:\n            DataCardUris object containing all uris associated with DataCard\n    \"\"\"\n\n    interface_type: str = \"\"\n    data_type: str = \"\"\n    description: Description = Description()\n    feature_map: Dict[str, Feature] = {}\n    additional_info: Dict[str, Union[float, int, str]] = {}\n    runcard_uid: Optional[str] = None\n    pipelinecard_uid: Optional[str] = None\n    auditcard_uid: Optional[str] = None\n</code></pre>"},{"location":"cards/metadata/#registered-model-metadata","title":"Registered Model Metadata","text":"<p>One of the benefits to the model registration process (especially when auto-converting to onnx) is the creation of model metadata that can be used in downstream applications to load and run models via apis or batch jobs. The example below shows sample metadata that is produced with a registered model.</p>"},{"location":"cards/metadata/#example_1","title":"Example","text":"<pre><code>{\n    \"model_name\": \"regression\",\n    \"model_class\": \"SklearnEstimator\",\n    \"model_type\": \"LinearRegression\",\n    \"model_interface\": \"SklearnModel\",\n    \"onnx_uri\": \"opsml-root:/OPSML_MODEL_REGISTRY/opsml/regression/v1.4.0/onnx-model.onnx\",\n    \"onnx_version\": \"1.14.1\",\n    \"model_uri\": \"opsml-root:/OPSML_MODEL_REGISTRY/opsml/regression/v1.4.0/trained-model.joblib\",\n    \"model_version\": \"1.4.0\",\n    \"model_repository\": \"opsml\",\n    \"sample_data_uri\": \"opsml-root:/OPSML_MODEL_REGISTRY/opsml/regression/v1.4.0/sample-model-data.joblib\",\n    \"opsml_version\": \"2.0.0\",\n    \"data_schema\": {\n        \"data_type\": \"numpy.ndarray\",\n        \"input_features\": {\n            \"inputs\": {\n                \"feature_type\": \"float64\",\n                \"shape\": [\n                    1,\n                    10\n                ]\n            }\n        },\n        \"output_features\": {\n            \"outputs\": {\n                \"feature_type\": \"float64\",\n                \"shape\": [\n                    1,\n                    1\n                ]\n            }\n        },\n        \"onnx_input_features\": {\n            \"predict\": {\n                \"feature_type\": \"tensor(float)\",\n                \"shape\": [\n                    null,\n                    10\n                ]\n            }\n        },\n        \"onnx_output_features\": {\n            \"variable\": {\n                \"feature_type\": \"tensor(float)\",\n                \"shape\": [\n                    null,\n                    1\n                ]\n            }\n        },\n        \"onnx_data_type\": null,\n        \"onnx_version\": \"1.14.1\"\n    }\n}\n</code></pre>"},{"location":"cards/metadata/#opsml.ModelMetadata","title":"<code>opsml.ModelMetadata</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Model metadata associated with all registered models</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <p>Name of model</p> required <code>model_class</code> <p>Name of model class</p> required <code>model_type</code> <p>Type of model</p> required <code>model_interface</code> <p>Type of interface</p> required <code>onnx_uri</code> <p>URI to onnx model</p> required <code>onnx_version</code> <p>Version of onnx model</p> required <code>model_uri</code> <p>URI to model</p> required <code>model_version</code> <p>Version of model</p> required <code>model_repository</code> <p>Model repository</p> required <code>sample_data_uri</code> <p>URI to sample data</p> required <code>opsml_version</code> <p>Opsml version</p> required <code>data_schema</code> <p>Data schema for model</p> required <code>preprocessor_uri</code> <p>(only present if preprocessor is used) URI to preprocessor</p> required <code>preprocessor_name</code> <p>(only present if preprocessor is used) Name of preprocessor</p> required <code>quantized_model_uri</code> <p>(only present if huggingface model is quantized) URI to huggingface quantized onnx model</p> required <code>tokenizer_uri</code> <p>(only present if huggingface tokenizer is used) URI to tokenizer</p> required <code>tokenizer_name</code> <p>(only present if huggingface is used) Name of tokenizer</p> required <code>feature_extractor_uri</code> <p>(only present if huggingface feature extractor is used) URI to feature extractor</p> required <code>feature_extractor_name</code> <p>(only present if huggingface feature_extractor is used) Name of feature extractor</p> required Source code in <code>opsml/types/model.py</code> <pre><code>class ModelMetadata(BaseModel):\n    \"\"\"Model metadata associated with all registered models\n\n    Args:\n        model_name:\n            Name of model\n        model_class:\n            Name of model class\n        model_type:\n            Type of model\n        model_interface:\n            Type of interface\n        onnx_uri:\n            URI to onnx model\n        onnx_version:\n            Version of onnx model\n        model_uri:\n            URI to model\n        model_version:\n            Version of model\n        model_repository:\n            Model repository\n        sample_data_uri:\n            URI to sample data\n        opsml_version:\n            Opsml version\n        data_schema:\n            Data schema for model\n        preprocessor_uri: (only present if preprocessor is used)\n            URI to preprocessor\n        preprocessor_name: (only present if preprocessor is used)\n            Name of preprocessor\n        quantized_model_uri: (only present if huggingface model is quantized)\n            URI to huggingface quantized onnx model\n        tokenizer_uri: (only present if huggingface tokenizer is used)\n            URI to tokenizer\n        tokenizer_name: (only present if huggingface is used)\n            Name of tokenizer\n        feature_extractor_uri: (only present if huggingface feature extractor is used)\n            URI to feature extractor\n        feature_extractor_name: (only present if huggingface feature_extractor is used)\n            Name of feature extractor\n    \"\"\"\n\n    model_name: str\n    model_class: str\n    model_type: str\n    model_interface: str\n    onnx_uri: Optional[str] = None\n    onnx_version: Optional[str] = None\n    model_uri: str\n    model_version: str\n    model_repository: str\n    sample_data_uri: str\n    opsml_version: str = __version__\n    data_schema: DataSchema\n\n    model_config = ConfigDict(\n        protected_namespaces=(\"protect_\",),\n        extra=\"allow\",\n    )\n</code></pre>"},{"location":"cards/modelcard/","title":"Overview","text":"<p>ModelCards are cards for storing, versioning, and tracking model objects.</p>"},{"location":"cards/modelcard/#features","title":"Features","text":"<ul> <li>shareable: All cards including ModelCards are shareable and searchable.</li> <li>auto-onnx: Automatic conversion of trained model into onnx model format.</li> <li>auto-schema: Auto-infer data schema and input and output signature.</li> <li>versioning: SemVer for your model.</li> </ul>"},{"location":"cards/modelcard/#create-a-card","title":"Create a Card","text":"<pre><code># load data card from earlier\nfrom sklearn.linear_model import LinearRegression\n\n# Opsml\nfrom opsml import CardRegistry, ModelCard, CardInfo\n\n# set up registries\ndata_registry = CardRegistry(registry_name=\"data\")\nmodel_registry = CardRegistry(registry_name=\"model\")\n\ncard_info = CardInfo(name=\"linnerrud\", repository=\"opsml\", contact=\"user@email.com\")\n\n\n# load datacard\ndatacard = data_registry.load_card(name=card_info.name, version=\"1.0.0\")\n\n# data is not loaded by default (helps when sharing cards with large data)\ndatacard.load_data()\ndata_splits = datacard.split_data()\n\n\nX_train = data_splits[\"train\"].X\ny_train = data_splits[\"train\"].y\n\n# fit model\nlinreg = LinearRegression()\nlinreg = linreg.fit(X=X_train, y=y_train)\nmodel_interface = SklearnModel(model=linreg, sample_data=X_train)\n\n# lets test the onnx model before registering\nmodelcard = ModelCard(\n    info=card_info,\n    interface = model_interface,\n    datacard_uid=datacard.uid,\n    to_onnx=True,\n)\n\n# if you'd like to convert to onnx before registering, you can do that as well\nmodelcard.convert_to_onnx()\n\n# custom onnx testing logic\n...\n\n# everything looks good\nmodel_registry.register_card(modelcard)\n</code></pre>"},{"location":"cards/modelcard/#modelcard-args","title":"ModelCard Args","text":"<code>name</code>: <code>str</code> Name for the data (Required) <code>repository</code>: <code>str</code> repository data belongs to (Required) <code>contact</code>: <code>str</code> Email to associate with data (Required) <code>interface</code>: <code>ModelInterface</code> ModelInterface used to interact with model. See ModelInterface for more information <code>datacard_uid</code> uid of DataCard that contains training data. This is not required to instantiate a ModelCard, but it is required to register a ModelCard <code>to_onnx</code> Whether to convert model to onnx or not. Default is True <code>metadata</code>: <code>ModelCardMetadata</code> Optional ModelCardMetadata used to store metadata about the model. See ModelCardMetadata for more information. If not provided, a default object is created. When registering a card, the metadata is updated with the latest information."},{"location":"cards/modelcard/#docs","title":"Docs","text":""},{"location":"cards/modelcard/#opsml.ModelCard","title":"<code>opsml.ModelCard</code>","text":"<p>             Bases: <code>ArtifactCard</code></p> <p>Create a ModelCard from your trained machine learning model. This Card is used in conjunction with the ModelCardCreator class.</p> <p>Parameters:</p> Name Type Description Default <code>interface</code> <pre><code>Trained model interface.\n</code></pre> required <code>name</code> <p>Name for the model specific to your current project</p> required <code>repository</code> <p>Repository that this model is associated with</p> required <code>contact</code> <p>Contact to associate with card</p> required <code>info</code> <p><code>CardInfo</code> object containing additional metadata. If provided, it will override any values provided for <code>name</code>, <code>repository</code>, <code>contact</code>, and <code>version</code>.</p> <p>Name, repository, and contact are required arguments for all cards. They can be provided directly or through a <code>CardInfo</code> object.</p> required <code>uid</code> <p>Unique id (assigned if card has been registered)</p> required <code>version</code> <p>Current version (assigned if card has been registered)</p> required <code>datacard_uid</code> <p>Uid of the DataCard associated with training the model</p> required <code>to_onnx</code> <p>Whether to convert the model to onnx or not</p> required <code>metadata</code> <p><code>ModelCardMetadata</code> associated with the model</p> required Source code in <code>opsml/cards/model.py</code> <pre><code>class ModelCard(ArtifactCard):\n    \"\"\"Create a ModelCard from your trained machine learning model.\n    This Card is used in conjunction with the ModelCardCreator class.\n\n    Args:\n        interface:\n                Trained model interface.\n        name:\n            Name for the model specific to your current project\n        repository:\n            Repository that this model is associated with\n        contact:\n            Contact to associate with card\n        info:\n            `CardInfo` object containing additional metadata. If provided, it will override any\n            values provided for `name`, `repository`, `contact`, and `version`.\n\n            Name, repository, and contact are required arguments for all cards. They can be provided\n            directly or through a `CardInfo` object.\n\n        uid:\n            Unique id (assigned if card has been registered)\n        version:\n            Current version (assigned if card has been registered)\n        datacard_uid:\n            Uid of the DataCard associated with training the model\n        to_onnx:\n            Whether to convert the model to onnx or not\n        metadata:\n            `ModelCardMetadata` associated with the model\n    \"\"\"\n\n    model_config = ConfigDict(\n        arbitrary_types_allowed=True,\n        protected_namespaces=(\"protect_\",),\n        validate_assignment=True,\n    )\n\n    interface: SerializeAsAny[ModelInterface]\n    datacard_uid: Optional[str] = None\n    to_onnx: bool = False\n    metadata: ModelCardMetadata = ModelCardMetadata()\n\n    @field_validator(\"datacard_uid\", mode=\"before\")\n    @classmethod\n    def check_uid(cls, datacard_uid: Optional[str] = None) -&gt; Optional[str]:\n        if datacard_uid is None:\n            return datacard_uid\n\n        try:\n            UUID(datacard_uid, version=4)  # we use uuid4\n            return datacard_uid\n\n        except ValueError as exc:\n            raise ValueError(\"Datacard uid is not a valid uuid\") from exc\n\n    def load_model(self, **kwargs: Any) -&gt; None:\n        \"\"\"Loads model, preprocessor and sample data to interface\"\"\"\n\n        from opsml.storage.card_loader import ModelCardLoader\n\n        ModelCardLoader(self).load_model(**kwargs)\n\n    def download_model(self, path: Path, **kwargs: Any) -&gt; None:\n        \"\"\"Downloads model, preprocessor and metadata to path\n\n        Args:\n            path:\n                Path to download model\n\n            kwargs:\n                load_preprocessor:\n                    Whether to load preprocessor or not. Default is True\n                load_onnx:\n                    Whether to load onnx model or not. Default is False\n                quantize:\n                    Whether to quantize onnx model or not. Default is False\n        \"\"\"\n\n        from opsml.storage.card_loader import ModelCardLoader\n\n        # set path to download model\n        kwargs[\"lpath\"] = path\n\n        ModelCardLoader(self).download_model(**kwargs)\n\n    def load_onnx_model(self, **kwargs: Any) -&gt; None:\n        \"\"\"Loads onnx model to interface\"\"\"\n\n        from opsml.storage.card_loader import ModelCardLoader\n\n        ModelCardLoader(self).load_onnx_model(**kwargs)\n\n    def load_preprocessor(self, **kwargs: Any) -&gt; None:\n        \"\"\"Loads onnx model to interface\"\"\"\n\n        if self.preprocessor is not None:\n            return\n\n        from opsml.storage.card_loader import ModelCardLoader\n\n        ModelCardLoader(self).load_preprocessor(**kwargs)\n\n    def create_registry_record(self) -&gt; Dict[str, Any]:\n        \"\"\"Creates a registry record from the current ModelCard\"\"\"\n\n        exclude_vars = {\"interface\": {\"model\", \"preprocessor\", \"sample_data\", \"onnx_model\"}}\n        dumped_model = self.model_dump(exclude=exclude_vars)\n\n        return dumped_model\n\n    @property\n    def model(self) -&gt; Any:\n        \"\"\"Quick access to model from interface\"\"\"\n        return self.interface.model\n\n    @property\n    def sample_data(self) -&gt; Any:\n        \"\"\"Quick access to sample data from interface\"\"\"\n        return self.interface.sample_data\n\n    @property\n    def preprocessor(self) -&gt; Any:\n        \"\"\"Quick access to preprocessor from interface\"\"\"\n\n        if hasattr(self.interface, \"preprocessor\"):\n            return self.interface.preprocessor\n\n        if hasattr(self.interface, \"tokenizer\"):\n            if self.interface.tokenizer is not None:\n                return self.interface.tokenizer\n\n        if hasattr(self.interface, \"feature_extractor\"):\n            if self.interface.feature_extractor is not None:\n                return self.interface.feature_extractor\n\n        return None\n\n    @property\n    def onnx_model(self) -&gt; Optional[OnnxModel]:\n        \"\"\"Quick access to onnx model from interface\"\"\"\n        return self.interface.onnx_model\n\n    @property\n    def model_metadata(self) -&gt; ModelMetadata:\n        \"\"\"Loads `ModelMetadata` class\"\"\"\n\n        from opsml.storage.card_loader import ModelCardLoader\n\n        return ModelCardLoader(self).load_model_metadata()\n\n    @property\n    def card_type(self) -&gt; str:\n        return CardType.MODELCARD.value\n</code></pre>"},{"location":"cards/modelcard/#opsml.ModelCard.onnx_model","title":"<code>onnx_model: Optional[OnnxModel]</code>  <code>property</code>","text":"<p>Quick access to onnx model from interface</p>"},{"location":"cards/overview/","title":"Overview","text":"<p>Cards (aka ArtifactCards) are one of the primary data structures for working with <code>Opsml</code> that contain both data and model interface objects as well as associated metadata. <code>ArtifactCards</code> are stored in registries and can be used to track and version data and models.</p> <pre><code>flowchart TD\nDS([\"fa:fa-user-group\" DS])\nDS --&gt; Model([Model])\nModel --&gt; Metrics([Metrics])\nMetrics --&gt; RunCard(RunCard)\nRunCard --&gt; RunRegistry[(RunRegistry)]\nModel --&gt; ModelCard(ModelCard)\nModelCard --&gt; ModelRegistry[(ModelRegistry)]\nModelCard --&gt;DeployableArtifact(Deployable Artifact)\nDS --&gt; Data([Data])\nData --&gt; DataCard(DataCard)\nDataCard --&gt; DataRegistry[(DataRegistry)]\nDataCard -.-&gt;ModelCard\n\nstyle DS fill:#028e6b,stroke:black,stroke-width:2px,color:white,font-weight:bolder\nstyle Model fill:#028e6b,stroke:black,stroke-width:2px,color:white,font-weight:bolder\nstyle Metrics fill:#028e6b,stroke:black,stroke-width:2px,color:white,font-weight:bolder\nstyle Data fill:#028e6b,stroke:black,stroke-width:2px,color:white,font-weight:bolder\nstyle RunCard fill:#028e6b,stroke:black,stroke-width:2px,color:white,font-weight:bolder\nstyle DataCard fill:#028e6b,stroke:black,stroke-width:2px,color:white,font-weight:bolder\nstyle ModelCard fill:#028e6b,stroke:black,stroke-width:2px,color:white,font-weight:bolder\nstyle DeployableArtifact fill:#028e6b,stroke:black,stroke-width:2px,color:white,font-weight:bolder\nstyle RunRegistry fill:#5e0fb7,stroke:black,stroke-width:2px,color:white,font-weight:bolder\nstyle ModelRegistry fill:#5e0fb7,stroke:black,stroke-width:2px,color:white,font-weight:bolder\nstyle DataRegistry fill:#5e0fb7,stroke:black,stroke-width:2px,color:white,font-weight:bolder</code></pre>"},{"location":"cards/overview/#card-types","title":"Card Types","text":"<ul> <li><code>DataCard</code>: Card used to store data-related information (``, dependent variables, feature descriptions, split logic, etc.)</li> <li><code>ModelCard</code>: Card used to store trained model and model information</li> <li><code>RunCard</code>: Stores artifact and metric info related to Data, Model, or Pipeline cards.</li> <li><code>ProjectCard</code>: Stores information related to unique projects. You will most likely never interact with this card directly.</li> </ul>"},{"location":"cards/overview/#registries","title":"Registries","text":"<p>Each card type is associated with a specific registry (<code>DataCard</code> with data registry, <code>ModelCard</code> with model registry, etc.), and registries can be used to <code>list</code>, <code>load</code> and <code>register</code> cards.</p>"},{"location":"cards/overview/#card-information","title":"Card Information","text":"<p>You'll notice when working with <code>ArtifactCards</code> and <code>CardRegistries</code> that there are a few common arguments that are always required. These arguments are:</p> <ul> <li>name: Name of card</li> <li>repository: Repository associated with card</li> <li>contact: Contact information for card</li> </ul> <p>These arguments are required for card registration and can be supplied through named arguments or through a <code>CardInfo</code> dataclass.</p> <p><code>CardInfo</code> is a helper class that can be used to store these arguments so you don't need to make repetitive calls. In addition, the <code>CardInfo</code> class allows you to set <code>runtime</code> environment variables through a <code>set_env()</code> method. This will allow to create cards without having to specify <code>name</code>, <code>repository</code> and/or <code>contact</code>. Examples are below.</p>"},{"location":"cards/overview/#example-of-named-arguments","title":"Example of named arguments","text":"<pre><code>from opsml import DataCard\n\n# skip data interface logic\n...\n\nDataCard(\n  name=\"linnerud\", \n  repository=\"opsml\", \n  contact=\"mlops.com\", \n  interface=data_interface\n  )\n</code></pre>"},{"location":"cards/overview/#example-of-cardinfo","title":"Example of CardInfo","text":"<pre><code>from opsml import DataCard, CardInfo\n\ninfo = CardInfo(name=\"linnerud\", repository=\"opsml\", contact=\"mlops.com\")\n\n# skip data interface logic\n...\n\nDataCard(\n  info=info,\n  interface=data_interface\n  )\n</code></pre>"},{"location":"cards/overview/#example-of-runtime-env-vars","title":"Example of Runtime Env Vars","text":"<pre><code>from opsml import DataCard, CardInfo\n\ninfo = CardInfo(name=\"linnerud\", repository=\"opsml\", contact=\"mlops.com\").set_env()\n\n# skip data interface logic\n...\n\nDataCard(interface=data_interface)\n</code></pre>"},{"location":"cards/overview/#name-uniqueness","title":"Name Uniqueness","text":"<p>When registering cards, <code>Opsml</code> will check to see if a card with the same name, repository and version already exists. Therefore, name uniqueness is guaranteed at the <code>repository/name</code> level. Thus, different repositories can share cards with the same name.</p>"},{"location":"cards/overview/#listing-cards","title":"Listing Cards","text":"Returns a list of dictionaries. <p>Required Args:</p> <ul> <li>Name: Name of card (Optional)</li> <li>repository: repository associated with card (Optional)</li> <li>Version: Version of Card (Optional)</li> <li>uid: Uid of card (Optional)</li> <li>info: <code>CardInfo</code> dataclass that can be used in place of Name, repository, Version and Uid</li> <li>limit: Limit result</li> </ul> <p>Example:</p> <pre><code>from opsml import CardRegistry\n\nregistry = CardRegistry(registry_name=\"model\") # can be \"data\", \"model\", \"run\", \"pipeline\n\n# examples\nregistry.list_cards() \n# will list all cards in registry\n\nregistry.list_cards(limit=10) \n# will list cards and limit the result to 10\n\nregistry.list_cards(name=\"linear-reg\")\n  # list all cards with name \"linear-reg\"\n\nregistry.list_cards(name=\"linear-reg\", repository=\"opsml\") \n# list all cards with name \"linear-reg\" with repository \"opsml\"\n\nregistry.list_cards(name=\"linear-reg\", repository=\"opsml\", version=\"1.0.0\") \n# list card with name \"linear-reg\" with repository \"opsml\" and version 1.0.0\n\nregistry.list_cards(name=\"linear-reg\", repository=\"opsml\", version=\"1.*.*\") \n# list cards with name \"linear-reg\" with repository \"opsml\" and major version of \"1\"\n\nregistry.list_cards(name=\"linear-reg\", repository=\"opsml\", version=\"^2.3.4\") \n# list card with name \"linear-reg\" with repository \"opsml\" and latest version &lt; 3.0.0\n\nregistry.list_cards(name=\"linear-reg\", repository=\"opsml\", version=\"~2.3.4\") \n# list card with name \"linear-reg\" with repository \"opsml\" and latest version &lt; 2.4.0\n\nregistry.list_cards(uid=uid)\n# list card by uid\n</code></pre>"},{"location":"cards/overview/#registering-a-card","title":"Registering a Card","text":"Register a card to a registry <p>Required Args:</p> <ul> <li>card: Card to register</li> <li>version_type: Type of version increment. Can be \"major\", \"minor\" and \"patch\" (Optional)</li> <li>save_path: Specific path to save to in root opsml folder if default are not preferred (Optional)</li> </ul> <p>Example:</p> <pre><code>from opsml import CardRegistry\n\nmodel_registry = CardRegistry(registry_name=\"model\")\n\n# skipping ModelInterface logic\n...\n\nmodel_card = ModelCard(\n      interface=model_interface,\n      name=\"linear-reg\",\n      repository=\"opsml\",\n      contact=\"mlops.com\",\n      datacard_uid=data_card.uid,\n  )\n\nexample_record = model_registry.register_card(card=model_card)\nprint(model_card.version)\n#&gt; 1.0.0\n</code></pre>"},{"location":"cards/overview/#loading-cards","title":"Loading Cards","text":"Load an Artifact card from a registry. <p>Required Args:</p> <ul> <li>Name: Name of card (Optional)</li> <li>repository: repository associated with card (Optional)</li> <li>Version: Version of Card (Optional)</li> <li>uid: Uid of card (Optional)</li> <li>info: <code>CardInfo</code> dataclass that can be used in place of Name, repository, Version and Uid</li> </ul> <p>Example:</p> <pre><code>from opsml import CardRegistry\nmodel_registry = CardRegistry(registry_name=\"model\")\n\nexample_record = model_registry.list_cards(name=\"linnerrud\", )[0]\n\nmodel_card = model_registry.load_card(uid=example_record.get(\"uid\"))\nprint(model_card.version)\n#&gt; 1.0.0\n</code></pre>"},{"location":"cards/overview/#update-cards","title":"Update Cards","text":"<p>You can also update cards</p> <pre><code>from opsml import CardRegistry\nmodel_registry = CardRegistry(registry_name=\"model\")\n\n# skipping card logic\n...\n\ncard.contact = \"new_contact\"\nmodel_registry.update_card(card)\n</code></pre>"},{"location":"cards/overview/#deleting-cards","title":"Deleting Cards","text":"<p>In the event you need to delete a card, there's a built in <code>delete_card</code> method.</p> <pre><code>from opsml import CardRegistry\nmodel_registry = CardRegistry(registry_name=\"model\")\n\n# skipping card logic\n...\n\nmodel_registry.delete_card(card)\n</code></pre>"},{"location":"cards/overview/#opsml.CardRegistry","title":"<code>opsml.CardRegistry</code>","text":"Source code in <code>opsml/registry/registry.py</code> <pre><code>class CardRegistry:\n    def __init__(self, registry_type: Union[RegistryType, str]):\n        \"\"\"\n        Interface for connecting to any of the ArtifactCard registries\n\n        Args:\n            registry_type:\n                Type of card registry to create\n            settings:\n                Storage settings\n\n        Returns:\n            Instantiated connection to specific Card registry\n\n        Example:\n            data_registry = CardRegistry(RegistryType.DATA)\n            data_registry.list_cards()\n\n            or\n            data_registry = CardRegistry(\"data\")\n            data_registry.list_cards()\n        \"\"\"\n\n        _registry_type = (\n            registry_type if isinstance(registry_type, RegistryType) else RegistryType.from_str(registry_type)\n        )\n\n        self._registry = _set_registry(_registry_type)\n        self.table_name = self._registry.table_name\n\n    @property\n    def registry_type(self) -&gt; RegistryType:\n        \"Registry type for card registry\"\n        return self._registry.registry_type\n\n    def list_cards(\n        self,\n        uid: Optional[str] = None,\n        name: Optional[str] = None,\n        repository: Optional[str] = None,\n        version: Optional[str] = None,\n        tags: Optional[Dict[str, str]] = None,\n        info: Optional[CardInfo] = None,\n        max_date: Optional[str] = None,\n        limit: Optional[int] = None,\n        ignore_release_candidates: bool = False,\n    ) -&gt; List[Dict[str, Any]]:\n        \"\"\"Retrieves records from registry\n\n        Args:\n            name:\n                Card name\n            repository:\n                Repository associated with card\n            version:\n                Optional version number of existing data. If not specified, the\n                most recent version will be used\n            tags:\n                Dictionary of key, value tags to search for\n            uid:\n                Unique identifier for Card. If present, the uid takes precedence\n            max_date:\n                Max date to search. (e.g. \"2023-05-01\" would search for cards up to and including \"2023-05-01\")\n            limit:\n                Places a limit on result list. Results are sorted by SemVer\n            info:\n                CardInfo object. If present, the info object takes precedence\n            ignore_release_candidates:\n                If True, ignores release candidates\n\n        Returns:\n            pandas dataframe of records or list of dictionaries\n        \"\"\"\n\n        if info is not None:\n            name = name or info.name\n            repository = repository or info.repository\n            uid = uid or info.uid\n            version = version or info.version\n            tags = tags or info.tags\n\n        if name is not None:\n            name = name.lower()\n\n        if repository is not None:\n            repository = repository.lower()\n\n        if all(not bool(var) for var in [name, repository, version, uid, tags]):\n            limit = limit or 25\n\n        card_list = self._registry.list_cards(\n            uid=uid,\n            name=name,\n            repository=repository,\n            version=version,\n            max_date=max_date,\n            limit=limit,\n            tags=tags,\n            ignore_release_candidates=ignore_release_candidates,\n        )\n\n        return card_list\n\n    def load_card(\n        self,\n        name: Optional[str] = None,\n        repository: Optional[str] = None,\n        uid: Optional[str] = None,\n        tags: Optional[Dict[str, str]] = None,\n        version: Optional[str] = None,\n        info: Optional[CardInfo] = None,\n        ignore_release_candidates: bool = False,\n        interface: Optional[Union[Type[ModelInterface], Type[DataInterface]]] = None,\n    ) -&gt; ArtifactCard:\n        \"\"\"Loads a specific card\n\n        Args:\n            name:\n                Optional Card name\n            uid:\n                Unique identifier for card. If present, the uid takes\n                precedence.\n            tags:\n                Optional tags associated with model.\n            repository:\n                Optional repository associated with card\n            version:\n                Optional version number of existing data. If not specified, the\n                most recent version will be used\n            info:\n                Optional CardInfo object. If present, the info takes precedence\n            ignore_release_candidates:\n                If True, ignores release candidates\n            interface:\n                Optional interface to use for loading card. This is required for when using\n                subclassed interfaces.\n\n        Returns\n            ArtifactCard\n        \"\"\"\n\n        # find better way to do this later\n        if info is not None:\n            name = name or info.name\n            uid = uid or info.uid\n            version = version or info.version\n            tags = tags or info.tags\n\n        name = clean_string(name)\n\n        records = self.list_cards(\n            uid=uid,\n            name=name,\n            repository=repository,\n            version=version,\n            tags=tags,\n            ignore_release_candidates=ignore_release_candidates,\n            limit=1,\n        )\n\n        return CardLoader(\n            card_args=records[0],\n            registry_type=self.registry_type,\n        ).load_card(interface=interface)\n\n    def register_card(\n        self,\n        card: ArtifactCard,\n        version_type: Union[VersionType, str] = VersionType.MINOR,\n        pre_tag: str = \"rc\",\n        build_tag: str = \"build\",\n    ) -&gt; None:\n        \"\"\"\n        Adds a new `Card` record to registry. Registration will be skipped if the card already exists.\n\n        Args:\n            card:\n                card to register\n            version_type:\n                Version type for increment. Options are \"major\", \"minor\" and\n                \"patch\". Defaults to \"minor\".\n            pre_tag:\n                pre-release tag to add to card version\n            build_tag:\n                build tag to add to card version\n        \"\"\"\n\n        _version_type = version_type if isinstance(version_type, VersionType) else VersionType.from_str(version_type)\n\n        if card.uid is not None and card.version != CommonKwargs.BASE_VERSION.value:\n            logger.info(\n                textwrap.dedent(\n                    f\"\"\"\n                Card {card.uid} already exists. Skipping registration. If you'd like to register\n                a new card, please instantiate a new Card object. If you'd like to update the\n                existing card, please use the update_card method.\n                \"\"\"\n                )\n            )\n\n        else:\n            self._registry.register_card(\n                card=card,\n                version_type=_version_type,\n                pre_tag=pre_tag,\n                build_tag=build_tag,\n            )\n\n    def update_card(self, card: ArtifactCard) -&gt; None:\n        \"\"\"\n        Update an artifact card based on current registry\n\n        Args:\n            card:\n                Card to register\n        \"\"\"\n        return self._registry.update_card(card=card)\n\n    def query_value_from_card(self, uid: str, columns: List[str]) -&gt; Dict[str, Any]:\n        \"\"\"\n        Query column values from a specific Card\n\n        Args:\n            uid:\n                Uid of Card\n            columns:\n                List of columns to query\n\n        Returns:\n            Dictionary of column, values pairs\n        \"\"\"\n        results = self._registry.list_cards(uid=uid)[0]\n        return {col: results[col] for col in columns}\n\n    def delete_card(self, card: ArtifactCard) -&gt; None:\n        \"\"\"\n        Delete a specific Card\n\n        Args:\n            card:\n                Card to delete\n        \"\"\"\n        return self._registry.delete_card(card)\n</code></pre>"},{"location":"cards/overview/#opsml.CardRegistry.registry_type","title":"<code>registry_type: RegistryType</code>  <code>property</code>","text":"<p>Registry type for card registry</p>"},{"location":"cards/overview/#opsml.CardRegistry.__init__","title":"<code>__init__(registry_type)</code>","text":"<p>Interface for connecting to any of the ArtifactCard registries</p> <p>Parameters:</p> Name Type Description Default <code>registry_type</code> <code>Union[RegistryType, str]</code> <p>Type of card registry to create</p> required <code>settings</code> <p>Storage settings</p> required <p>Returns:</p> Type Description <p>Instantiated connection to specific Card registry</p> Example <p>data_registry = CardRegistry(RegistryType.DATA) data_registry.list_cards()</p> <p>or data_registry = CardRegistry(\"data\") data_registry.list_cards()</p> Source code in <code>opsml/registry/registry.py</code> <pre><code>def __init__(self, registry_type: Union[RegistryType, str]):\n    \"\"\"\n    Interface for connecting to any of the ArtifactCard registries\n\n    Args:\n        registry_type:\n            Type of card registry to create\n        settings:\n            Storage settings\n\n    Returns:\n        Instantiated connection to specific Card registry\n\n    Example:\n        data_registry = CardRegistry(RegistryType.DATA)\n        data_registry.list_cards()\n\n        or\n        data_registry = CardRegistry(\"data\")\n        data_registry.list_cards()\n    \"\"\"\n\n    _registry_type = (\n        registry_type if isinstance(registry_type, RegistryType) else RegistryType.from_str(registry_type)\n    )\n\n    self._registry = _set_registry(_registry_type)\n    self.table_name = self._registry.table_name\n</code></pre>"},{"location":"cards/overview/#opsml.CardRegistry.delete_card","title":"<code>delete_card(card)</code>","text":"<p>Delete a specific Card</p> <p>Parameters:</p> Name Type Description Default <code>card</code> <code>ArtifactCard</code> <p>Card to delete</p> required Source code in <code>opsml/registry/registry.py</code> <pre><code>def delete_card(self, card: ArtifactCard) -&gt; None:\n    \"\"\"\n    Delete a specific Card\n\n    Args:\n        card:\n            Card to delete\n    \"\"\"\n    return self._registry.delete_card(card)\n</code></pre>"},{"location":"cards/overview/#opsml.CardRegistry.list_cards","title":"<code>list_cards(uid=None, name=None, repository=None, version=None, tags=None, info=None, max_date=None, limit=None, ignore_release_candidates=False)</code>","text":"<p>Retrieves records from registry</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>Optional[str]</code> <p>Card name</p> <code>None</code> <code>repository</code> <code>Optional[str]</code> <p>Repository associated with card</p> <code>None</code> <code>version</code> <code>Optional[str]</code> <p>Optional version number of existing data. If not specified, the most recent version will be used</p> <code>None</code> <code>tags</code> <code>Optional[Dict[str, str]]</code> <p>Dictionary of key, value tags to search for</p> <code>None</code> <code>uid</code> <code>Optional[str]</code> <p>Unique identifier for Card. If present, the uid takes precedence</p> <code>None</code> <code>max_date</code> <code>Optional[str]</code> <p>Max date to search. (e.g. \"2023-05-01\" would search for cards up to and including \"2023-05-01\")</p> <code>None</code> <code>limit</code> <code>Optional[int]</code> <p>Places a limit on result list. Results are sorted by SemVer</p> <code>None</code> <code>info</code> <code>Optional[CardInfo]</code> <p>CardInfo object. If present, the info object takes precedence</p> <code>None</code> <code>ignore_release_candidates</code> <code>bool</code> <p>If True, ignores release candidates</p> <code>False</code> <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>pandas dataframe of records or list of dictionaries</p> Source code in <code>opsml/registry/registry.py</code> <pre><code>def list_cards(\n    self,\n    uid: Optional[str] = None,\n    name: Optional[str] = None,\n    repository: Optional[str] = None,\n    version: Optional[str] = None,\n    tags: Optional[Dict[str, str]] = None,\n    info: Optional[CardInfo] = None,\n    max_date: Optional[str] = None,\n    limit: Optional[int] = None,\n    ignore_release_candidates: bool = False,\n) -&gt; List[Dict[str, Any]]:\n    \"\"\"Retrieves records from registry\n\n    Args:\n        name:\n            Card name\n        repository:\n            Repository associated with card\n        version:\n            Optional version number of existing data. If not specified, the\n            most recent version will be used\n        tags:\n            Dictionary of key, value tags to search for\n        uid:\n            Unique identifier for Card. If present, the uid takes precedence\n        max_date:\n            Max date to search. (e.g. \"2023-05-01\" would search for cards up to and including \"2023-05-01\")\n        limit:\n            Places a limit on result list. Results are sorted by SemVer\n        info:\n            CardInfo object. If present, the info object takes precedence\n        ignore_release_candidates:\n            If True, ignores release candidates\n\n    Returns:\n        pandas dataframe of records or list of dictionaries\n    \"\"\"\n\n    if info is not None:\n        name = name or info.name\n        repository = repository or info.repository\n        uid = uid or info.uid\n        version = version or info.version\n        tags = tags or info.tags\n\n    if name is not None:\n        name = name.lower()\n\n    if repository is not None:\n        repository = repository.lower()\n\n    if all(not bool(var) for var in [name, repository, version, uid, tags]):\n        limit = limit or 25\n\n    card_list = self._registry.list_cards(\n        uid=uid,\n        name=name,\n        repository=repository,\n        version=version,\n        max_date=max_date,\n        limit=limit,\n        tags=tags,\n        ignore_release_candidates=ignore_release_candidates,\n    )\n\n    return card_list\n</code></pre>"},{"location":"cards/overview/#opsml.CardRegistry.load_card","title":"<code>load_card(name=None, repository=None, uid=None, tags=None, version=None, info=None, ignore_release_candidates=False, interface=None)</code>","text":"<p>Loads a specific card</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>Optional[str]</code> <p>Optional Card name</p> <code>None</code> <code>uid</code> <code>Optional[str]</code> <p>Unique identifier for card. If present, the uid takes precedence.</p> <code>None</code> <code>tags</code> <code>Optional[Dict[str, str]]</code> <p>Optional tags associated with model.</p> <code>None</code> <code>repository</code> <code>Optional[str]</code> <p>Optional repository associated with card</p> <code>None</code> <code>version</code> <code>Optional[str]</code> <p>Optional version number of existing data. If not specified, the most recent version will be used</p> <code>None</code> <code>info</code> <code>Optional[CardInfo]</code> <p>Optional CardInfo object. If present, the info takes precedence</p> <code>None</code> <code>ignore_release_candidates</code> <code>bool</code> <p>If True, ignores release candidates</p> <code>False</code> <code>interface</code> <code>Optional[Union[Type[ModelInterface], Type[DataInterface]]]</code> <p>Optional interface to use for loading card. This is required for when using subclassed interfaces.</p> <code>None</code> <p>Returns     ArtifactCard</p> Source code in <code>opsml/registry/registry.py</code> <pre><code>def load_card(\n    self,\n    name: Optional[str] = None,\n    repository: Optional[str] = None,\n    uid: Optional[str] = None,\n    tags: Optional[Dict[str, str]] = None,\n    version: Optional[str] = None,\n    info: Optional[CardInfo] = None,\n    ignore_release_candidates: bool = False,\n    interface: Optional[Union[Type[ModelInterface], Type[DataInterface]]] = None,\n) -&gt; ArtifactCard:\n    \"\"\"Loads a specific card\n\n    Args:\n        name:\n            Optional Card name\n        uid:\n            Unique identifier for card. If present, the uid takes\n            precedence.\n        tags:\n            Optional tags associated with model.\n        repository:\n            Optional repository associated with card\n        version:\n            Optional version number of existing data. If not specified, the\n            most recent version will be used\n        info:\n            Optional CardInfo object. If present, the info takes precedence\n        ignore_release_candidates:\n            If True, ignores release candidates\n        interface:\n            Optional interface to use for loading card. This is required for when using\n            subclassed interfaces.\n\n    Returns\n        ArtifactCard\n    \"\"\"\n\n    # find better way to do this later\n    if info is not None:\n        name = name or info.name\n        uid = uid or info.uid\n        version = version or info.version\n        tags = tags or info.tags\n\n    name = clean_string(name)\n\n    records = self.list_cards(\n        uid=uid,\n        name=name,\n        repository=repository,\n        version=version,\n        tags=tags,\n        ignore_release_candidates=ignore_release_candidates,\n        limit=1,\n    )\n\n    return CardLoader(\n        card_args=records[0],\n        registry_type=self.registry_type,\n    ).load_card(interface=interface)\n</code></pre>"},{"location":"cards/overview/#opsml.CardRegistry.query_value_from_card","title":"<code>query_value_from_card(uid, columns)</code>","text":"<p>Query column values from a specific Card</p> <p>Parameters:</p> Name Type Description Default <code>uid</code> <code>str</code> <p>Uid of Card</p> required <code>columns</code> <code>List[str]</code> <p>List of columns to query</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary of column, values pairs</p> Source code in <code>opsml/registry/registry.py</code> <pre><code>def query_value_from_card(self, uid: str, columns: List[str]) -&gt; Dict[str, Any]:\n    \"\"\"\n    Query column values from a specific Card\n\n    Args:\n        uid:\n            Uid of Card\n        columns:\n            List of columns to query\n\n    Returns:\n        Dictionary of column, values pairs\n    \"\"\"\n    results = self._registry.list_cards(uid=uid)[0]\n    return {col: results[col] for col in columns}\n</code></pre>"},{"location":"cards/overview/#opsml.CardRegistry.register_card","title":"<code>register_card(card, version_type=VersionType.MINOR, pre_tag='rc', build_tag='build')</code>","text":"<p>Adds a new <code>Card</code> record to registry. Registration will be skipped if the card already exists.</p> <p>Parameters:</p> Name Type Description Default <code>card</code> <code>ArtifactCard</code> <p>card to register</p> required <code>version_type</code> <code>Union[VersionType, str]</code> <p>Version type for increment. Options are \"major\", \"minor\" and \"patch\". Defaults to \"minor\".</p> <code>MINOR</code> <code>pre_tag</code> <code>str</code> <p>pre-release tag to add to card version</p> <code>'rc'</code> <code>build_tag</code> <code>str</code> <p>build tag to add to card version</p> <code>'build'</code> Source code in <code>opsml/registry/registry.py</code> <pre><code>def register_card(\n    self,\n    card: ArtifactCard,\n    version_type: Union[VersionType, str] = VersionType.MINOR,\n    pre_tag: str = \"rc\",\n    build_tag: str = \"build\",\n) -&gt; None:\n    \"\"\"\n    Adds a new `Card` record to registry. Registration will be skipped if the card already exists.\n\n    Args:\n        card:\n            card to register\n        version_type:\n            Version type for increment. Options are \"major\", \"minor\" and\n            \"patch\". Defaults to \"minor\".\n        pre_tag:\n            pre-release tag to add to card version\n        build_tag:\n            build tag to add to card version\n    \"\"\"\n\n    _version_type = version_type if isinstance(version_type, VersionType) else VersionType.from_str(version_type)\n\n    if card.uid is not None and card.version != CommonKwargs.BASE_VERSION.value:\n        logger.info(\n            textwrap.dedent(\n                f\"\"\"\n            Card {card.uid} already exists. Skipping registration. If you'd like to register\n            a new card, please instantiate a new Card object. If you'd like to update the\n            existing card, please use the update_card method.\n            \"\"\"\n            )\n        )\n\n    else:\n        self._registry.register_card(\n            card=card,\n            version_type=_version_type,\n            pre_tag=pre_tag,\n            build_tag=build_tag,\n        )\n</code></pre>"},{"location":"cards/overview/#opsml.CardRegistry.update_card","title":"<code>update_card(card)</code>","text":"<p>Update an artifact card based on current registry</p> <p>Parameters:</p> Name Type Description Default <code>card</code> <code>ArtifactCard</code> <p>Card to register</p> required Source code in <code>opsml/registry/registry.py</code> <pre><code>def update_card(self, card: ArtifactCard) -&gt; None:\n    \"\"\"\n    Update an artifact card based on current registry\n\n    Args:\n        card:\n            Card to register\n    \"\"\"\n    return self._registry.update_card(card=card)\n</code></pre>"},{"location":"cards/runcard/","title":"RunCard","text":"<p><code>RunCards</code> are use to store metrics and artifacts related to <code>DataCards</code> and <code>ModelCards</code>. While a RunCard can be used as a object itself, it's best when used as part of a <code>Project</code> run.</p>"},{"location":"cards/runcard/#creating-a-run","title":"Creating A Run","text":"<p>Runs are unique context-managed executions associated with a <code>Project</code> that record all created cards and their associated metrics, params, and artifacts to a single card called a <code>RunCard</code>.</p> <p>The following example shows how to create a simple run as well as use <code>CardInfo</code> to store helper info</p> <pre><code>from sklearn.linear_model import LinearRegression\n\nfrom opsml import (\n    CardInfo,\n    DataCard,\n    DataSplit,\n    ModelCard,\n    OpsmlProject,\n    PandasData,\n    ProjectInfo,\n    SklearnModel,\n)\nfrom opsml.helpers.data import create_fake_data\n\ninfo = ProjectInfo(name=\"opsml-project\", repository=\"opsml\", contact=\"user@email.com\")\n\n# create card info and set NAME, REPOSITORY, and CONTACT as environment variables\ncard_info = CardInfo(name=\"linear-reg\", repository=\"opsml\", contact=\"user@email.com\").set_env()\n\n# create project\nproject = OpsmlProject(info=info)\n\nwith project.run() as run:\n    # create fake data\n    X, y = create_fake_data(n_samples=1000, task_type=\"regression\")\n    X[\"target\"] = y\n\n    # Create data interface\n    data_interface = PandasData(\n        data=X,\n        data_splits=[\n            DataSplit(label=\"train\", column_name=\"col_1\", column_value=0.5, inequality=\"&gt;=\"),\n            DataSplit(label=\"test\", column_name=\"col_1\", column_value=0.5, inequality=\"&lt;\"),\n        ],\n        dependent_vars=[\"target\"],\n    )\n\n    # Create datacard\n    datacard = DataCard(interface=data_interface)\n    run.register_card(card=datacard)\n\n    # split data\n    data = datacard.split_data()\n\n    # fit model\n    reg = LinearRegression()\n    reg.fit(data[\"train\"].X.to_numpy(), data[\"train\"].y.to_numpy())\n\n    # create model interface\n    interface = SklearnModel(model=reg, sample_data=data[\"train\"].X.to_numpy())\n\n    # create modelcard\n    modelcard = ModelCard(interface=interface, to_onnx=True, datacard_uid=datacard.uid)\n\n    # you can log metrics view log_metric or log_metrics\n    run.log_metric(\"test_metric\", 10)\n    run.log_metrics({\"test_metric2\": 20})\n\n    # log parameter\n    run.log_parameter(\"test_parameter\", 10)\n\n    # register modelcard\n    run.register_card(card=modelcard)\n\n    # example of logging artifact to file\n    with Path(\"artifact.txt\").open(\"w\") as f:\n        f.write(\"This is a test\")\n\n    run.log_artifact_from_file(\"artifact\", \"artifact.txt\")\n</code></pre> <p>You can now log into the <code>Opsml</code> server and see your recent run and associated metadata</p>"},{"location":"cards/runcard/#opsml.RunCard","title":"<code>opsml.RunCard</code>","text":"<p>             Bases: <code>ArtifactCard</code></p> <p>Create a RunCard from specified arguments.</p> <p>Apart from required args, a RunCard must be associated with one of datacard_uid, modelcard_uids or pipelinecard_uid</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <p>Run name</p> required <code>repository</code> <p>Repository that this card is associated with</p> required <code>contact</code> <p>Contact to associate with card</p> required <code>info</code> <p><code>CardInfo</code> object containing additional metadata. If provided, it will override any values provided for <code>name</code>, <code>repository</code>, <code>contact</code>, and <code>version</code>.</p> <p>Name, repository, and contact are required arguments for all cards. They can be provided directly or through a <code>CardInfo</code> object.</p> required <code>datacard_uids</code> <p>Optional DataCard uids associated with this run</p> required <code>modelcard_uids</code> <p>Optional List of ModelCard uids to associate with this run</p> required <code>pipelinecard_uid</code> <p>Optional PipelineCard uid to associate with this experiment</p> required <code>metrics</code> <p>Optional dictionary of key (str), value (int, float) metric paris. Metrics can also be added via class methods.</p> required <code>parameters</code> <p>Parameters associated with a RunCard</p> required <code>artifact_uris</code> <p>Optional dictionary of artifact uris associated with artifacts.</p> required <code>uid</code> <p>Unique id (assigned if card has been registered)</p> required <code>version</code> <p>Current version (assigned if card has been registered)</p> required Source code in <code>opsml/cards/run.py</code> <pre><code>class RunCard(ArtifactCard):\n    \"\"\"\n    Create a RunCard from specified arguments.\n\n    Apart from required args, a RunCard must be associated with one of\n    datacard_uid, modelcard_uids or pipelinecard_uid\n\n    Args:\n        name:\n            Run name\n        repository:\n            Repository that this card is associated with\n        contact:\n            Contact to associate with card\n        info:\n            `CardInfo` object containing additional metadata. If provided, it will override any\n            values provided for `name`, `repository`, `contact`, and `version`.\n\n            Name, repository, and contact are required arguments for all cards. They can be provided\n            directly or through a `CardInfo` object.\n\n        datacard_uids:\n            Optional DataCard uids associated with this run\n        modelcard_uids:\n            Optional List of ModelCard uids to associate with this run\n        pipelinecard_uid:\n            Optional PipelineCard uid to associate with this experiment\n        metrics:\n            Optional dictionary of key (str), value (int, float) metric paris.\n            Metrics can also be added via class methods.\n        parameters:\n            Parameters associated with a RunCard\n        artifact_uris:\n            Optional dictionary of artifact uris associated with artifacts.\n        uid:\n            Unique id (assigned if card has been registered)\n        version:\n            Current version (assigned if card has been registered)\n\n    \"\"\"\n\n    datacard_uids: List[str] = []\n    modelcard_uids: List[str] = []\n    pipelinecard_uid: Optional[str] = None\n    metrics: Metrics = {}\n    parameters: Params = {}\n    artifact_uris: ArtifactUris = {}\n    tags: Dict[str, Union[str, int]] = {}\n    project: Optional[str] = None\n\n    @model_validator(mode=\"before\")\n    @classmethod\n    def validate_defaults_args(cls, card_args: Dict[str, Any]) -&gt; Dict[str, Any]:\n        # add default\n        contact = card_args.get(\"contact\")\n\n        if contact is None:\n            card_args[\"contact\"] = CommonKwargs.UNDEFINED.value\n\n        repository = card_args.get(\"repository\")\n\n        if repository is None:\n            card_args[\"repository\"] = \"opsml\"\n\n        return card_args\n\n    def add_tag(self, key: str, value: str) -&gt; None:\n        \"\"\"\n        Logs tags to current RunCard\n\n        Args:\n            key:\n                Key for tag\n            value:\n                value for tag\n        \"\"\"\n        self.tags = {**{key: value}, **self.tags}\n\n    def add_tags(self, tags: Dict[str, str]) -&gt; None:\n        \"\"\"\n        Logs tags to current RunCard\n\n        Args:\n            tags:\n                Dictionary of tags\n        \"\"\"\n        self.tags = {**tags, **self.tags}\n\n    def log_graph(\n        self,\n        name: str,\n        x: Union[List[Union[float, int]], NDArray[Any]],\n        y: Union[List[Union[float, int]], NDArray[Any], Dict[str, Union[List[Union[float, int]], NDArray[Any]]]],\n        y_label: str,\n        x_label: str,\n        graph_style: str,\n    ) -&gt; None:\n        \"\"\"Logs a graph to the RunCard, which will be rendered in the UI as a line graph\n\n        Args:\n            name:\n                Name of graph\n            x:\n                List or numpy array of x values\n\n            x_label:\n                Label for x axis\n            y:\n                Either a list or numpy array of y values or a dictionary of y values where key is the group label and\n                value is a list or numpy array of y values\n            y_label:\n                Label for y axis\n            graph_style:\n                Style of graph. Options are \"line\" or \"scatter\"\n\n        example:\n\n            ### single line graph\n            x = np.arange(1, 400, 0.5)\n            y = x * x\n            run.log_graph(name=\"graph1\", x=x, y=y, x_label=\"x\", y_label=\"y\", graph_style=\"line\")\n\n            ### multi line graph\n            x = np.arange(1, 1000, 0.5)\n            y1 = x * x\n            y2 = y1 * 1.1\n            y3 = y2 * 3\n            run.log_graph(\n                name=\"multiline\",\n                x=x,\n                y={\"y1\": y1, \"y2\": y2, \"y3\": y3},\n                x_label=\"x\",\n                y_label=\"y\",\n                graph_style=\"line\",\n            )\n\n        \"\"\"\n\n        if isinstance(x, np.ndarray):\n            x = x.flatten().tolist()\n            assert isinstance(x, list), \"x must be a list or dictionary\"\n\n        x = _decimate_list(x)\n\n        parsed_y, graph_type = _parse_y_to_list(len(x), y)\n\n        logger.info(f\"Logging graph {name} to RunCard\")\n        graph = RunGraph(\n            name=name,\n            x=x,\n            x_label=x_label,\n            y=parsed_y,\n            y_label=y_label,\n            graph_type=graph_type,\n            graph_style=GraphStyle.from_str(graph_style).value,  # validate graph style\n        )\n\n        # save graph to storage so we can view in ui while run is active\n        lpath, rpath = _dump_graph_artifact(graph, name, self.uri)\n\n        self._add_artifact_uri(\n            name=name,\n            local_path=lpath.as_posix(),\n            remote_path=rpath.as_posix(),\n        )\n\n    def log_parameters(self, parameters: Dict[str, Union[float, int, str]]) -&gt; None:\n        \"\"\"\n        Logs parameters to current RunCard\n\n        Args:\n            parameters:\n                Dictionary of parameters\n        \"\"\"\n\n        for key, value in parameters.items():\n            # check key\n            self.log_parameter(key, value)\n\n    def log_parameter(self, key: str, value: Union[int, float, str]) -&gt; None:\n        \"\"\"\n        Logs parameter to current RunCard\n\n        Args:\n            key:\n                Param name\n            value:\n                Param value\n        \"\"\"\n\n        TypeChecker.check_param_type(param=value)\n        _key = TypeChecker.replace_spaces(key)\n\n        param = Param(name=key, value=value)\n\n        if self.parameters.get(_key) is not None:\n            self.parameters[_key].append(param)\n\n        else:\n            self.parameters[_key] = [param]\n\n    def log_metric(\n        self,\n        key: str,\n        value: Union[int, float],\n        timestamp: Optional[int] = None,\n        step: Optional[int] = None,\n    ) -&gt; None:\n        \"\"\"\n        Logs metric to the existing RunCard metric dictionary\n\n        Args:\n            key:\n                Metric name\n            value:\n                Metric value\n            timestamp:\n                Optional timestamp\n            step:\n                Optional step associated with name and value\n        \"\"\"\n\n        TypeChecker.check_metric_type(metric=value)\n        _key = TypeChecker.replace_spaces(key)\n\n        metric = Metric(name=_key, value=value, timestamp=timestamp, step=step)\n\n        self._registry.insert_metric([{**metric.model_dump(), **{\"run_uid\": self.uid}}])\n\n        if self.metrics.get(_key) is not None:\n            self.metrics[_key].append(metric)\n        else:\n            self.metrics[_key] = [metric]\n\n    def log_metrics(self, metrics: Dict[str, Union[float, int]], step: Optional[int] = None) -&gt; None:\n        \"\"\"\n        Log metrics to the existing RunCard metric dictionary\n\n        Args:\n            metrics:\n                Dictionary containing key (str) and value (float or int) pairs\n                to add to the current metric set\n            step:\n                Optional step associated with metrics\n        \"\"\"\n\n        for key, value in metrics.items():\n            self.log_metric(key, value, step)\n\n    def log_artifact_from_file(\n        self,\n        name: str,\n        local_path: Union[str, Path],\n        artifact_path: Optional[Union[str, Path]] = None,\n    ) -&gt; None:\n        \"\"\"\n        Log a local file or directory to the opsml server and associate with the current run.\n\n        Args:\n            name:\n                Name to assign to artifact(s)\n            local_path:\n                Local path to file or directory. Can be string or pathlike object\n            artifact_path:\n                Optional path to store artifact in opsml server. If not provided, 'artifacts' will be used\n        \"\"\"\n\n        lpath = Path(local_path)\n        rpath = self.uri / (artifact_path or SaveName.ARTIFACTS.value)\n\n        if lpath.is_file():\n            rpath = rpath / lpath.name\n\n        client.storage_client.put(lpath, rpath)\n        self._add_artifact_uri(\n            name=name,\n            local_path=lpath.as_posix(),\n            remote_path=rpath.as_posix(),\n        )\n\n    def create_registry_record(self) -&gt; Dict[str, Any]:\n        \"\"\"Creates a registry record from the current RunCard\"\"\"\n\n        exclude_attr = {\"parameters\", \"metrics\"}\n\n        return self.model_dump(exclude=exclude_attr)\n\n    def _add_artifact_uri(self, name: str, local_path: str, remote_path: str) -&gt; None:\n        \"\"\"\n        Adds an artifact_uri to the runcard\n\n        Args:\n            name:\n                Name to associate with artifact\n            uri:\n                Uri where artifact is stored\n        \"\"\"\n\n        self.artifact_uris[name] = Artifact(\n            name=name,\n            local_path=local_path,\n            remote_path=remote_path,\n        )\n\n    def add_card_uid(self, card_type: str, uid: str) -&gt; None:\n        \"\"\"\n        Adds a card uid to the appropriate card uid list for tracking\n\n        Args:\n            card_type:\n                ArtifactCard class name\n            uid:\n                Uid of registered ArtifactCard\n        \"\"\"\n\n        if card_type == CardType.DATACARD:\n            self.datacard_uids = [uid, *self.datacard_uids]\n        elif card_type == CardType.MODELCARD:\n            self.modelcard_uids = [uid, *self.modelcard_uids]\n\n    def get_metric(self, name: str) -&gt; Union[List[Metric], Metric]:\n        \"\"\"\n        Gets a metric by name\n\n        Args:\n            name:\n                Name of metric\n\n        Returns:\n            List of dictionaries or dictionary containing value\n\n        \"\"\"\n        _key = TypeChecker.replace_spaces(name)\n\n        metric = self.metrics.get(_key)\n\n        if metric is None:\n            # try to get metric from registry\n            assert self.uid is not None, \"RunCard must be registered to get metric\"\n            _metric = self._registry.get_metric(run_uid=self.uid, name=[_key])\n\n            if _metric is not None:\n                metric = [Metric(**i) for i in _metric]\n\n            else:\n                raise ValueError(f\"Metric {metric} was not defined\")\n\n        if len(metric) &gt; 1:\n            return metric\n        if len(metric) == 1:\n            return metric[0]\n        return metric\n\n    def load_metrics(self) -&gt; None:\n        \"\"\"Reloads metrics from registry\"\"\"\n        assert self.uid is not None, \"RunCard must be registered to load metrics\"\n\n        metrics = self._registry.get_metric(run_uid=self.uid)\n\n        if metrics is None:\n            logger.info(\"No metrics found for RunCard\")\n            return None\n\n        # reset metrics\n        self.metrics = {}\n        for metric in metrics:\n            _metric = Metric(**metric)\n            if _metric.name not in self.metrics:\n                self.metrics[_metric.name] = [_metric]\n            else:\n                self.metrics[_metric.name].append(_metric)\n        return None\n\n    def get_parameter(self, name: str) -&gt; Union[List[Param], Param]:\n        \"\"\"\n        Gets a parameter by name\n\n        Args:\n            name:\n                Name of parameter\n\n        Returns:\n            List of dictionaries or dictionary containing value\n\n        \"\"\"\n        _key = TypeChecker.replace_spaces(name)\n        param = self.parameters.get(_key)\n        if param is not None:\n            if len(param) &gt; 1:\n                return param\n            if len(param) == 1:\n                return param[0]\n            return param\n\n        raise ValueError(f\"Param {param} is not defined\")\n\n    def load_artifacts(self, name: Optional[str] = None) -&gt; None:\n        \"\"\"Loads artifacts from artifact_uris\"\"\"\n        if bool(self.artifact_uris) is False:\n            logger.info(\"No artifact uris associated with RunCard\")\n            return None\n\n        if name is not None:\n            artifact = self.artifact_uris.get(name)\n            assert artifact is not None, f\"Artifact {name} not found\"\n            client.storage_client.get(\n                Path(artifact.remote_path),\n                Path(artifact.local_path),\n            )\n\n        else:\n            for _, artifact in self.artifact_uris.items():\n                client.storage_client.get(\n                    Path(artifact.remote_path),\n                    Path(artifact.local_path),\n                )\n        return None\n\n    @property\n    def uri(self) -&gt; Path:\n        \"\"\"The base URI to use for the card and it's artifacts.\"\"\"\n\n        # when using runcard outside of run context\n        if self.version == CommonKwargs.BASE_VERSION.value:\n            if self.uid is None:\n                self.uid = uuid.uuid4().hex\n\n            end_path = self.uid\n        else:\n            end_path = f\"v{self.version}\"\n\n        return Path(\n            config.storage_root,\n            RegistryTableNames.from_str(self.card_type).value,\n            str(self.repository),\n            str(self.name),\n            end_path,\n        )\n\n    @cached_property\n    def _registry(self) -&gt; RunCardRegistry:\n        from opsml.registry.backend import _set_registry\n\n        return cast(RunCardRegistry, _set_registry(RegistryType.RUN))\n\n    @property\n    def card_type(self) -&gt; str:\n        return CardType.RUNCARD.value\n</code></pre>"},{"location":"cards/runcard/#opsml.RunCard.add_tag","title":"<code>add_tag(key, value)</code>","text":"<p>Logs tags to current RunCard</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Key for tag</p> required <code>value</code> <code>str</code> <p>value for tag</p> required Source code in <code>opsml/cards/run.py</code> <pre><code>def add_tag(self, key: str, value: str) -&gt; None:\n    \"\"\"\n    Logs tags to current RunCard\n\n    Args:\n        key:\n            Key for tag\n        value:\n            value for tag\n    \"\"\"\n    self.tags = {**{key: value}, **self.tags}\n</code></pre>"},{"location":"cards/runcard/#opsml.RunCard.add_tags","title":"<code>add_tags(tags)</code>","text":"<p>Logs tags to current RunCard</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>Dict[str, str]</code> <p>Dictionary of tags</p> required Source code in <code>opsml/cards/run.py</code> <pre><code>def add_tags(self, tags: Dict[str, str]) -&gt; None:\n    \"\"\"\n    Logs tags to current RunCard\n\n    Args:\n        tags:\n            Dictionary of tags\n    \"\"\"\n    self.tags = {**tags, **self.tags}\n</code></pre>"},{"location":"cards/runcard/#opsml.RunCard.log_parameter","title":"<code>log_parameter(key, value)</code>","text":"<p>Logs parameter to current RunCard</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Param name</p> required <code>value</code> <code>Union[int, float, str]</code> <p>Param value</p> required Source code in <code>opsml/cards/run.py</code> <pre><code>def log_parameter(self, key: str, value: Union[int, float, str]) -&gt; None:\n    \"\"\"\n    Logs parameter to current RunCard\n\n    Args:\n        key:\n            Param name\n        value:\n            Param value\n    \"\"\"\n\n    TypeChecker.check_param_type(param=value)\n    _key = TypeChecker.replace_spaces(key)\n\n    param = Param(name=key, value=value)\n\n    if self.parameters.get(_key) is not None:\n        self.parameters[_key].append(param)\n\n    else:\n        self.parameters[_key] = [param]\n</code></pre>"},{"location":"cards/runcard/#opsml.RunCard.log_parameters","title":"<code>log_parameters(parameters)</code>","text":"<p>Logs parameters to current RunCard</p> <p>Parameters:</p> Name Type Description Default <code>parameters</code> <code>Dict[str, Union[float, int, str]]</code> <p>Dictionary of parameters</p> required Source code in <code>opsml/cards/run.py</code> <pre><code>def log_parameters(self, parameters: Dict[str, Union[float, int, str]]) -&gt; None:\n    \"\"\"\n    Logs parameters to current RunCard\n\n    Args:\n        parameters:\n            Dictionary of parameters\n    \"\"\"\n\n    for key, value in parameters.items():\n        # check key\n        self.log_parameter(key, value)\n</code></pre>"},{"location":"cards/runcard/#opsml.RunCard.log_metric","title":"<code>log_metric(key, value, timestamp=None, step=None)</code>","text":"<p>Logs metric to the existing RunCard metric dictionary</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Metric name</p> required <code>value</code> <code>Union[int, float]</code> <p>Metric value</p> required <code>timestamp</code> <code>Optional[int]</code> <p>Optional timestamp</p> <code>None</code> <code>step</code> <code>Optional[int]</code> <p>Optional step associated with name and value</p> <code>None</code> Source code in <code>opsml/cards/run.py</code> <pre><code>def log_metric(\n    self,\n    key: str,\n    value: Union[int, float],\n    timestamp: Optional[int] = None,\n    step: Optional[int] = None,\n) -&gt; None:\n    \"\"\"\n    Logs metric to the existing RunCard metric dictionary\n\n    Args:\n        key:\n            Metric name\n        value:\n            Metric value\n        timestamp:\n            Optional timestamp\n        step:\n            Optional step associated with name and value\n    \"\"\"\n\n    TypeChecker.check_metric_type(metric=value)\n    _key = TypeChecker.replace_spaces(key)\n\n    metric = Metric(name=_key, value=value, timestamp=timestamp, step=step)\n\n    self._registry.insert_metric([{**metric.model_dump(), **{\"run_uid\": self.uid}}])\n\n    if self.metrics.get(_key) is not None:\n        self.metrics[_key].append(metric)\n    else:\n        self.metrics[_key] = [metric]\n</code></pre>"},{"location":"cards/runcard/#opsml.RunCard.log_metrics","title":"<code>log_metrics(metrics, step=None)</code>","text":"<p>Log metrics to the existing RunCard metric dictionary</p> <p>Parameters:</p> Name Type Description Default <code>metrics</code> <code>Dict[str, Union[float, int]]</code> <p>Dictionary containing key (str) and value (float or int) pairs to add to the current metric set</p> required <code>step</code> <code>Optional[int]</code> <p>Optional step associated with metrics</p> <code>None</code> Source code in <code>opsml/cards/run.py</code> <pre><code>def log_metrics(self, metrics: Dict[str, Union[float, int]], step: Optional[int] = None) -&gt; None:\n    \"\"\"\n    Log metrics to the existing RunCard metric dictionary\n\n    Args:\n        metrics:\n            Dictionary containing key (str) and value (float or int) pairs\n            to add to the current metric set\n        step:\n            Optional step associated with metrics\n    \"\"\"\n\n    for key, value in metrics.items():\n        self.log_metric(key, value, step)\n</code></pre>"},{"location":"cards/runcard/#opsml.projects.OpsmlProject","title":"<code>opsml.projects.OpsmlProject</code>","text":"Source code in <code>opsml/projects/project.py</code> <pre><code>class OpsmlProject:\n    def __init__(self, info: ProjectInfo):\n        \"\"\"\n        Instantiates a project which creates cards, metrics and parameters to\n        the opsml registry via a \"run\" object.\n\n        If info.run_id is set, that run_id will be loaded as read only. In read\n        only mode, you can retrieve cards, metrics, and parameters, however you\n        cannot write new data. If you wish to record data/create a new run, you will\n        need to enter the run context.\n\n        In order to create new cards, you need to create a run using the `run`\n        context manager.\n\n        Example:\n\n            project: OpsmlProject = OpsmlProject(\n                ProjectInfo(\n                    name=\"test-project\",\n                    # If run_id is omitted, a new run is created.\n                    run_id=\"123ab123kaj8u8naskdfh813\",\n                )\n            )\n            # the project is in \"read only\" mode. all read operations will work\n            for k, v in project.parameters:\n                logger.info(\"{} = {}\", k, v)\n\n            # creating a project run\n            with project.run() as run:\n                # Now that the run context is entered, it's in read/write mode\n                # You can write cards, parameters, and metrics to the project.\n                run.log_parameter(key=\"my_param\", value=\"12.34\")\n\n        Args:\n            info:\n                Run information. if a run_id is given, that run is set\n                as the project's current run.\n        \"\"\"\n        # Set the run manager and project_id (creates ProjectCard if project doesn't exist)\n        registrar = _ProjectRegistrar(project_info=info)\n\n        # get project id or register new project\n        info.project_id = registrar.register_project()\n\n        # crete run manager\n        self._run_mgr = _RunManager(project_info=info, registries=registrar.registries)\n\n    @property\n    def run_id(self) -&gt; str:\n        \"\"\"Current run id associated with project\"\"\"\n        if self._run_mgr.run_id is not None:\n            return self._run_mgr.run_id\n        raise ValueError(\"Run id not set for current project\")\n\n    @run_id.setter\n    def run_id(self, run_id: str) -&gt; None:\n        \"\"\"Set the run_id to use with the active project\"\"\"\n        self._run_mgr.run_id = run_id\n\n    @property\n    def project_id(self) -&gt; int:\n        return self._run_mgr.project_id\n\n    @property\n    def project_name(self) -&gt; str:\n        return self._run_mgr._project_info.name  # pylint: disable=protected-access\n\n    @contextmanager\n    def run(self, run_name: Optional[str] = None) -&gt; Iterator[ActiveRun]:\n        \"\"\"\n        Starts a new run for the project\n\n        Args:\n            run_name:\n                Optional run name\n        \"\"\"\n\n        try:\n            yield self._run_mgr.start_run(run_name=run_name)  # self._run_mgr.active_run\n\n        except ActiveRunException as error:\n            logger.error(\"Run already active. Ending run.\")\n            raise error\n\n        except Exception as error:\n            logger.error(\"Error encountered. Ending run. {}\", error)\n            self._run_mgr.end_run()\n            raise error\n\n        self._run_mgr.end_run()\n\n    def load_card(self, registry_name: str, info: CardInfo) -&gt; ArtifactCard:\n        \"\"\"\n        Loads an ArtifactCard.\n\n        Args:\n            registry_name:\n                Name of registry to load card from\n            info:\n                Card information to retrieve. `uid` takes precedence if it\n                exists. If the optional `version` is specified, that version\n                will be loaded. If it doesn't exist, the most recent ersion will\n                be loaded.\n\n        Returns\n            `ArtifactCard`\n        \"\"\"\n        card_type = CardType(registry_name.lower()).value\n        return CardHandler.load_card(\n            registries=self._run_mgr.registries,\n            registry_name=card_type,\n            info=info,\n        )\n\n    def list_runs(self, limit: int = 100) -&gt; List[Dict[str, Any]]:\n        \"\"\"\n        Lists all runs for the current project, sorted by timestamp\n\n        Returns:\n            List of RunCard\n        \"\"\"\n        logger.info(\"Listing runs for project {}\", self.project_name)\n\n        project_runs = self._run_mgr.registries.run._registry.list_cards(  # pylint: disable=protected-access\n            limit=limit,\n            query_terms={\"project\": self.project_name},\n        )\n\n        return sorted(project_runs, key=lambda k: k[\"timestamp\"], reverse=True)\n\n    @property\n    def runcard(self) -&gt; RunCard:\n        return cast(RunCard, self._run_mgr.registries.run.load_card(uid=self.run_id))\n\n    @property\n    def metrics(self) -&gt; Metrics:\n        runcard = self.runcard\n        runcard.load_metrics()\n        return runcard.metrics\n\n    def get_metric(self, name: str) -&gt; Union[List[Metric], Metric]:\n        \"\"\"\n        Get metric by name\n\n        Args:\n            name: str\n\n        Returns:\n            List of Metric or Metric\n\n        \"\"\"\n        return self.runcard.get_metric(name=name)\n\n    @property\n    def parameters(self) -&gt; Params:\n        return self.runcard.parameters\n\n    def get_parameter(self, name: str) -&gt; Union[List[Param], Param]:\n        \"\"\"\n        Get param by name\n\n        Args:\n            name: str\n\n        Returns:\n            List of Param or Param\n\n        \"\"\"\n        return self.runcard.get_parameter(name=name)\n\n    @property\n    def tags(self) -&gt; Dict[str, Union[str, int]]:\n        return self.runcard.tags\n\n    @property\n    def datacard_uids(self) -&gt; List[str]:\n        \"\"\"DataCards associated with the current run\"\"\"\n        return self.runcard.datacard_uids\n\n    @property\n    def modelcard_uids(self) -&gt; List[str]:\n        \"\"\"ModelCards associated with the current run\"\"\"\n        return self.runcard.modelcard_uids\n</code></pre>"},{"location":"cards/runcard/#opsml.projects.OpsmlProject.datacard_uids","title":"<code>datacard_uids: List[str]</code>  <code>property</code>","text":"<p>DataCards associated with the current run</p>"},{"location":"cards/runcard/#opsml.projects.OpsmlProject.modelcard_uids","title":"<code>modelcard_uids: List[str]</code>  <code>property</code>","text":"<p>ModelCards associated with the current run</p>"},{"location":"cards/runcard/#opsml.projects.OpsmlProject.run_id","title":"<code>run_id: str</code>  <code>property</code> <code>writable</code>","text":"<p>Current run id associated with project</p>"},{"location":"cards/runcard/#opsml.projects.OpsmlProject.__init__","title":"<code>__init__(info)</code>","text":"<p>Instantiates a project which creates cards, metrics and parameters to the opsml registry via a \"run\" object.</p> <p>If info.run_id is set, that run_id will be loaded as read only. In read only mode, you can retrieve cards, metrics, and parameters, however you cannot write new data. If you wish to record data/create a new run, you will need to enter the run context.</p> <p>In order to create new cards, you need to create a run using the <code>run</code> context manager.</p> <p>Example:</p> <pre><code>project: OpsmlProject = OpsmlProject(\n    ProjectInfo(\n        name=\"test-project\",\n        # If run_id is omitted, a new run is created.\n        run_id=\"123ab123kaj8u8naskdfh813\",\n    )\n)\n# the project is in \"read only\" mode. all read operations will work\nfor k, v in project.parameters:\n    logger.info(\"{} = {}\", k, v)\n\n# creating a project run\nwith project.run() as run:\n    # Now that the run context is entered, it's in read/write mode\n    # You can write cards, parameters, and metrics to the project.\n    run.log_parameter(key=\"my_param\", value=\"12.34\")\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>info</code> <code>ProjectInfo</code> <p>Run information. if a run_id is given, that run is set as the project's current run.</p> required Source code in <code>opsml/projects/project.py</code> <pre><code>def __init__(self, info: ProjectInfo):\n    \"\"\"\n    Instantiates a project which creates cards, metrics and parameters to\n    the opsml registry via a \"run\" object.\n\n    If info.run_id is set, that run_id will be loaded as read only. In read\n    only mode, you can retrieve cards, metrics, and parameters, however you\n    cannot write new data. If you wish to record data/create a new run, you will\n    need to enter the run context.\n\n    In order to create new cards, you need to create a run using the `run`\n    context manager.\n\n    Example:\n\n        project: OpsmlProject = OpsmlProject(\n            ProjectInfo(\n                name=\"test-project\",\n                # If run_id is omitted, a new run is created.\n                run_id=\"123ab123kaj8u8naskdfh813\",\n            )\n        )\n        # the project is in \"read only\" mode. all read operations will work\n        for k, v in project.parameters:\n            logger.info(\"{} = {}\", k, v)\n\n        # creating a project run\n        with project.run() as run:\n            # Now that the run context is entered, it's in read/write mode\n            # You can write cards, parameters, and metrics to the project.\n            run.log_parameter(key=\"my_param\", value=\"12.34\")\n\n    Args:\n        info:\n            Run information. if a run_id is given, that run is set\n            as the project's current run.\n    \"\"\"\n    # Set the run manager and project_id (creates ProjectCard if project doesn't exist)\n    registrar = _ProjectRegistrar(project_info=info)\n\n    # get project id or register new project\n    info.project_id = registrar.register_project()\n\n    # crete run manager\n    self._run_mgr = _RunManager(project_info=info, registries=registrar.registries)\n</code></pre>"},{"location":"cards/runcard/#opsml.projects.OpsmlProject.get_metric","title":"<code>get_metric(name)</code>","text":"<p>Get metric by name</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>str</p> required <p>Returns:</p> Type Description <code>Union[List[Metric], Metric]</code> <p>List of Metric or Metric</p> Source code in <code>opsml/projects/project.py</code> <pre><code>def get_metric(self, name: str) -&gt; Union[List[Metric], Metric]:\n    \"\"\"\n    Get metric by name\n\n    Args:\n        name: str\n\n    Returns:\n        List of Metric or Metric\n\n    \"\"\"\n    return self.runcard.get_metric(name=name)\n</code></pre>"},{"location":"cards/runcard/#opsml.projects.OpsmlProject.get_parameter","title":"<code>get_parameter(name)</code>","text":"<p>Get param by name</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>str</p> required <p>Returns:</p> Type Description <code>Union[List[Param], Param]</code> <p>List of Param or Param</p> Source code in <code>opsml/projects/project.py</code> <pre><code>def get_parameter(self, name: str) -&gt; Union[List[Param], Param]:\n    \"\"\"\n    Get param by name\n\n    Args:\n        name: str\n\n    Returns:\n        List of Param or Param\n\n    \"\"\"\n    return self.runcard.get_parameter(name=name)\n</code></pre>"},{"location":"cards/runcard/#opsml.projects.OpsmlProject.list_runs","title":"<code>list_runs(limit=100)</code>","text":"<p>Lists all runs for the current project, sorted by timestamp</p> <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>List of RunCard</p> Source code in <code>opsml/projects/project.py</code> <pre><code>def list_runs(self, limit: int = 100) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Lists all runs for the current project, sorted by timestamp\n\n    Returns:\n        List of RunCard\n    \"\"\"\n    logger.info(\"Listing runs for project {}\", self.project_name)\n\n    project_runs = self._run_mgr.registries.run._registry.list_cards(  # pylint: disable=protected-access\n        limit=limit,\n        query_terms={\"project\": self.project_name},\n    )\n\n    return sorted(project_runs, key=lambda k: k[\"timestamp\"], reverse=True)\n</code></pre>"},{"location":"cards/runcard/#opsml.projects.OpsmlProject.load_card","title":"<code>load_card(registry_name, info)</code>","text":"<p>Loads an ArtifactCard.</p> <p>Parameters:</p> Name Type Description Default <code>registry_name</code> <code>str</code> <p>Name of registry to load card from</p> required <code>info</code> <code>CardInfo</code> <p>Card information to retrieve. <code>uid</code> takes precedence if it exists. If the optional <code>version</code> is specified, that version will be loaded. If it doesn't exist, the most recent ersion will be loaded.</p> required <p>Returns     <code>ArtifactCard</code></p> Source code in <code>opsml/projects/project.py</code> <pre><code>def load_card(self, registry_name: str, info: CardInfo) -&gt; ArtifactCard:\n    \"\"\"\n    Loads an ArtifactCard.\n\n    Args:\n        registry_name:\n            Name of registry to load card from\n        info:\n            Card information to retrieve. `uid` takes precedence if it\n            exists. If the optional `version` is specified, that version\n            will be loaded. If it doesn't exist, the most recent ersion will\n            be loaded.\n\n    Returns\n        `ArtifactCard`\n    \"\"\"\n    card_type = CardType(registry_name.lower()).value\n    return CardHandler.load_card(\n        registries=self._run_mgr.registries,\n        registry_name=card_type,\n        info=info,\n    )\n</code></pre>"},{"location":"cards/runcard/#opsml.projects.OpsmlProject.run","title":"<code>run(run_name=None)</code>","text":"<p>Starts a new run for the project</p> <p>Parameters:</p> Name Type Description Default <code>run_name</code> <code>Optional[str]</code> <p>Optional run name</p> <code>None</code> Source code in <code>opsml/projects/project.py</code> <pre><code>@contextmanager\ndef run(self, run_name: Optional[str] = None) -&gt; Iterator[ActiveRun]:\n    \"\"\"\n    Starts a new run for the project\n\n    Args:\n        run_name:\n            Optional run name\n    \"\"\"\n\n    try:\n        yield self._run_mgr.start_run(run_name=run_name)  # self._run_mgr.active_run\n\n    except ActiveRunException as error:\n        logger.error(\"Run already active. Ending run.\")\n        raise error\n\n    except Exception as error:\n        logger.error(\"Error encountered. Ending run. {}\", error)\n        self._run_mgr.end_run()\n        raise error\n\n    self._run_mgr.end_run()\n</code></pre>"},{"location":"cards/versioning/","title":"Versioning","text":"<p>All <code>ArtifactCards</code> follow a Semver version format (<code>major.minor.patch</code>). By default, a <code>minor</code> increment is used whenever a card is registered. If a version is provided, it overrides the default version type.</p> <p>Cards can also be versioned as a release candidate and/or attached with a build tag (you can use default or provide your own tags when registering a card).</p> <ul> <li> <p>Release candidate -&gt; <code>major.minor.patch-rc.{#}</code> -&gt; <code>1.0.0-rc.1</code> -&gt; version_type: \"pre\"</p> </li> <li> <p>Build tag -&gt; <code>major.minor.patch+build.{#}</code> -&gt; <code>1.0.0+build.1</code> -&gt; version_type: \"build\"</p> </li> <li> <p>Release candidate with build tag -&gt; <code>major.minor.patch-rc.{#}+build.{#}</code> -&gt; <code>1.0.0-rc.1+build.1</code> -&gt; version_type: \"pre_build\"</p> </li> </ul>"},{"location":"cards/versioning/#recommended-flow","title":"Recommended Flow","text":"<ul> <li>The ability to provide <code>version</code> is only an option to enable flexibility; it is not required. The recommended approach if you don't need release candidates or extra flexibility is to create a <code>Card</code> and specify the <code>version_type</code> when registering a card, which will allow <code>OpsML</code> to handle the versioning for you. </li> </ul> <pre><code>modelcard = ModelCard(\n    name=\"model\", \n    repository=\"opsml\", \n    interface=model_interface,\n    datacard_uid=datacard.uid,\n    )\n\nmodel_registry.register_card(\n    card=modelcard, \n    version_type=\"patch\",\n    )\n# let OpsML take care of figuring out the version\n</code></pre>"},{"location":"cards/versioning/#rules-for-release-candidates-and-build-tags","title":"Rules for release candidates and build tags:","text":"<ol> <li>A full <code>major.minor.patch</code> version must be specified in the card.</li> <li><code>version_type</code> must be either <code>pre</code>, <code>build</code> or <code>pre_build</code>.</li> <li>Supply custom tags to either <code>pre_tag</code> or <code>build_tag</code> if you prefer to override defaults.</li> <li><code>build-tags</code> are allowed to be attached to \"official\" <code>major.minor.patch</code> versions. Thus, it's possible to have <code>1.0.0</code> and <code>1.0.0+build.1</code> as valid versions in the registry. In this scenario <code>1.0.0+build.1</code> would be given precedence when listing or loading a card.</li> </ol> <pre><code>card = ModelCard(**kwargs, version=\"1.0.0\")\nregistry.register_card(card=card, version_type=\"pre\", pre_tag=\"foo\")\n# 1.0.0-foo.1\n</code></pre> <ol> <li>Registering a card with the same information (above) will increment the pre-release and/or build tag.</li> <li>Incrementing a pre-release tag resets the build tag counter.</li> <li>If a card is registered with a <code>major</code>, <code>minor</code> or <code>patch</code> increment and there are only pre-release or build candidates associated with the respective <code>major.minor.patch</code> the version will be incremented to the corresponding <code>valid</code> version.</li> </ol> <pre><code># 1st rc\ncard = DataCard(**kwargs, version=\"1.0.0\")\nregistry.register_card(card=card, version_type=\"pre\")\n# 1.0.0-rc.1\n\n#2nd rc\ncard = DataCard(**kwargs, version=\"1.0.0\")\nregistry.register_card(card=card, version_type=\"pre\")\n# 1.0.0-rc.2\n\n\n#Official\ncard = DataCard(**kwargs)\nregistry.register_card(card=card)\n# 1.0.0\n</code></pre> <p>All Cards accept manual insertion of <code>major.minor.patch</code>, <code>major.minor</code> or <code>major</code>. If a version is supplied, <code>opsml</code> will search the associated registry for the latest version that matches the supplied version. As an example, if the latest registered version of a card is <code>1.2.0</code> and a new card is registered with a version specified as <code>1.2</code> and a <code>version_type</code> of <code>patch</code>, <code>opsml</code> will increment the version to <code>1.2.1</code>.</p> <p>Example: <pre><code>card = DataCard(**kwargs)\nregistry.register_card(card=card)\n# 1.2.0\n\ncard = DataCard(**kwargs, version=\"1.2\")\nregistry.register_card(card=card, version_type=\"patch\")\n# 1.2.1\n</code></pre></p>"},{"location":"cards/versioning/#other-examples","title":"Other Examples:","text":"<pre><code># Major, Minor and Patch\nregistry.register_card(card=card, version_type=\"patch\") # patch increment 1.0.0 -&gt; 1.0.1\nregistry.register_card(card=card, version_type=\"minor\") # minor increment (default) 1.0.0 -&gt; 1.1.0\nregistry.register_card(card=card, version_type=\"major\") # major increment 1.0.0 -&gt; 2.0.0\n\n# Pre, Build, Pre_Build\ncard = DataCard(**kwargs, version=\"1.0.0\")\nregistry.register_card(card=card, version_type=\"pre\") # pre-release or release candidate increment -&gt; 1.0.0-rc.1\n\n\ncard = DataCard(**kwargs, version=\"1.0.0\")\nregistry.register_card(card=card, version_type=\"build\") # build increment -&gt; 1.0.0+build.1\n\n\ncard = DataCard(**kwargs, version=\"1.0.0\")\nregistry.register_card(card=card, version_type=\"pre_build\") # pre-release and build increment -&gt; 1.0.0-rc.1+build.1\n\n\n# Create a minor increment and associate it with a build tag (git commit hash)\ncard = DataCard(**kwargs)\nregistry.register_card(card=card, build_tag=\"git.1a5d783h3784\") # minor increment with build tag -&gt; 1.1.0+git.1a5d783h3784\n</code></pre>"},{"location":"cards/versioning/#terminology","title":"Terminology:","text":""},{"location":"cards/versioning/#major","title":"<code>Major</code>","text":"<p>Indicates a breaking change</p> <ul> <li>Examples:<ul> <li>Adding new features to a dataset</li> <li>New model architecture</li> <li>Training same model architecture but with additional features (major change for both data and model)</li> </ul> </li> </ul>"},{"location":"cards/versioning/#minor","title":"<code>Minor</code>","text":"<p>Non-breaking changes that typically add functionality</p> <ul> <li>Examples:<ul> <li>Updating data/sql logic</li> <li>Updating model parameters</li> <li>Features and output remain the same</li> </ul> </li> </ul>"},{"location":"cards/versioning/#patch","title":"<code>Patch</code>","text":"<p>Indicates a non-breaking change</p> <ul> <li>Examples:<ul> <li>model re-training</li> <li>data re-freshes</li> </ul> </li> </ul>"},{"location":"cards/versioning/#pre","title":"<code>Pre</code>","text":"<p>Indicates a release candidate</p> <ul> <li>Examples:<ul> <li>Saved model that is not ready for an official release</li> <li>Candidate data that needs to be further validated</li> </ul> </li> </ul>"},{"location":"cards/versioning/#build","title":"<code>Build</code>","text":"<p>Indicates a build tag</p> <ul> <li>Examples:<ul> <li>Appending git commit hash to a version</li> </ul> </li> </ul>"},{"location":"cli/overview/","title":"Command Line Interface for Opsml Server","text":"<p>Out of the box, <code>Opsml</code> comes pre-installed with a <code>Opsml-Cli</code>, which is a Rust-compiled binary that can be used as a CLI to interact with an <code>Opsml</code> server. CLI commands are listed below. </p>"},{"location":"cli/overview/#listing-cards","title":"Listing Cards","text":"<p>command: <code>list-cards</code></p> <pre><code>opsml-cli list-cards --registry \"model\" --name \"linnerud\" --repository \"opsml\" --limit 10\n</code></pre> <p>Will list available cards in a registry</p>"},{"location":"cli/overview/#args","title":"Args","text":"<ul> <li>registry: Card registry to search</li> <li>name: Name of card</li> <li>repository: Repository associated with card</li> <li>version: Version of card</li> <li>uid: Uid of card</li> <li>max-date: Max date to search. Must be in <code>YYYY-MM-DD</code> format</li> <li>limit: Max number of records to return</li> <li>tag_name: Tag name to search</li> <li>tag_value: Tag value to search</li> </ul>"},{"location":"cli/overview/#download-model-metadata-and-model","title":"Download Model Metadata and Model","text":"<p>commands: <code>download-model-metadata</code>, <code>download-model</code></p> <pre><code># download model metadata\nopsml-cli download-model-metadata --name \"linnerud\" --repository \"opsml\" --version \"1.0.0\"\n\n# download model (this will also download metadata)\nopsml-cli download-model --uid {{model_uid}}\n</code></pre> <p>Will download model metadata or model from a registry</p>"},{"location":"cli/overview/#args_1","title":"Args","text":"<ul> <li>name: Name of card</li> <li>repository: Repository associated with card</li> <li>version: Version of card</li> <li>uid: Uid of card</li> <li>write-dir: Directory to write to</li> </ul>"},{"location":"cli/overview/#get-model-metrics","title":"Get Model Metrics","text":"<p>command: <code>get-model-metrics</code></p> <pre><code>opsml-cli get-model-metrics --name \"linnerud\" --repository \"opsml\" --version \"1.0.0\"\n</code></pre> <p>Prints metrics associated with a ModelCard</p> <ul> <li>name: Name of card</li> <li>repository: repository associated with card</li> <li>version: Version of card</li> <li>uid: uid of card</li> </ul>"},{"location":"cli/overview/#compare-model-metrics","title":"Compare Model Metrics","text":"<p>command: <code>compare-model-metrics</code></p> <pre><code>opsml-cli compare-model-metrics --challenge-uid {{challenger_uid}} --champion-uid {{champion_uid}} --metric-name \"accuracy\" --lower-is-better false\n</code></pre> <p>Runs a comparison between a model challenger and n model champions</p> <ul> <li>challenger_uid: UID of challenger model</li> <li>champion_uid: Champion UIDs</li> <li>metric_name: Metrics to compare</li> <li>lower_is_better: Whether a lower metric is better</li> </ul>"},{"location":"engineering/how-it-works/","title":"How OpsML Works","text":"<p>The following sections describe specific components of OpsML and how they work.</p>"},{"location":"engineering/how-it-works/#ds-interfaces","title":"DS Interfaces","text":"<p><code>Opsml</code> provides a few public interfaces for DSs to use while abstracting and hiding the underlying implementation details. These interfaces are the <code>ArtifactCard</code> (<code>DataCard</code>, <code>ModelCard</code>, <code>RunCard</code>, etc.) and the <code>CardRegistry</code>. Every <code>ArtifactCard</code> type is associated with a <code>CardRegistry</code> type. Upon instantiation, a DS provides a type to the <code>CardRegistry</code> in order to load the unique registry. Under the hood, each registry inherits from either a <code>Client</code> registry or a <code>Server</code> registry, which is dependent upon the local <code>OpsML</code> environment variables. If the <code>OPSML_TRACKING_URI</code> is set with an http or https uri corresponding to an <code>OpsML</code> server, then the registry will be a <code>Client</code> registry. If the <code>OPSML_TRACKING_URI</code> is set with a SQL connection string, then the registry will be a <code>Server</code> registry. The settings singleton is used to determine which parent registry to instantiate.</p>"},{"location":"engineering/how-it-works/#card-registration","title":"Card Registration","text":"<p>Each card follows the following flow when being registered. Implementation details for each card type may be different, but the general flow is the same.</p> <p></p> <p>Steps upon registration (register_card):</p> <ul> <li> <p>Validate Card: </p> <ul> <li>Each card is validated for (1) the card type matches the registry type and (2) the card has not been registered before</li> </ul> </li> <li> <p>Set Version: </p> <ul> <li>Card registry is queried for the latest <code>Semver</code> for the given model name. A new version is then created based on latest version and version increment type.</li> </ul> </li> <li> <p>Create UID: </p> <ul> <li>A unique ID is created and applied to the card</li> </ul> </li> <li> <p>Set Storage: </p> <ul> <li>A unique storage path is created and the storage client is updated</li> </ul> </li> <li> <p>Create Registry Record: </p> <ul> <li>Save Card Artifacts:</li> <li>Each <code>ArtifactCard</code> has a set of artifacts that are saved to storage. These artifacts are saved to storage and the storage paths are updated in the card and metadata</li> <li>Create Registry Record:</li> <li>A registry record is generated from card metadata and committed to the registry</li> </ul> </li> </ul>"},{"location":"engineering/ownership/","title":"Ownership","text":"<p>In many organizations there is often a separation of concerns between data science and engineering when it comes to data science tooling and infrastructure. Thus, with something like <code>Opsml</code> it's appropriate to think \"who owns what?\" or \"where does data science and engineering fit into the lifecycle, use, and management of a system like this?\". The goal of <code>Opsml</code> is to provide an interface into infrastructure that data scientists use and engineering owns/controls. The diagram below is one example of this separation of concerns.</p>"},{"location":"engineering/ownership/#architecture-of-opsml-proxy-setup","title":"Architecture of Opsml Proxy Setup","text":""},{"location":"engineering/ownership/#general-setup","title":"General Setup","text":"<p>Note - This is an example setup to give an overview of the separation between data science and engineering</p> <p><code>Opsml</code> is packaged and deployed as a proxy system where a server is set up and exposed via a callable api that data scientists set as an environment variable (OPSML_TRACKING_URI). When data scientists use <code>Opsml</code> they will interact with the server through a client API that is automatically configured when <code>Opsml</code> is loaded in python.</p>"},{"location":"engineering/ownership/#parts-owned-by-engineering","title":"Parts Owned by Engineering","text":"<ul> <li><code>Opsml</code> server that is packaged into a docker container and deployed through K8s</li> <li>Storage system (local or cloud) that will be used to store <code>ArtifactCard</code> artifacts (models, data, figures, etc.) </li> <li>Database that will be used to store <code>ArtifactCard</code> metadata. This will typically be a mysql or postgresql database</li> <li>K8s and compute infrastructure for hosting applications</li> <li>CI/CD build process</li> </ul>"},{"location":"engineering/ownership/#other-considerations","title":"Other Considerations","text":"<ul> <li>In this scenario it is expected that the infrastructure hosting the <code>Opsml</code> server is also responsible for authentication and security. As an example, the host system may be placed on an internal network that is only accessible via authentication through a VPN. <code>Opsml</code> was built to be an ML tooling interface, not a security system. Thus, security should be configured on the host system.</li> <li>Credentialing for external systems (storage, databases, etc.) should also be configured and embedded in the environment that hosts the <code>Opsml</code> server. This enables engineering to limit and control the credentials needed for <code>Opsml</code>. It also eliminates the need for data scientists to have to specify credentials when working with <code>Opsml</code> (apart for security authentication). Note - <code>OpsML</code> does support basic auth (single username and password) and we may expand this a on optional full authentication system in the future if there is a need.</li> </ul>"},{"location":"engineering/ownership/#scenario-1-ds-workflows","title":"Scenario 1: DS Workflows","text":"<p>This scenario covers the typical data science workflow and tasks that include exploratory analysis, model training and model evaluation. As part of this workflow, a data scientist will produce various <code>ArtifactCards</code> and store their attributes/metadata through client/server communication.</p>"},{"location":"engineering/ownership/#scenario-2-model-deployment","title":"Scenario 2: Model Deployment","text":"<p>In this scenario, a data scientist or ml engineer creates the custom api logic for their model (FastApi for example) and specifies resources to deploy in a custom configuration or specification file. For this example, assume the engineering repository has set up an automated process whereby changes to the configuration file and push/tags trigger a CI/CD process that builds and serves a new model api. Upon build kickoff, the model specified in the configuration file is downloaded from the <code>Opsml</code> server and packaged along with the api code into a docker container. This docker container is then deployed on K8s where the api is served and ready for requests.</p>"},{"location":"engineering/ownership/#environment","title":"Environment","text":"<p>It is recommended to setup <code>Opsml</code> on each of your environments (dev/staging and prod). This is slightly different than other DS tooling packages and was done in order to follow best practices is systems/infra design. As a result, you will have separate registries across environments that will not be linked. Thus, versions across staging and prod may not be in sync, which is not necessarily an issue considering prod should be the environment used to train and deploy prod model artifacts.</p>"},{"location":"engineering/ownership/#limit-write-access-in-prod","title":"Limit write access in prod","text":"<p>By design, so long as a data scientist has an <code>OPSML_TRACKING_URI</code> they should be able to read and write objects to the <code>Opsml</code> server. However, we usually don't want anyone to write/update a prod artifact from a non-prod environment. As an added measure of security, only requests coming from a prod environment will be allowed to write/update prod artifacts (anything can be read). This is accomplished through a <code>verify_token</code> dependency that checks for an <code>OPSML_PROD_TOKEN</code> token in your request and matches it to the <code>OPSML_PROD_TOKEN</code> in the prod environment. Note This is only checked if the <code>APP_ENV</code> is set to production.</p> <p>For this functionality to work you will need to set <code>OPSML_PROD_TOKEN</code> env var in both the production compute environment that your data scientists use to train models and in the production environment that hosts the <code>Opsml Server</code>. Once these are set, <code>Opsml</code> will take care of the rest. It's also recommended that you use <code>APP_ENV</code> as the env var that specifies the current environment (dev, staging, production).</p>"},{"location":"engineering/server/","title":"<code>Opsml</code> Server Setup","text":"<p>In addition to using <code>Opsml</code> as a stand-alone python package, it can also be used as a server (<code>FastApi</code>) providing a proxy interface between data scientists and backend infrastructure (recommended approach). What this means for data scientists, is that they can use <code>Opsml</code> as they normally would without having to set any credentials apart from the http proxy uri. For engineers, this means that they can control the infrastucture, databases, and overall server setup based on their specifications and security requirements. More on this can be found here</p>"},{"location":"engineering/server/#registry-architecture","title":"Registry Architecture","text":""},{"location":"engineering/server/#project-run-flow-architecture","title":"Project Run Flow Architecture","text":""},{"location":"engineering/server/#setup","title":"Setup","text":"<p>You can setup the <code>Opsml</code> server based on your repository needs. For our purposes at <code>Shipt</code>, we tend to follow a conventional setup whereby we host Docker images via K8s. For this setup up, we typically will install <code>Opsml</code> and its dependencies into a Dockerfile.</p>"},{"location":"engineering/server/#required-env-vars","title":"Required Env Vars","text":"<p>As mentioned here <code>Opsml</code> expects 2 variables to be set (these can be set in an Dockerfile or at webserver runtime).</p>"},{"location":"engineering/server/#opsml_tracking_uri","title":"OPSML_TRACKING_URI","text":"<p>This is the tracking uri of your backend database.</p> <p>Example:</p> <p><code>OPSML_TRACKING_URI=postgresql://user:pass@host:port/database_name</code></p>"},{"location":"engineering/server/#opsml_storage_uri","title":"OPSML_STORAGE_URI","text":"<p>This is the storage uri of your storage backend (e.g. GCP, AWS).</p> <p>Example:</p> <p><code>OPSML_STORAGE_URI=gs://my-google-cloud-bucket</code></p>"},{"location":"engineering/server/#opsml_pool_size-optional","title":"OPSML_POOL_SIZE (optional)","text":"<p>Default pool size to use with sqlalchemy engine. If not set, will default to 10.</p> <p>Example:</p> <p><code>OPSML_POOL_SIZE=10</code></p>"},{"location":"engineering/server/#opsml_max_overflow-optional","title":"OPSML_MAX_OVERFLOW (optional)","text":"<p>Default max overflow to use with sqlalchemy engine. If not set, will default to 5.</p> <p>Example:</p> <p><code>OPSML_MAX_OVERFLOW=10</code></p>"},{"location":"engineering/server/#run-command","title":"Run Command","text":"<ul> <li>During local development/testing, you can spin up and test the <code>Opsml</code> server via the CLI command <code>opsml-uvicorn-server</code> which will launch a Uvicorn server.</li> <li>For production, it is recommended that you run Gunicorn.</li> <li>The following command can be used to run a Gunicorn <code>Opsml</code> server.</li> </ul> <p><code>gunicorn -k uvicorn.workers.UvicornWorker --config=./app/gunicorn_conf.py --bind=0.0.0.0:3000 \"opsml.app.main:run_app(login=False)\"</code></p>"},{"location":"engineering/server/#example-pyprojecttoml-for-an-opsml-server","title":"Example pyproject.toml for an Opsml Server","text":"<pre><code>[tool.poetry]\nname = \"opsml-server\"\nversion = \"0.1.0\"\ndescription = \"\"\nauthors = [\"ml-platform\"]\n\n[tool.poetry.dependencies]\npython = \"&gt;=3.9,&lt;=3.11\"\nopsml = {version = \"^2.0.0\", extras = [\"gcs\", \"postgres\", \"server\"]}\n</code></pre>"},{"location":"faq/common_questions/","title":"FAQ","text":"<p>Below are a list of commonly answered questions.</p>"},{"location":"faq/common_questions/#why-do-some-examples-use-a-context-manager-and-some-dont-whats-recommended","title":"Why do some examples use a context manager and some don't? What's recommended?","text":"<p>By default, all cards can be registered, listed, loaded and updated outside of a context manager. In fact, this was done on purpose to not lock users into a particular style. The context manager comes into play when using <code>RunCards</code> as they provide a means to group artifacts (Cards, metrics, params) under a specific project run. Technically, this grouping can still be achieved by using <code>RunCards</code> directly but this comes at the expense of more lines of code. The context manager tends to be a more convenient way of logging and tracking artifacts. In addition, when using an <code>OpsmlProject</code>, all artifacts are automatically viewable in the Opsml UI.</p> <p>Recommendation based on needs</p> <ul> <li>I'd like to be able to view all artifacts, metrics, graphs, reports in a UI<ul> <li>Use the <code>OpsmlProject</code> context manager</li> </ul> </li> <li>I don't really need to see all of the artifacts, I care more that they are tracked and callable when needed<ul> <li>Use whatever you prefer</li> </ul> </li> <li>I like grouping runs/experiments by projects. UI doesn't really matter.<ul> <li>Use the <code>OpsmlProject</code> context manager</li> </ul> </li> </ul>"},{"location":"faq/common_questions/#how-do-i-turn-off-onnx-conversion","title":"How do I turn off onnx conversion?","text":"<p>Auto onnx conversion can be turned off by default. It can be turned on by setting <code>to_onnx=True</code> in the <code>ModelCard</code> constructor.</p>"},{"location":"faq/common_questions/#how-do-i-supply-my-own-onnx-definition","title":"How do I supply my own onnx definition?","text":"<p>If you'd like to create your onnx model yourself and associate that with the ModelCard, you will need to provide your own implementation of the <code>onnx_model</code> arg. An example of this can be seen here.</p>"},{"location":"faq/common_questions/#whats-with-using-name-repository-and-contact-or-cardinfo-in-the-examples","title":"What's with using name, repository, and contact or <code>CardInfo</code> in the examples?","text":"<p>Every <code>ArtifactCard</code> requires a name, repository and contact. For convenience, you can instead provide a <code>CardInfo</code> instance.</p>"},{"location":"faq/common_questions/#how-is-opsml-different-than-other-products-out-there","title":"How is <code>Opsml</code> different than other products out there?","text":"<p>A key difference between <code>Opsml</code> and other products is that <code>Opsml</code> was not designed to be a platform or lock you in to any specific way of doing things. Instead, the goal and initial idea behind <code>Opsml</code> was to provide tooling and an interface that stitches, standardizes and automates some of the key building blocks (storage, tracking, versioning) to any machine learning workflow or platform. Thus, <code>Opsml</code> is capable of being used with other platforms or machine learning workflow systems. Or you can build your own!</p>"},{"location":"faq/contributing/","title":"Contributing to Shipt/opsml","text":""},{"location":"faq/contributing/#welcome","title":"Welcome","text":"<p>Hello! We're glad and grateful that you're interested in contributing to <code>Opsml</code> ! Below you will find the general guidelines for setting up your environment and creating/submitting <code>pull requests</code>.</p>"},{"location":"faq/contributing/#very-important","title":"Very Important","text":"<p>To contribute to <code>Opsml</code> you will need to sign a Contributor License Agreement (CLA) via HelloSign when you create your first <code>pull_request</code> (this is an automated process). For a <code>pull_request</code> to be valid, your Github email address must match the email address used to sign the CLA. Github has documentation on setting email addresses. Your git email must also match this email address</p>"},{"location":"faq/contributing/#table-of-contents","title":"Table of contents","text":"<ul> <li>Environment setup</li> <li>Contributing changes</li> <li>Contributing TLDR</li> <li>Community guidelines</li> <li>Reporting bugs</li> <li>Suggesting enhancements</li> </ul>"},{"location":"faq/contributing/#environment-setup","title":"Environment Setup","text":"<p>Steps: 1. Create a new env. <code>Opsml</code> currently supports python 3.9 -&gt; 3.11 2. Fork <code>Opsml</code> 3. Install all required and development packages in your new env (we use poetry for dependency management).</p> <p><pre><code>make setup\n</code></pre> or with poetry directly</p> <pre><code>poetry install --all-extras --with dev,dev-lints\n</code></pre>"},{"location":"faq/contributing/#contributing-changes","title":"Contributing Changes","text":"<ol> <li>Create a new branch for your addition</li> <li>General naming conventions (we're not picky):<ul> <li><code>/username/&lt;featureName&gt;</code>: for features</li> <li><code>/username/&lt;fixName&gt;</code>: for general refactoring or bug fixes</li> </ul> </li> <li>Test your changes:</li> <li>You can run formatting, lints and tests locally via <code>make format</code>, <code>make lints</code> and <code>make unit.tests</code>, respectively.</li> <li>Submit a Draft Pull Request. Do it early and mark it <code>WIP</code> so a maintainer knows it's not ready for review just yet. You can also add a label to it if you feel like it .</li> <li>If you haven't signed our CLA before, then you will receive an email from HelloSign to sign the CLA (mentioned above).<ul> <li>The CLA request will be sent to the email address associated with your github account.</li> <li>You cannot have your PR merged without signing the PR.</li> <li>If you already submitted a PR and need to correct your user.name and/or user.email please do so and then use <code>git commit --amend --reset-author</code> and then <code>git push --force</code> to correct the PR.</li> </ul> </li> <li>Move the <code>pull_request</code> out of draft state.</li> <li>Make sure you fill out the <code>pull_request</code> template (included with every <code>pull_request</code>)</li> <li>Request review from one of our maintainers (this should happen automatically via <code>.github/CODEOWNERS</code>). </li> <li>Get Approval. We'll let you know if there are any changes that are needed. </li> <li>Merge your changes into <code>Opsml</code>!</li> </ol>"},{"location":"faq/contributing/#contributing-tldr","title":"Contributing TLDR","text":"<ol> <li>Create branch</li> <li>Add changes</li> <li>Test locally</li> <li>Create PR (fill out CLA if you haven't before)</li> <li>Get your awesome work reviewed and approved by a maintainer</li> <li>Merge</li> <li>Celebrate!</li> </ol>"},{"location":"faq/contributing/#community-guidelines","title":"Community Guidelines","text":"<ol> <li>Be Kind<ul> <li>Working with us should be a fun learning opportunity, and we want it to be a good experience for everyone. Please treat each other with respect.  </li> <li>If something looks outdated or incorrect, please let us know! We want to make <code>Opsml</code> as useful as possible. </li> </ul> </li> <li>Own Your Work<ul> <li>Creating a PR for <code>Opsml</code> is your first step to becoming a contributor, so make sure that you own your changes. </li> <li>Our maintainers will do their best to respond to you in a timely manner, but we ask the same from you as the contributor. </li> </ul> </li> </ol>"},{"location":"faq/contributing/#submitting-issuesbugs","title":"Submitting issues/bugs","text":"<p>We use GitHub issues to track bugs and suggested enhancements. You can report a bug by opening a new issue new issue Before reporting a bug/issue, please check that it has not already been reported, and that it is not already fixed in the latest version. If you find a closed issue related to your current issue, please open a new issue and include a link to the original issue in the body of your new one. Please include as much information about your bug as possible.</p>"},{"location":"faq/contributing/#suggesting-enhancements","title":"Suggesting enhancements","text":"<p>You can suggest an enhancement by opening a new feature request. Before creating an enhancement suggestion, please check that a similar issue does not already exist.</p> <p>Please describe the behavior you want and why, and provide examples of how <code>Opsml</code> would be used if your feature were added.</p>"},{"location":"faq/contributing/#thank-you","title":"Thank you!","text":""},{"location":"interfaces/overview/","title":"Overview","text":"<pre><code>---\ntitle: Opsml Primary Artifacts\n---\nflowchart LR\n    interface[[\"Interface\"]]\n\n    artifacts(\"\n    ArtifactCard\n    #bull; Interface\n    #bull; Metadata\")\n\n    db[(\"Card Registry\")]\n\n    interface --stored in--&gt; artifacts --stored in--&gt; db</code></pre> <p>Interfaces are one of the 3 primary objects in <code>Opsml</code> and can be viewed as a low-level object with the most flexibility. Although each subclassed interface is unique, they are all designed to be injected into a <code>ModelCard</code> or <code>DataCard</code></p>"},{"location":"interfaces/overview/#interface-types","title":"Interface Types","text":"<ul> <li> <p><code>DataInterface</code>: Interface used to store data-related information (data, dependent variables, feature descriptions, split logic, etc.)</p> </li> <li> <p><code>ModelInterface</code>: Interface used to store trained model and model information</p> </li> </ul>"},{"location":"interfaces/overview/#data-interface","title":"Data Interface","text":"<p>The <code>DataInterface</code> is the primary interface for working with data in <code>Opsml</code>. It is designed to be subclassed and can be used to store data in a variety of formats depending on the library. Out of the box the following subclasses are available:</p> <ul> <li><code>PandasData</code>: Stores data from a pandas dataframe</li> <li><code>NumpyData</code>: Stores data from a numpy array</li> <li><code>PolarsData</code>: Stores data from a polars dataframe</li> <li><code>ArrowData</code>: Stores data from a pyarrow table</li> <li><code>ImageDataset</code>: Stores data from a directory of images</li> <li><code>TextDataset</code>: Stores data from a directory of text files</li> <li><code>TorchData</code>: Stores data from a torch tensor(s)</li> <li><code>SqlData</code>: Stores sql text</li> </ul>"},{"location":"interfaces/overview/#model-interface","title":"Model Interface","text":"<p>The <code>ModelInterface</code> is the primary interface for working with models in <code>Opsml</code>. It is designed to be subclassed and can be used to store models in a variety of formats depending on the library. Out of the box the following subclasses are available:</p> <ul> <li><code>SklearnModel</code>: Stores data from a sklearn model</li> <li><code>TorchModel</code>: Stores data from a pytorch model</li> <li><code>LightningModel</code>: Stores data from a pytorch lightning model</li> <li><code>HuggingFaceModel</code>: Stores data from a huggingface model</li> <li><code>TensorFlowModel</code>: Stores data from a tensorflow model</li> <li><code>XGBoostModel</code>: Stores data from a xgboost model</li> <li><code>LightGBMModel</code>: Stores data from a lightgbm model</li> <li><code>CatBoostModel</code>: Stores data from a catboost model</li> </ul> <p>For more information on interfaces, see the each interface's respective documentation.</p>"},{"location":"interfaces/data/data_profile/","title":"Data Profile","text":""},{"location":"interfaces/data/data_profile/#data-profile_1","title":"Data Profile","text":"<p>Opsml DataInterfaces support ydata-profiling with an optional extra.</p> <pre><code>poetry add opsml[profiling]\n</code></pre> <p>To add a data profile to your interface you can either supply a custom data profile created through the <code>ydata-profiling</code> library or you can call the <code>create_data_profile</code> method after <code>DataInterface</code> instantiation. Note - you can also call <code>create_data_profile</code> from a <code>DataCard</code> after instantiation (example below). The <code>create_data_profile</code> is optimized for performance, and thus, will omit certain analyses by defualt (interactions, character/word analysis, etc.). If you'd like more control over what analyses are conducted, it is recommended that you create a custom report via <code>ydata-profiling</code> and provide it to the DataCard using the <code>data_profile</code> arg.</p> <p>Example of <code>create_data_profile</code></p> <pre><code># Data\nfrom sklearn.datasets import load_linnerud\n\n# Opsml\nfrom opsml import CardInfo, DataCard, CardRegistry, PandasData\n\ndata, target = load_linnerud(return_X_y=True, as_frame=True)\ndata[\"Pulse\"] = target.Pulse\n\ninterface = PandasData(data=data)\n\n# create data profile from interface\ninterface.create_data_profile(sample_perc=0.5) # you can specify a sampling percentage between 0 and 1\n\ncard_info = CardInfo(name=\"linnerrud\", repository=\"opsml\", contact=\"user@email.com\")\ndata_card = DataCard(info=card_info, data=data)\n\n# this also works\ndata_card.create_data_profile(sample_perc=0.5) \n\n# if youd like to view you're report, you can export it to html or json\n# Jupyter notebooks will render the html without needing to save (just call data_card.data_profile)\n# data_card.data_profile.to_file(\"my_report.html\")\n\n# Registering card will automatically save the report and its html\ndata_registry = CardRegistry(registry_name=\"data\")\ndata_registry.register_card(card=data_card)\n</code></pre> <p>Example of providing your own custom data profile</p> <pre><code>from ydata_profiling import ProfileReport\nfrom opsml import PandasData \n\ndata, target = load_linnerud(return_X_y=True, as_frame=True)\ndata[\"Pulse\"] = target.Pulse\n\ndata_profile = ProfileReport(data, title=\"Profiling Report\")\ninterface = PandasData(data=data, data_profile=data_profile)\n</code></pre>"},{"location":"interfaces/data/data_profile/#comparing-data-profiles","title":"Comparing data profiles","text":"<p>You can also leverage <code>Opsmls</code> thin profiling wrapper for comparing different data profiles</p> <pre><code>from sklearn.datasets import load_linnerud\nimport numpy as np\n\n# Opsml\nfrom opsml import PandasData\nfrom opsml.profile import DataProfiler\n\ndata, target = load_linnerud(return_X_y=True, as_frame=True)\ndata[\"Pulse\"] = target.Pulse\n\n# Simulate creating 1st DataCard\ninterface = PandasData(data=data)\ninterface.create_data_profile()\n\n# Simulate creating 2nd DataCard\ndata2 = data * np.random.rand(data.shape[1])\ncard_info = CardInfo(name=\"linnerrud\", repository=\"opsml\", contact=\"user@email.com\")\ninterface2 = PandasData(data=data)\ninterface2.create_data_profile()\n\ncomparison = DataProfiler.compare_reports(reports=[data_card.data_profile, data_card2.data_profile])\ncomparison.to_file(\"comparison_report.html\")\n</code></pre>"},{"location":"interfaces/data/data_profile/#docs","title":"Docs","text":""},{"location":"interfaces/data/data_profile/#opsml.profile.DataProfiler","title":"<code>opsml.profile.DataProfiler</code>","text":"Source code in <code>opsml/profile/profile_data.py</code> <pre><code>class DataProfiler:\n    @staticmethod\n    def create_profile_report(\n        data: Union[pd.DataFrame, pl.DataFrame],\n        name: str,\n        sample_perc: float = 1,\n    ) -&gt; ProfileReport:\n        \"\"\"\n        Creates a `ydata-profiling` report\n\n        Args:\n            data:\n                Pandas dataframe\n            sample_perc:\n                Percentage to use for sampling\n            name:\n                Name of the report\n\n        Returns:\n            `ProfileReport`\n        \"\"\"\n        from ydata_profiling import ProfileReport\n\n        kwargs = {\"title\": f\"Profile report for {name}\"}\n\n        if isinstance(data, pl.DataFrame):\n            if sample_perc &lt; 1:\n                return ProfileReport(\n                    df=data.sample(fraction=sample_perc, with_replacement=False, shuffle=True).to_pandas(),\n                    config_file=os.path.join(DIR_PATH, \"profile_config.yml\"),\n                    lazy=False,\n                    **kwargs,\n                )\n\n            return ProfileReport(\n                df=data.to_pandas(),\n                config_file=os.path.join(DIR_PATH, \"profile_config.yml\"),\n                lazy=False,\n                **kwargs,\n            )\n\n        if sample_perc &lt; 1:\n            return ProfileReport(\n                df=data.sample(frac=sample_perc, replace=False),\n                config_file=os.path.join(DIR_PATH, \"profile_config.yml\"),\n                lazy=False,\n                **kwargs,\n            )\n\n        return ProfileReport(\n            df=data,\n            config_file=os.path.join(DIR_PATH, \"profile_config.yml\"),\n            lazy=False,\n            **kwargs,\n        )\n\n    @staticmethod\n    def load_profile(data: bytes) -&gt; ProfileReport:\n        \"\"\"Loads a `ProfileReport` from data bytes\n\n        Args:\n            data:\n                `ProfileReport` in bytes\n\n        Returns:\n            `ProfileReport`\n        \"\"\"\n        from ydata_profiling import ProfileReport\n\n        profile = ProfileReport()\n        profile.loads(data)\n        return profile\n\n    @staticmethod\n    def compare_reports(reports: List[ProfileReport]) -&gt; ProfileReport:\n        \"\"\"Compares ProfileReports\n\n        Args:\n            reports:\n                List of `ProfileReport`\n\n        Returns:\n            `ProfileReport`\n        \"\"\"\n        from ydata_profiling import compare\n\n        return compare(reports=reports)\n</code></pre>"},{"location":"interfaces/data/data_profile/#opsml.profile.DataProfiler.create_profile_report","title":"<code>create_profile_report(data, name, sample_perc=1)</code>  <code>staticmethod</code>","text":"<p>Creates a <code>ydata-profiling</code> report</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[DataFrame, DataFrame]</code> <p>Pandas dataframe</p> required <code>sample_perc</code> <code>float</code> <p>Percentage to use for sampling</p> <code>1</code> <code>name</code> <code>str</code> <p>Name of the report</p> required <p>Returns:</p> Type Description <code>ProfileReport</code> <p><code>ProfileReport</code></p> Source code in <code>opsml/profile/profile_data.py</code> <pre><code>@staticmethod\ndef create_profile_report(\n    data: Union[pd.DataFrame, pl.DataFrame],\n    name: str,\n    sample_perc: float = 1,\n) -&gt; ProfileReport:\n    \"\"\"\n    Creates a `ydata-profiling` report\n\n    Args:\n        data:\n            Pandas dataframe\n        sample_perc:\n            Percentage to use for sampling\n        name:\n            Name of the report\n\n    Returns:\n        `ProfileReport`\n    \"\"\"\n    from ydata_profiling import ProfileReport\n\n    kwargs = {\"title\": f\"Profile report for {name}\"}\n\n    if isinstance(data, pl.DataFrame):\n        if sample_perc &lt; 1:\n            return ProfileReport(\n                df=data.sample(fraction=sample_perc, with_replacement=False, shuffle=True).to_pandas(),\n                config_file=os.path.join(DIR_PATH, \"profile_config.yml\"),\n                lazy=False,\n                **kwargs,\n            )\n\n        return ProfileReport(\n            df=data.to_pandas(),\n            config_file=os.path.join(DIR_PATH, \"profile_config.yml\"),\n            lazy=False,\n            **kwargs,\n        )\n\n    if sample_perc &lt; 1:\n        return ProfileReport(\n            df=data.sample(frac=sample_perc, replace=False),\n            config_file=os.path.join(DIR_PATH, \"profile_config.yml\"),\n            lazy=False,\n            **kwargs,\n        )\n\n    return ProfileReport(\n        df=data,\n        config_file=os.path.join(DIR_PATH, \"profile_config.yml\"),\n        lazy=False,\n        **kwargs,\n    )\n</code></pre>"},{"location":"interfaces/data/data_profile/#opsml.profile.DataProfiler.compare_reports","title":"<code>compare_reports(reports)</code>  <code>staticmethod</code>","text":"<p>Compares ProfileReports</p> <p>Parameters:</p> Name Type Description Default <code>reports</code> <code>List[ProfileReport]</code> <p>List of <code>ProfileReport</code></p> required <p>Returns:</p> Type Description <code>ProfileReport</code> <p><code>ProfileReport</code></p> Source code in <code>opsml/profile/profile_data.py</code> <pre><code>@staticmethod\ndef compare_reports(reports: List[ProfileReport]) -&gt; ProfileReport:\n    \"\"\"Compares ProfileReports\n\n    Args:\n        reports:\n            List of `ProfileReport`\n\n    Returns:\n        `ProfileReport`\n    \"\"\"\n    from ydata_profiling import compare\n\n    return compare(reports=reports)\n</code></pre>"},{"location":"interfaces/data/data_splits/","title":"Data Splits","text":"<p>In most data science workflows, it's common to split data into different subsets for analysis and comparison. In support of this, <code>DataInterface</code> subclasses allow you to specify and split your data based on specific logic that is provided to a <code>DataSplit</code>.</p>"},{"location":"interfaces/data/data_splits/#split-types","title":"Split types","text":""},{"location":"interfaces/data/data_splits/#column-name-and-value","title":"Column Name and Value","text":"<ul> <li>Split data based on a column value. </li> <li>Supports inequality signs. </li> <li>Works with <code>Pandas</code> and <code>Polars</code> <code>DataFrames</code>.</li> </ul> <p>Example</p> <pre><code>import polars as pl\nfrom opsml import PolarsData, DataSplit, CardInfo\n\ninfo = CardInfo(name=\"data\", repository=\"mlops\", contact=\"user@mlops.com\")\n\ndf = pl.DataFrame(\n    {\n        \"foo\": [1, 2, 3, 4, 5, 6],\n        \"bar\": [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"],\n        \"y\": [1, 2, 3, 4, 5, 6],\n    }\n)\n\ninterface = PolarsData(\n    info=info,\n    data=df,\n    data_splits = [\n        DataSplit(label=\"train\", column_name=\"foo\", column_value=6, inequality=\"&lt;\"),\n        DataSplit(label=\"test\", column_name=\"foo\", column_value=6)\n    ]\n\n)\n\nsplits = interface.split_data()\nassert splits[\"train\"].X.shape[0] == 5\nassert splits[\"test\"].X.shape[0] == 1\n</code></pre>"},{"location":"interfaces/data/data_splits/#indices","title":"Indices","text":"<ul> <li>Split data based on pre-defined indices</li> <li>Works with <code>NDArray</code>, <code>pyarrow.Table</code>, <code>pandas.DataFrame</code> and <code>polars.DataFrame</code></li> </ul> <pre><code>import numpy as np\nfrom opsml import NumpyData, DataSplit, CardInfo\n\ninfo = CardInfo(name=\"data\", repository=\"mlops\", contact=\"user@mlops.com\")\n\ndata = np.random.rand(10, 10)\n\ninterface = NumpyData(\n    info=info,\n    data=data,\n    data_splits = [\n        DataSplit(label=\"train\", indices=[0,1,5])\n    ]\n\n)\n\nsplits = interface.split_data()\nassert splits[\"train\"].X.shape[0] == 3\n</code></pre>"},{"location":"interfaces/data/data_splits/#start-and-stop-slicing","title":"Start and Stop Slicing","text":"<ul> <li>Split data based on row slices with a start and stop index</li> <li>Works with <code>NDArray</code>, <code>pyarrow.Table</code>, <code>pandas.DataFrame</code> and <code>polars.DataFrame</code></li> </ul> <pre><code>import numpy as np\nfrom opsml import NumpyData, DataSplit, CardInfo\n\ninfo = CardInfo(name=\"data\", repository=\"mlops\", contact=\"user@mlops.com\")\n\ndata = np.random.rand(10, 10)\n\ninterface = NumpyData(\n    info=info,\n    data=data,\n    data_splits = [\n        DataSplit(label=\"train\", start=0, stop=3)\n    ]\n\n)\n\nsplits = interface.split_data()\nassert splits[\"train\"].X.shape[0] == 3\n</code></pre>"},{"location":"interfaces/data/data_splits/#opsml.DataSplit","title":"<code>opsml.DataSplit</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>opsml/data/splitter.py</code> <pre><code>class DataSplit(BaseModel):\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    label: str\n    column_name: Optional[str] = None\n    column_value: Optional[Union[str, float, int, pd.Timestamp]] = None\n    inequality: Optional[str] = None\n    start: Optional[int] = None\n    stop: Optional[int] = None\n    indices: Optional[List[int]] = None\n\n    @field_validator(\"indices\", mode=\"before\")\n    @classmethod\n    def convert_to_list(cls, value: Optional[List[int]]) -&gt; Optional[List[int]]:\n        \"\"\"Pre to convert indices to list if not None\"\"\"\n\n        if value is not None and not isinstance(value, list):\n            value = list(value)\n\n        return value\n\n    @field_validator(\"inequality\", mode=\"before\")\n    @classmethod\n    def trim_whitespace(cls, value: str) -&gt; str:\n        \"\"\"Trims whitespace from inequality signs\"\"\"\n\n        if value is not None:\n            value = value.strip()\n\n        return value\n</code></pre>"},{"location":"interfaces/data/data_splits/#opsml.DataSplit.convert_to_list","title":"<code>convert_to_list(value)</code>  <code>classmethod</code>","text":"<p>Pre to convert indices to list if not None</p> Source code in <code>opsml/data/splitter.py</code> <pre><code>@field_validator(\"indices\", mode=\"before\")\n@classmethod\ndef convert_to_list(cls, value: Optional[List[int]]) -&gt; Optional[List[int]]:\n    \"\"\"Pre to convert indices to list if not None\"\"\"\n\n    if value is not None and not isinstance(value, list):\n        value = list(value)\n\n    return value\n</code></pre>"},{"location":"interfaces/data/data_splits/#opsml.DataSplit.trim_whitespace","title":"<code>trim_whitespace(value)</code>  <code>classmethod</code>","text":"<p>Trims whitespace from inequality signs</p> Source code in <code>opsml/data/splitter.py</code> <pre><code>@field_validator(\"inequality\", mode=\"before\")\n@classmethod\ndef trim_whitespace(cls, value: str) -&gt; str:\n    \"\"\"Trims whitespace from inequality signs\"\"\"\n\n    if value is not None:\n        value = value.strip()\n\n    return value\n</code></pre>"},{"location":"interfaces/data/datasets/","title":"Datasets","text":""},{"location":"interfaces/data/datasets/#datasets","title":"Datasets","text":"<p>In addition to <code>DataInterface</code> classes, <code>opsml</code> also provides a <code>Dataset</code> class that is used when working with text or image data.</p>"},{"location":"interfaces/data/datasets/#required-arguments-for-all-datasets-examples-below","title":"Required Arguments for all Datasets (examples below)","text":"<code>data_dir</code> Path to directory containing data. This should be the <code>root</code> directory that contains all of the data. If you wish to define <code>splits</code>, you can do so by creating sub-directories within the <code>root</code> directory. For example, if you have a <code>train</code> and <code>test</code> split, you can create a directory structure like this: <pre><code>root\n\u251c\u2500\u2500 train        # this will be inferred as a split named `train`\n\u2502   \u251c\u2500\u2500 file1.txt\n\u2502   \u251c\u2500\u2500 file2.txt\n\u2502   \u251c\u2500\u2500 file3.txt\n\u2502   \u2514\u2500\u2500 metadata.jsonl\n\u2514\u2500\u2500 test          # this will be inferred as a split named `test`\n    \u251c\u2500\u2500 file4.txt\n    \u251c\u2500\u2500 file5.txt\n    \u251c\u2500\u2500 file6.txt\n    \u2514\u2500\u2500 metadata.jsonl\n</code></pre> <code>shard_size</code> Size of each shard. Defaults to <code>512MB</code>"},{"location":"interfaces/data/datasets/#optional-arguments","title":"Optional Arguments","text":"<code>splits</code> Dictionary of splits. Defaults to <code>{}</code> This is automatically inferred from directory structure <code>description</code> Description of dataset. Defaults to <code>Description()</code>"},{"location":"interfaces/data/datasets/#dataset-saving-and-loading","title":"Dataset Saving and Loading","text":"<p>Datasets are saved via <code>pyarrow</code> reader and writers. This allows for efficient loading and saving of datasets. For saving, <code>Dataset</code> splits are saved as parquet files based on the specified <code>shard</code> size. During loading, the dataset is loaded based on both <code>batch_size</code> and <code>chunk_size</code> arguments. The <code>batch_size</code> argument is used to specify the number of rows to load at a time. The <code>chunk_size</code> argument is used to split the batch by <code>n</code> chunks. Both of these arguments are used to control memory usage during loading.</p>"},{"location":"interfaces/data/datasets/#metadata","title":"Metadata","text":"<p>The <code>metadata.jsonl</code> file is a <code>jsonl</code> file containing line separated json entries that can be written and loaded via the dataset's <code>Metadata</code> class. The <code>Metadata</code> class is a <code>pydantic</code> model that is used to validate the <code>metadata.jsonl</code> file. Each <code>metadata</code> subclass accepts a list of <code>FileRecords</code>. For subclass-specific examples, please refer to the examples below.</p>"},{"location":"interfaces/data/datasets/#imagedataset","title":"ImageDataset","text":"<p><code>ImageDataset</code> is a subclass of <code>Dataset</code> that is used to load and save image data. It is similar to <code>HuggingFace</code> datasets, which was intentional in order to maintain some level of parity.</p> Data Type <code>Directory of images</code> Save Format <code>parquet</code> Source <code>ImageDataset</code>"},{"location":"interfaces/data/datasets/#imagemetadata","title":"ImageMetadata","text":"<p><code>ImageMetadata</code> is the metadata subclass that is associated with <code>ImageDataset</code>.</p>"},{"location":"interfaces/data/datasets/#required-arguments","title":"Required Arguments","text":"<code>records</code> List of <code>ImageRecords</code>"},{"location":"interfaces/data/datasets/#opsml.ImageMetadata","title":"<code>opsml.ImageMetadata</code>","text":"<p>             Bases: <code>Metadata</code></p> <p>Create Image metadata from a list of ImageRecords</p> <p>Args:</p> <pre><code>records:\n    List of ImageRecords\n</code></pre> Source code in <code>opsml/data/interfaces/custom_data/image.py</code> <pre><code>class ImageMetadata(Metadata):\n    \"\"\"Create Image metadata from a list of ImageRecords\n\n    Args:\n\n        records:\n            List of ImageRecords\n    \"\"\"\n\n    records: List[ImageRecord]\n\n    @classmethod\n    def load_from_file(cls, filepath: Path) -&gt; \"ImageMetadata\":\n        \"\"\"Load metadata from a file\n\n        Args:\n            filepath:\n                Path to metadata file\n        \"\"\"\n        assert filepath.name == \"metadata.jsonl\", \"Filename must be metadata.jsonl\"\n        with filepath.open(\"r\", encoding=\"utf-8\") as file_:\n            records = []\n            for line in file_:\n                records.append(ImageRecord(**json.loads(line)))\n            return cls(records=records)\n</code></pre>"},{"location":"interfaces/data/datasets/#opsml.ImageMetadata.load_from_file","title":"<code>load_from_file(filepath)</code>  <code>classmethod</code>","text":"<p>Load metadata from a file</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Path</code> <p>Path to metadata file</p> required Source code in <code>opsml/data/interfaces/custom_data/image.py</code> <pre><code>@classmethod\ndef load_from_file(cls, filepath: Path) -&gt; \"ImageMetadata\":\n    \"\"\"Load metadata from a file\n\n    Args:\n        filepath:\n            Path to metadata file\n    \"\"\"\n    assert filepath.name == \"metadata.jsonl\", \"Filename must be metadata.jsonl\"\n    with filepath.open(\"r\", encoding=\"utf-8\") as file_:\n        records = []\n        for line in file_:\n            records.append(ImageRecord(**json.loads(line)))\n        return cls(records=records)\n</code></pre>"},{"location":"interfaces/data/datasets/#imagerecord","title":"ImageRecord","text":"<p><code>ImageRecord</code> is the <code>FileRecord</code> subclass that is associated with <code>ImageMetadata</code>.</p>"},{"location":"interfaces/data/datasets/#required-arguments_1","title":"Required Arguments","text":"<code>filepath</code> Pathlike object to image file"},{"location":"interfaces/data/datasets/#optional-arguments_1","title":"Optional Arguments","text":"<code>caption</code> Caption for the image <code>categories</code> List of categories for the image <code>objects</code> Bounding box specifications for objects in the image. See <code>BBox</code>"},{"location":"interfaces/data/datasets/#opsml.ImageRecord","title":"<code>opsml.ImageRecord</code>","text":"<p>             Bases: <code>FileRecord</code></p> <p>Image record to associate with image file</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <p>Full path to the file</p> required <code>caption</code> <p>Optional caption for image</p> required <code>categories</code> <p>Optional list of categories for image</p> required <code>objects</code> <p>Optional <code>BBox</code> for the image</p> required <code>size</code> <p>Size of the file. This is inferred automatically if filepath is provided.</p> required Source code in <code>opsml/data/interfaces/custom_data/image.py</code> <pre><code>class ImageRecord(FileRecord):\n    \"\"\"Image record to associate with image file\n\n    Args:\n        filepath:\n            Full path to the file\n        caption:\n            Optional caption for image\n        categories:\n            Optional list of categories for image\n        objects:\n            Optional `BBox` for the image\n        size:\n            Size of the file. This is inferred automatically if filepath is provided.\n\n    \"\"\"\n\n    caption: Optional[str] = None\n    categories: Optional[List[Union[str, int, float]]] = None\n    objects: Optional[BBox] = None\n\n    def to_arrow(self, data_dir: Path, split_label: Optional[str] = None) -&gt; Dict[str, Any]:\n        \"\"\"Saves data to arrow format\n\n        Args:\n            data_dir:\n                Path to data directory\n            split_label:\n                Optional split label for data\n\n        Returns:\n            Dictionary of data to be saved to arrow\n        \"\"\"\n        path = self.filepath.relative_to(data_dir)\n\n        with Image.open(self.filepath) as img:\n            stream_record = {\n                \"split_label\": split_label,\n                \"path\": path.as_posix(),\n                \"height\": img.height,\n                \"width\": img.width,\n                \"bytes\": img.tobytes(),\n                \"mode\": img.mode,\n            }\n        return stream_record\n</code></pre>"},{"location":"interfaces/data/datasets/#opsml.ImageRecord.to_arrow","title":"<code>to_arrow(data_dir, split_label=None)</code>","text":"<p>Saves data to arrow format</p> <p>Parameters:</p> Name Type Description Default <code>data_dir</code> <code>Path</code> <p>Path to data directory</p> required <code>split_label</code> <code>Optional[str]</code> <p>Optional split label for data</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary of data to be saved to arrow</p> Source code in <code>opsml/data/interfaces/custom_data/image.py</code> <pre><code>def to_arrow(self, data_dir: Path, split_label: Optional[str] = None) -&gt; Dict[str, Any]:\n    \"\"\"Saves data to arrow format\n\n    Args:\n        data_dir:\n            Path to data directory\n        split_label:\n            Optional split label for data\n\n    Returns:\n        Dictionary of data to be saved to arrow\n    \"\"\"\n    path = self.filepath.relative_to(data_dir)\n\n    with Image.open(self.filepath) as img:\n        stream_record = {\n            \"split_label\": split_label,\n            \"path\": path.as_posix(),\n            \"height\": img.height,\n            \"width\": img.width,\n            \"bytes\": img.tobytes(),\n            \"mode\": img.mode,\n        }\n    return stream_record\n</code></pre>"},{"location":"interfaces/data/datasets/#example-writing-metadata","title":"Example Writing Metadata","text":"<pre><code># create images\nfrom opsml import ImageRecord, ImageMetadata, BBox\n\nrecords = []\nrecord.append(ImageRecord(\n        filepath=Path(\"image_dir/opsml.jpg\"),\n        caption=\"This is a caption for the image\",\n        categories=[0],\n        objects=BBox(\n            bbox=[[302.0, 109.0, 73.0, 52.0]],\n            categories=[0]\n        ),\n    )\n)\n\nImageMetadata(records=records).write_to_file(Path(\"image_dir/metadata.jsonl\"))\n</code></pre>"},{"location":"interfaces/data/datasets/#example-using-imagedataset","title":"Example Using ImageDataset","text":"<pre><code>from opsml import ImageDataset, CardInfo, DataCard, CardRegistry\n\ninfo = CardInfo(name=\"data\", repository=\"opsml\", contact=\"user@email.com\")\ndata_registry = CardRegistry(\"data\")\n\ndata = ImageDataset(path=Path(\"image_dir\"))\n\n# Create and register datacard\ndatacard = DataCard(interface=interface, info=info)\ndata_registry.register_card(card=datacard)\n</code></pre>"},{"location":"interfaces/data/datasets/#textdataset","title":"TextDataset","text":"<p><code>TextDataset</code> is a subclass of <code>Dataset</code> that is used to load and save test data. It is similar to <code>HuggingFace</code> datasets, which was intentional in order to maintain some level of parity.</p> Data Type <code>Directory of text files</code> Save Format <code>parquet</code> Source <code>TextDataset</code>"},{"location":"interfaces/data/datasets/#textmetadata","title":"TextMetadata","text":"<p><code>TextMetadata</code> is the metadata subclass that is associated with <code>TextDataset</code>.</p>"},{"location":"interfaces/data/datasets/#required-arguments_2","title":"Required Arguments","text":"<code>records</code> List of <code>TextRecords</code>"},{"location":"interfaces/data/datasets/#opsml.TextMetadata","title":"<code>opsml.TextMetadata</code>","text":"<p>             Bases: <code>Metadata</code></p> <p>Create Image metadata from a list of ImageRecords</p> <p>Args:</p> <pre><code>records:\n    List of ImageRecords\n</code></pre> Source code in <code>opsml/data/interfaces/custom_data/text.py</code> <pre><code>class TextMetadata(Metadata):\n    \"\"\"Create Image metadata from a list of ImageRecords\n\n    Args:\n\n        records:\n            List of ImageRecords\n    \"\"\"\n\n    records: List[TextRecord]\n\n    @classmethod\n    def load_from_file(cls, filepath: Path) -&gt; \"TextMetadata\":\n        \"\"\"Load metadata from a file\n\n        Args:\n            filepath:\n                Path to metadata file\n        \"\"\"\n        assert filepath.name == \"metadata.jsonl\", \"Filename must be metadata.jsonl\"\n        with filepath.open(\"r\", encoding=\"utf-8\") as file_:\n            records = []\n            for line in file_:\n                records.append(TextRecord(**json.loads(line)))\n            return cls(records=records)\n</code></pre>"},{"location":"interfaces/data/datasets/#opsml.TextMetadata.load_from_file","title":"<code>load_from_file(filepath)</code>  <code>classmethod</code>","text":"<p>Load metadata from a file</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Path</code> <p>Path to metadata file</p> required Source code in <code>opsml/data/interfaces/custom_data/text.py</code> <pre><code>@classmethod\ndef load_from_file(cls, filepath: Path) -&gt; \"TextMetadata\":\n    \"\"\"Load metadata from a file\n\n    Args:\n        filepath:\n            Path to metadata file\n    \"\"\"\n    assert filepath.name == \"metadata.jsonl\", \"Filename must be metadata.jsonl\"\n    with filepath.open(\"r\", encoding=\"utf-8\") as file_:\n        records = []\n        for line in file_:\n            records.append(TextRecord(**json.loads(line)))\n        return cls(records=records)\n</code></pre>"},{"location":"interfaces/data/datasets/#textrecord","title":"TextRecord","text":"<p><code>TextRecord</code> is the <code>FileRecord</code> subclass that is associated with <code>TextMetadata</code>.</p>"},{"location":"interfaces/data/datasets/#required-arguments_3","title":"Required Arguments","text":"<code>filepath</code> Pathlike object to image file"},{"location":"interfaces/data/datasets/#opsml.TextRecord","title":"<code>opsml.TextRecord</code>","text":"<p>             Bases: <code>FileRecord</code></p> <p>Text record to associate with text file</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <p>Full path to the file</p> required <code>size</code> <p>Size of the file. This is inferred automatically if filepath is provided.</p> required Source code in <code>opsml/data/interfaces/custom_data/text.py</code> <pre><code>class TextRecord(FileRecord):\n    \"\"\"Text record to associate with text file\n\n    Args:\n        filepath:\n            Full path to the file\n        size:\n            Size of the file. This is inferred automatically if filepath is provided.\n\n    \"\"\"\n\n    def to_arrow(self, data_dir: Path, split_label: Optional[str] = None) -&gt; Dict[str, Any]:\n        \"\"\"Saves data to arrow format\n\n        Args:\n            data_dir:\n                Path to data directory\n            split_label:\n                Optional split label for data\n\n        Returns:\n            Dictionary of data to be saved to arrow\n        \"\"\"\n        path = self.filepath.relative_to(data_dir)\n\n        # write file\n        with open(self.filepath, \"rb\") as file_:\n            stream_record = {\n                \"split_label\": split_label,\n                \"path\": path.as_posix(),\n                \"bytes\": file_.read(),\n            }\n        return stream_record\n</code></pre>"},{"location":"interfaces/data/datasets/#opsml.TextRecord.to_arrow","title":"<code>to_arrow(data_dir, split_label=None)</code>","text":"<p>Saves data to arrow format</p> <p>Parameters:</p> Name Type Description Default <code>data_dir</code> <code>Path</code> <p>Path to data directory</p> required <code>split_label</code> <code>Optional[str]</code> <p>Optional split label for data</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary of data to be saved to arrow</p> Source code in <code>opsml/data/interfaces/custom_data/text.py</code> <pre><code>def to_arrow(self, data_dir: Path, split_label: Optional[str] = None) -&gt; Dict[str, Any]:\n    \"\"\"Saves data to arrow format\n\n    Args:\n        data_dir:\n            Path to data directory\n        split_label:\n            Optional split label for data\n\n    Returns:\n        Dictionary of data to be saved to arrow\n    \"\"\"\n    path = self.filepath.relative_to(data_dir)\n\n    # write file\n    with open(self.filepath, \"rb\") as file_:\n        stream_record = {\n            \"split_label\": split_label,\n            \"path\": path.as_posix(),\n            \"bytes\": file_.read(),\n        }\n    return stream_record\n</code></pre>"},{"location":"interfaces/data/datasets/#example-writing-metadata_1","title":"Example Writing Metadata","text":"<pre><code>from opsml import TextMetadata, TextRecord\n\nrecord = TextRecord(filepath=Path(\"text_dir/opsml.txt\"))\n\nTextMetadata(records=[record]).write_to_file(Path(\"text_dir/metadata.jsonl\"))\n</code></pre>"},{"location":"interfaces/data/datasets/#example-using-textdataset","title":"Example Using TextDataset","text":"<pre><code>from opsml import TextDataset, CardInfo, DataCard, CardRegistry\n\ninfo = CardInfo(name=\"data\", repository=\"opsml\", contact=\"user@email.com\")\ndata_registry = CardRegistry(\"data\")\n\ndata = TextDataset(path=Path(\"text_dir\"))\n\n# Create and register datacard\ndatacard = DataCard(interface=interface, info=info)\ndata_registry.register_card(card=datacard)\n</code></pre>"},{"location":"interfaces/data/feature/","title":"Feature","text":"<p>Feature is a pydantic data structure for holding feature type and shape information for a given feature. It is used in the <code>DataInterface</code> class to automatically store feature information.</p>"},{"location":"interfaces/data/feature/#opsml.types.Feature","title":"<code>opsml.types.Feature</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>opsml/types/model.py</code> <pre><code>class Feature(BaseModel):\n    feature_type: str\n    shape: Tuple[Any, ...]\n</code></pre>"},{"location":"interfaces/data/interfaces/","title":"Data Interface","text":"<p>The <code>DataInterface</code> is the primary interface for working with data in <code>Opsml</code>. It is designed to be subclassed and can be used to store data in a variety of formats depending on the library. Out of the box the following subclasses are available:</p> <ul> <li><code>PandasData</code>: Stores data from a pandas dataframe</li> <li><code>NumpyData</code>: Stores data from a numpy array</li> <li><code>PolarsData</code>: Stores data from a polars dataframe</li> <li><code>ArrowData</code>: Stores data from a pyarrow table</li> <li><code>ImageDataset</code>: Stores data from a directory of images</li> <li><code>TextDataset</code>: Stores data from a directory of text files</li> <li><code>TorchData</code>: Stores data from a torch tensor(s)</li> <li><code>SqlData</code>: Stores sql text</li> </ul>"},{"location":"interfaces/data/interfaces/#required-arguments","title":"Required Arguments","text":"<code>data</code>: See data interface for required type Data to save. See subclasses for supported data types <code>name</code>: <code>str</code> Name for the data <code>repository</code>: <code>str</code> Repository data belongs to <code>contact</code>: <code>str</code> Contact information (can be anything you define such as an email or slack channel) (Required)"},{"location":"interfaces/data/interfaces/#optional-arguments","title":"Optional Arguments","text":"<code>sql_logic</code>: <code>Dict[str, str]</code> SQL query or path to sql file containing logic to build data. Required if <code>data</code> is not provided. <code>data_splits</code>: <code>List[DataSplit]</code> Split logic for your data. Optional list of <code>DataSplit</code>. See DataSplit for more information. <code>data_profile</code>: <code>Optional[ProfileReport]</code> <code>ydata-profiling</code> data profile. This can also be generated via <code>create_data_profile</code> method after instantiation. See DataProfile for more information. <code>feature_map</code>: <code>Dict[str, Feature]</code> Feature map for your data. Optional dictionary of <code>Feature</code>. See Feature for more information. This is automatically inferred from data. <code>feature_descriptions</code>: <code>Dict[str, str]</code> Optional dictionary of feature descriptions."},{"location":"interfaces/data/interfaces/#pandasdata","title":"PandasData","text":"<p>Information about the <code>PandasData</code> interface.</p> Data Type <code>pandas.DataFrame</code> Save Format <code>parquet</code> Source <code>PandasData</code>"},{"location":"interfaces/data/interfaces/#example","title":"Example","text":"<pre><code>from opsml import PandasData, CardInfo, DataCard, CardRegistry\nfrom opsml.helpers.data import create_fake_data\n\ninfo = CardInfo(name=\"data\", repository=\"opsml\", contact=\"user@email.com\")\ndata_registry = CardRegistry(\"data\")\n\n# create fake data\nX, _ = create_fake_data(n_samples=1000, task_type=\"regression\")\n\n# Create data interface\ninterface = PandasData(data=X)\n\n# Create and register datacard\ndatacard = DataCard(interface=interface, info=info)\ndata_registry.register_card(card=datacard)\n</code></pre>"},{"location":"interfaces/data/interfaces/#polarsdata","title":"PolarsData","text":"<p>Information about the <code>PandasData</code> interface.</p> Data Type <code>polars.DataFrame</code> Save Format <code>parquet</code> Source <code>PolarsData</code>"},{"location":"interfaces/data/interfaces/#example_1","title":"Example","text":"<pre><code>from opsml import PolarsData, CardInfo, DataCard, CardRegistry\nfrom opsml.helpers.data import create_fake_data\n\ninfo = CardInfo(name=\"data\", repository=\"opsml\", contact=\"user@email.com\")\ndata_registry = CardRegistry(\"data\")\n\n# create fake data\nX, _ = create_fake_data(n_samples=1000, task_type=\"regression\", to_polars=True)\n\n# Create data interface\ninterface = PolarsData(data=X)\n\n# Create and register datacard\ndatacard = DataCard(interface=interface, info=info)\ndata_registry.register_card(card=datacard)\n</code></pre>"},{"location":"interfaces/data/interfaces/#numpydata","title":"NumpyData","text":"<p>Information about the <code>NumpyData</code> interface.</p> Data Type <code>np.ndarray</code> Save Format <code>Zarr</code> Source <code>NumpyData</code>"},{"location":"interfaces/data/interfaces/#example_2","title":"Example","text":"<pre><code>from opsml import NumpyData, CardInfo, DataCard, CardRegistry\nimport numpy as np\n\ninfo = CardInfo(name=\"data\", repository=\"opsml\", contact=\"user@email.com\")\ndata_registry = CardRegistry(\"data\")\n\ndata = np.random.rand(10, 100)\ninterface = NumpyData(data=data)\n\n# Create and register datacard\ndatacard = DataCard(interface=interface, info=info)\ndata_registry.register_card(card=datacard)\n</code></pre>"},{"location":"interfaces/data/interfaces/#arrowdata","title":"ArrowData","text":"<p>Information about the <code>ArrowData</code> interface.</p> Data Type <code>pa.Table</code> Save Format <code>parquet</code> Source <code>ArrowData</code>"},{"location":"interfaces/data/interfaces/#example_3","title":"Example","text":"<pre><code>from opsml import ArrowData, CardInfo, DataCard, CardRegistry\nimport pyarrow as pa\n\ninfo = CardInfo(name=\"data\", repository=\"opsml\", contact=\"user@email.com\")\ndata_registry = CardRegistry(\"data\")\n\nn_legs = pa.array([2, 4, 5, 100])\nanimals = pa.array([\"Flamingo\", \"Horse\", \"Brittle stars\", \"Centipede\"])\nnames = [\"n_legs\", \"animals\"]\ntable = pa.Table.from_arrays([n_legs, animals], names=names)\n\ninterface = ArrowData(data=table)\n\n# Create and register datacard\ndatacard = DataCard(interface=interface, info=info)\ndata_registry.register_card(card=datacard)\n</code></pre>"},{"location":"interfaces/data/interfaces/#torchdata","title":"TorchData","text":"<p>Information about the <code>TorchData</code> interface.</p> Data Type <code>torch.Tensor</code> Save Format <code>torch</code> Source <code>TorchData</code>"},{"location":"interfaces/data/interfaces/#example_4","title":"Example","text":"<pre><code>from opsml import TorchData, CardInfo, DataCard, CardRegistry\nimport torch\n\ninfo = CardInfo(name=\"data\", repository=\"opsml\", contact=\"user@email.com\")\ndata_registry = CardRegistry(\"data\")\n\nX = torch.Tensor([[1.0], [51.0], [89.0]])\n\ninterface = TorchData(data=table)\n\n# Create and register datacard\ndatacard = DataCard(interface=interface, info=info)\ndata_registry.register_card(card=datacard)\n</code></pre>"},{"location":"interfaces/data/interfaces/#sqldata","title":"SqlData","text":"<p>SqlData is an interface for storing sql logic in the event that you prefer to not save the data itself. This is useful for large datasets that you may not want to store in <code>Opsml</code> but still want to keep track of the logic used to generate the data.</p> Data Type <code>Dict[str, str]</code> Save Format <code>sql file</code> Source <code>SqlData</code>"},{"location":"interfaces/data/interfaces/#example_5","title":"Example","text":"<pre><code>from opsml import SqlData, CardInfo, DataCard, CardRegistry\n\ninfo = CardInfo(name=\"data\", repository=\"opsml\", contact=\"user@email.com\")\ndata_registry = CardRegistry(\"data\")\n\ndata = SqlData(sql_logic={\"my_logic\": \"select * from test_table\"})\n\n# or this would work\n\ndata = SqlData(sql_logic={\"my_logic\": \"path/to/file.sql\"})\n\n# Create and register datacard\ndatacard = DataCard(interface=interface, info=info)\ndata_registry.register_card(card=datacard)\n</code></pre>"},{"location":"interfaces/data/interfaces/#subclassing-datainterface","title":"Subclassing <code>DataInterface</code>","text":"<p>In the event that the currently supported <code>DataInterfaces</code> do not meet your needs, you can subclass the parent <code>DataInterface</code> and implement your own interface. However, there are a few requirements:</p> <ul> <li><code>save_data</code> method must be overwritten to your desired logic and must accept a <code>path</code> argument</li> <li><code>load_data</code> method must be overwritten to your desired logic and must accept a <code>path</code> argument</li> <li><code>data_suffix</code> property must be overwritten to return your specific data suffix (e.g. <code>.csv</code>, <code>.json</code>, etc.)</li> </ul> <p>These requirements are necessary for <code>Opsml</code> to properly save and load your data, as these are called during either saving or loading via the <code>DataCard</code>.</p>"},{"location":"interfaces/data/interfaces/#example_6","title":"Example","text":"<pre><code>from opsml import DataInterface, CardInfo, DataCard, CardRegistry\n\ninfo = CardInfo(name=\"data\", repository=\"opsml\", contact=\"opsml_user\")\nregistry = CardRegistry(\"data\")\n\n# DataInterface is a pydantic BaseModel\nclass MyDataInterface(DataInterface):\n\n    data: DataType\n\n    def save_data(self, path):\n        # save logic here\n\n    def load_data(self, path):\n        # load logic here\n\n    @property\n    def data_suffix(self):\n        return \".my_data\"\n\ninterface = MyDataInterface(data={{my_data}})\n\n# Create and register datacard\ndatacard = DataCard(interface=interface, info=info)\nregistry.register_card(card=datacard)\n\n# Now you can load your data via the registry\n# you will need to supply the interface subclass\ndatacard = registry.load_card(uid=datacard.uid, interface=MyDataInterface)\n</code></pre>"},{"location":"interfaces/data/interfaces/#final-note","title":"Final Note","text":"<p>It is up to you to make sure your subclass works as expected and is compatible with the <code>DataCard</code> class. If you feel your subclass is useful to others, please consider contributing it to the <code>Opsml</code> library. In addition, if using a custom subclass, others will not be able to load/use your <code>card</code> unless they have access to the custom subclass.</p>"},{"location":"interfaces/model/deployment/","title":"Deployment","text":"<p>While <code>Opsml</code> is not an all-in-one platform that will deploy your model in one click (maybe one day ), it does provide a helper class and a happy path to deploy your model. This is outlined below.</p> <pre><code>flowchart LR\n    subgraph Client\n    user(fa:fa-user DS) --&gt;|create| data(fa:fa-table Data)\n    data --&gt;|create|model(fa:fa-brain Model)\n    data --&gt;|package in|datacard(DataCard)\n    model --&gt;|package in|modelcard(ModelCard)\n    datacard --&gt;|associate|modelcard\n    end \n\n    subgraph Server\n    datacard --&gt;|insert into|datareg[(DataRegistry)]\n    modelcard --&gt;|insert into|modelreg[(ModelRegistry)]\n    end\n\n    subgraph CICD\n    modelreg --&gt; dir(Directory)\n    dir --&gt; |package|docker(DockerFile)\n    end\n\n\n    subgraph API\n    loaded(ModelLoader) --&gt;|load|loaded_model(Model)\n    end\n\n    docker --&gt; API\n\n    subgraph UI\n    vis(visualize)\n    end\n\n    user --&gt; vis\n    modelreg --&gt;|view in|UI\n    datareg --&gt;|view in|UI\n\n\n    style Client rx:10,ry:10\n    style Server rx:10,ry:10\n    style CICD rx:10,ry:10\n    style API rx:10,ry:10\n    style UI rx:10,ry:10\n\n\n    style user fill:#028e6b,stroke:black,stroke-width:2px,color:white,font-weight:bolder\n    style data fill:#028e6b,stroke:black,stroke-width:2px,color:white,font-weight:bolder\n    style model fill:#028e6b,stroke:black,stroke-width:2px,color:white,font-weight:bolder\n    style datacard fill:#028e6b,stroke:black,stroke-width:2px,color:white,font-weight:bolder\n    style modelcard fill:#028e6b,stroke:black,stroke-width:2px,color:white,font-weight:bolder\n    style loaded fill:#028e6b,stroke:black,stroke-width:2px,color:white,font-weight:bolder\n    style dir fill:#028e6b,stroke:black,stroke-width:2px,color:white,font-weight:bolder\n    style docker fill:#028e6b,stroke:black,stroke-width:2px,color:white,font-weight:bolder\n    style loaded_model fill:#028e6b,stroke:black,stroke-width:2px,color:white,font-weight:bolder\n    style vis fill:#028e6b,stroke:black,stroke-width:2px,color:white,font-weight:bolder\n\n    style datareg fill:#5e0fb7,stroke:black,stroke-width:2px,color:white,font-weight:bolder\n    style modelreg fill:#5e0fb7,stroke:black,stroke-width:2px,color:white,font-weight:bolder</code></pre>"},{"location":"interfaces/model/deployment/#steps","title":"Steps:","text":""},{"location":"interfaces/model/deployment/#ds-worflow","title":"DS Worflow","text":"<ol> <li>DS creates data and model</li> <li>DS packages data and model into appropriate interfaces and <code>DataCard</code> and <code>ModelCard</code>, respectively.</li> <li><code>DataCard</code> and <code>ModelCard</code> are registered and pushed to their respective registries.</li> </ol>"},{"location":"interfaces/model/deployment/#cicd-workflow","title":"CICD Workflow","text":"<ol> <li>During CICD, the model is downloaded from the <code>ModelRegistry</code> via the <code>Opsml CLI</code> to a directory</li> <li>Model directory and API logic are packaged into a docker image</li> </ol>"},{"location":"interfaces/model/deployment/#api-workflow","title":"API Workflow","text":"<ol> <li>Docker image is deployed to a server.</li> <li>During startup, the API logic leverages the <code>ModelLoader</code> class to load the model from the directory.</li> <li>Model is now ready to be used by the API.</li> </ol>"},{"location":"interfaces/model/deployment/#opsml.model.ModelLoader","title":"<code>opsml.model.ModelLoader</code>","text":"<p>Helper class for loading models from disk and downloading via opsml-cli</p> Source code in <code>opsml/model/loader.py</code> <pre><code>class ModelLoader:\n    \"\"\"Helper class for loading models from disk and downloading via opsml-cli\"\"\"\n\n    def __init__(self, path: Path):\n        \"\"\"Initialize ModelLoader\n\n        Args:\n            interface:\n                ModelInterface for the model\n            path:\n                Directory path to the model artifacts\n        \"\"\"\n\n        self.path = path\n        self.metadata = self._load_metadata()\n        self.interface = self._load_interface()\n\n    def _load_interface(self) -&gt; ModelInterface:\n        \"\"\"Loads a ModelInterface from disk using metadata\n\n        Args:\n            interface:\n                ModelInterface to load\n\n        Returns:\n            ModelInterface\n        \"\"\"\n        from opsml.storage.card_loader import _get_model_interface\n\n        Interface = _get_model_interface(self.metadata.model_interface)  # pylint: disable=invalid-name\n\n        loaded_interface = Interface.model_construct(\n            _fields_set={\"name\", \"repository\", \"version\"},\n            **{\n                \"name\": self.metadata.model_name,\n                \"repository\": self.metadata.model_repository,\n                \"version\": self.metadata.model_version,\n            },\n        )\n\n        loaded_interface.model_type = self.metadata.model_type\n\n        if hasattr(self.metadata, \"prepocessor_name\"):\n            loaded_interface.preprocessor_name = self.metadata.preprocessor_name\n\n        if hasattr(self.metadata, \"tokenizer_name\"):\n            loaded_interface.tokenizer_name = self.metadata.tokenizer_name\n\n        if hasattr(self.metadata, \"feature_extractor_name\"):\n            loaded_interface.feature_extractor_name = self.metadata.feature_extractor_name\n\n        return loaded_interface\n\n    @property\n    def model(self) -&gt; Any:\n        return self.interface.model\n\n    @property\n    def onnx_model(self) -&gt; OnnxModel:\n        assert self.interface.onnx_model is not None, \"OnnxModel not loaded\"\n        return self.interface.onnx_model\n\n    @property\n    def preprocessor(self) -&gt; Any:\n        \"\"\"Quick access to preprocessor from interface\"\"\"\n\n        if hasattr(self.interface, \"preprocessor\"):\n            return self.interface.preprocessor\n\n        if hasattr(self.interface, \"tokenizer\"):\n            if self.interface.tokenizer is not None:\n                return self.interface.tokenizer\n\n        if hasattr(self.interface, \"feature_extractor\"):\n            if self.interface.feature_extractor is not None:\n                return self.interface.feature_extractor\n\n        return None\n\n    def _load_metadata(self) -&gt; ModelMetadata:\n        \"\"\"Load metadata from disk\"\"\"\n        metadata_path = (self.path / SaveName.MODEL_METADATA.value).with_suffix(Suffix.JSON.value)\n\n        with metadata_path.open(\"r\") as file_:\n            return ModelMetadata(**json.load(file_))\n\n    def _load_huggingface_preprocessors(self) -&gt; None:\n        \"\"\"Load huggingface preprocessors from disk\"\"\"\n\n        assert isinstance(self.interface, HuggingFaceModel), \"HuggingFaceModel interface required\"\n\n        if self.preprocessor is not None:\n            return\n\n        if hasattr(self.metadata, \"tokenizer_name\"):\n            load_path = (self.path / SaveName.TOKENIZER.value).with_suffix(\"\")\n            self.interface.load_tokenizer(load_path)\n            return\n\n        if hasattr(self.metadata, \"feature_extractor_name\"):\n            load_path = (self.path / SaveName.FEATURE_EXTRACTOR.value).with_suffix(\"\")\n            self.interface.load_feature_extractor(load_path)\n            return\n\n        return\n\n    def load_preprocessor(self) -&gt; None:\n        \"\"\"Load preprocessor from disk\"\"\"\n\n        if isinstance(self.interface, HuggingFaceModel):\n            self._load_huggingface_preprocessors()\n            return\n\n        if hasattr(self.metadata, \"preprocessor_name\"):\n            load_path = (self.path / SaveName.PREPROCESSOR.value).with_suffix(self.interface.preprocessor_suffix)\n            self.interface.load_preprocessor(load_path)\n            return\n\n        return\n\n    def load_model(self, **kwargs: Any) -&gt; None:\n        load_path = (self.path / SaveName.TRAINED_MODEL.value).with_suffix(self.interface.model_suffix)\n        self.interface.load_model(load_path, **kwargs)\n\n        if isinstance(self.interface, HuggingFaceModel):\n            if self.interface.is_pipeline:\n                self.interface.to_pipeline()\n\n    def _load_huggingface_onnx_model(self, **kwargs: Any) -&gt; None:\n        assert isinstance(self.interface, HuggingFaceModel), \"Expected HuggingFaceModel\"\n        load_quantized = kwargs.get(\"load_quantized\", False)\n        save_name = SaveName.QUANTIZED_MODEL.value if load_quantized else SaveName.ONNX_MODEL.value\n\n        if self.interface.is_pipeline:\n            self._load_huggingface_preprocessors()\n\n        load_path = (self.path / save_name).with_suffix(self.interface.model_suffix)\n        self.interface.onnx_model = OnnxModel(onnx_version=self.metadata.onnx_version)\n        self.interface.load_onnx_model(load_path)\n\n    def load_onnx_model(self, **kwargs: Any) -&gt; None:\n        \"\"\"Load onnx model from disk\n\n        Kwargs:\n\n            ------Note: These kwargs only apply to HuggingFace models------\n\n            kwargs:\n                load_quantized:\n                    If True, load quantized model\n\n                onnx_args:\n                    Additional onnx args needed to load the model\n\n        \"\"\"\n        if isinstance(self.interface, HuggingFaceModel):\n            self.interface.onnx_args = kwargs.get(\"onnx_args\", None)\n            self._load_huggingface_onnx_model(**kwargs)\n            return\n\n        load_path = (self.path / SaveName.ONNX_MODEL.value).with_suffix(Suffix.ONNX.value)\n        self.interface.onnx_model = OnnxModel(onnx_version=self.metadata.onnx_version)\n        self.interface.load_onnx_model(load_path)\n        return\n</code></pre>"},{"location":"interfaces/model/deployment/#opsml.model.ModelLoader.preprocessor","title":"<code>preprocessor: Any</code>  <code>property</code>","text":"<p>Quick access to preprocessor from interface</p>"},{"location":"interfaces/model/deployment/#opsml.model.ModelLoader.__init__","title":"<code>__init__(path)</code>","text":"<p>Initialize ModelLoader</p> <p>Parameters:</p> Name Type Description Default <code>interface</code> <p>ModelInterface for the model</p> required <code>path</code> <code>Path</code> <p>Directory path to the model artifacts</p> required Source code in <code>opsml/model/loader.py</code> <pre><code>def __init__(self, path: Path):\n    \"\"\"Initialize ModelLoader\n\n    Args:\n        interface:\n            ModelInterface for the model\n        path:\n            Directory path to the model artifacts\n    \"\"\"\n\n    self.path = path\n    self.metadata = self._load_metadata()\n    self.interface = self._load_interface()\n</code></pre>"},{"location":"interfaces/model/deployment/#opsml.model.ModelLoader.load_onnx_model","title":"<code>load_onnx_model(**kwargs)</code>","text":"<p>Load onnx model from disk</p> <p>Kwargs:</p> <pre><code>------Note: These kwargs only apply to HuggingFace models------\n\nkwargs:\n    load_quantized:\n        If True, load quantized model\n\n    onnx_args:\n        Additional onnx args needed to load the model\n</code></pre> Source code in <code>opsml/model/loader.py</code> <pre><code>def load_onnx_model(self, **kwargs: Any) -&gt; None:\n    \"\"\"Load onnx model from disk\n\n    Kwargs:\n\n        ------Note: These kwargs only apply to HuggingFace models------\n\n        kwargs:\n            load_quantized:\n                If True, load quantized model\n\n            onnx_args:\n                Additional onnx args needed to load the model\n\n    \"\"\"\n    if isinstance(self.interface, HuggingFaceModel):\n        self.interface.onnx_args = kwargs.get(\"onnx_args\", None)\n        self._load_huggingface_onnx_model(**kwargs)\n        return\n\n    load_path = (self.path / SaveName.ONNX_MODEL.value).with_suffix(Suffix.ONNX.value)\n    self.interface.onnx_model = OnnxModel(onnx_version=self.metadata.onnx_version)\n    self.interface.load_onnx_model(load_path)\n    return\n</code></pre>"},{"location":"interfaces/model/deployment/#opsml.model.ModelLoader.load_preprocessor","title":"<code>load_preprocessor()</code>","text":"<p>Load preprocessor from disk</p> Source code in <code>opsml/model/loader.py</code> <pre><code>def load_preprocessor(self) -&gt; None:\n    \"\"\"Load preprocessor from disk\"\"\"\n\n    if isinstance(self.interface, HuggingFaceModel):\n        self._load_huggingface_preprocessors()\n        return\n\n    if hasattr(self.metadata, \"preprocessor_name\"):\n        load_path = (self.path / SaveName.PREPROCESSOR.value).with_suffix(self.interface.preprocessor_suffix)\n        self.interface.load_preprocessor(load_path)\n        return\n\n    return\n</code></pre>"},{"location":"interfaces/model/extras/","title":"Model Extras","text":"<p>In addition to interface and onnx-related objects, there are a few objects that may be of use when interactions with models. </p>"},{"location":"interfaces/model/extras/#huggingfaceortmodel","title":"HuggingFaceORTModel","text":"<p>The <code>HuggingFaceORTModel</code> is an enum that allows you to specify an ORT type for a <code>HuggingFaceModel</code>. Refer to the source code below for the available options.</p> <pre><code>from opsml import HuggingFaceORTModel, HuggingFaceOnnxArgs\n\nHuggingFaceOnnxArgs(\n    ort_type=HuggingFaceORTModel.ORT_SEQUENCE_CLASSIFICATION.value,\n    provider=\"CPUExecutionProvider\",\n    quantize=False,\n    )\n</code></pre>"},{"location":"interfaces/model/extras/#opsml.HuggingFaceORTModel","title":"<code>opsml.HuggingFaceORTModel</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> Source code in <code>opsml/types/huggingface.py</code> <pre><code>class HuggingFaceORTModel(str, Enum):\n    ORT_AUDIO_CLASSIFICATION = \"ORTModelForAudioClassification\"\n    ORT_AUDIO_FRAME_CLASSIFICATION = \"ORTModelForAudioFrameClassification\"\n    ORT_AUDIO_XVECTOR = \"ORTModelForAudioXVector\"\n    ORT_CUSTOM_TASKS = \"ORTModelForCustomTasks\"\n    ORT_CTC = \"ORTModelForCTC\"\n    ORT_FEATURE_EXTRACTION = \"ORTModelForFeatureExtraction\"\n    ORT_IMAGE_CLASSIFICATION = \"ORTModelForImageClassification\"\n    ORT_MASKED_LM = \"ORTModelForMaskedLM\"\n    ORT_MULTIPLE_CHOICE = \"ORTModelForMultipleChoice\"\n    ORT_QUESTION_ANSWERING = \"ORTModelForQuestionAnswering\"\n    ORT_SEMANTIC_SEGMENTATION = \"ORTModelForSemanticSegmentation\"\n    ORT_SEQUENCE_CLASSIFICATION = \"ORTModelForSequenceClassification\"\n    ORT_TOKEN_CLASSIFICATION = \"ORTModelForTokenClassification\"\n    ORT_SEQ2SEQ_LM = \"ORTModelForSeq2SeqLM\"\n    ORT_SPEECH_SEQ2SEQ = \"ORTModelForSpeechSeq2Seq\"\n    ORT_VISION2SEQ = \"ORTModelForVision2Seq\"\n    ORT_PIX2STRUCT = \"ORTModelForPix2Struct\"\n    ORT_CAUSAL_LM = \"ORTModelForCausalLM\"\n    ORT_OPTIMIZER = \"ORTOptimizer\"\n    ORT_QUANTIZER = \"ORTQuantizer\"\n    ORT_TRAINER = \"ORTTrainer\"\n    ORT_SEQ2SEQ_TRAINER = \"ORTSeq2SeqTrainer\"\n    ORT_TRAINING_ARGUMENTS = \"ORTTrainingArguments\"\n    ORT_SEQ2SEQ_TRAINING_ARGUMENTS = \"ORTSeq2SeqTrainingArguments\"\n    ORT_STABLE_DIFFUSION_PIPELINE = \"ORTStableDiffusionPipeline\"\n    ORT_STABLE_DIFFUSION_IMG2IMG_PIPELINE = \"ORTStableDiffusionImg2ImgPipeline\"\n    ORT_STABLE_DIFFUSION_INPAINT_PIPELINE = \"ORTStableDiffusionInpaintPipeline\"\n    ORT_STABLE_DIFFUSION_XL_PIPELINE = \"ORTStableDiffusionXLPipeline\"\n    ORT_STABLE_DIFFUSION_XL_IMG2IMG_PIPELINE = \"ORTStableDiffusionXLImg2ImgPipeline\"\n</code></pre>"},{"location":"interfaces/model/extras/#huggingfacetask","title":"HuggingFaceTask","text":"<p>HuggingFaceTask is an enum that allows you to specify a task type for a <code>HuggingFaceModel</code>. Refer to the source code below for the available options.</p> <pre><code>from opsml import HuggingFaceTask, HuggingFaceModel\n\nHuggingFaceModel(\n    model=model,\n    task_type=HuggingFaceTask.SEQUENCE_CLASSIFICATION.value,\n    )\n</code></pre>"},{"location":"interfaces/model/extras/#opsml.HuggingFaceTask","title":"<code>opsml.HuggingFaceTask</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> Source code in <code>opsml/types/huggingface.py</code> <pre><code>class HuggingFaceTask(str, Enum):\n    AUDIO_CLASSIFICATION = \"audio-classification\"\n    AUTOMATIC_SPEECH_RECOGNITION = \"automatic-speech-recognition\"\n    CONVERSATIONAL = \"conversational\"\n    DEPTH_ESTIMATION = \"depth-estimation\"\n    DOCUMENT_QUESTION_ANSWERING = \"document-question-answering\"\n    FEATURE_EXTRACTION = \"feature-extraction\"\n    FILL_MASK = \"fill-mask\"\n    IMAGE_CLASSIFICATION = \"image-classification\"\n    IMAGE_SEGMENTATION = \"image-segmentation\"\n    IMAGE_TO_IMAGE = \"image-to-image\"\n    IMAGE_TO_TEXT = \"image-to-text\"\n    MASK_GENERATION = \"mask-generation\"\n    OBJECT_DETECTION = \"object-detection\"\n    QUESTION_ANSWERING = \"question-answering\"\n    SUMMARIZATION = \"summarization\"\n    TABLE_QUESTION_ANSWERING = \"table-question-answering\"\n    TEXT2TEXT_GENERATION = \"text2text-generation\"\n    TEXT_CLASSIFICATION = \"text-classification\"\n    TEXT_GENERATION = \"text-generation\"\n    TEXT_TO_AUDIO = \"text-to-audio\"\n    TOKEN_CLASSIFICATION = \"token-classification\"\n    TRANSLATION = \"translation\"\n    TRANSLATION_XX_TO_YY = \"translation_xx_to_yy\"\n    VIDEO_CLASSIFICATION = \"video-classification\"\n    VISUAL_QUESTION_ANSWERING = \"visual-question-answering\"\n    ZERO_SHOT_CLASSIFICATION = \"zero-shot-classification\"\n    ZERO_SHOT_IMAGE_CLASSIFICATION = \"zero-shot-image-classification\"\n    ZERO_SHOT_AUDIO_CLASSIFICATION = \"zero-shot-audio-classification\"\n    ZERO_SHOT_OBJECT_DETECTION = \"zero-shot-object-detection\"\n</code></pre>"},{"location":"interfaces/model/extras/#torchsaveargs","title":"TorchSaveArgs","text":"<p>Optional <code>TorchModel</code> arguments for saving a <code>TorchModel</code> object. Only <code>as_state_dict</code> is currently supported. If True, the <code>TorchModel</code> model object's state dict will be</p>"},{"location":"interfaces/model/extras/#opsml.types.TorchSaveArgs","title":"<code>opsml.types.TorchSaveArgs</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Torch save arguments.</p> <p>Parameters:</p> Name Type Description Default <code>as_state_dict</code> <p>Indicates to save the torch model in state_dict format. If True, the model architecture will need to be provided at load time.</p> required Source code in <code>opsml/types/model.py</code> <pre><code>class TorchSaveArgs(BaseModel):\n    \"\"\"Torch save arguments.\n\n    Args:\n        as_state_dict:\n            Indicates to save the torch model in state_dict format. If True, the model\n            architecture will need to be provided at load time.\n    \"\"\"\n\n    as_state_dict: bool = False\n</code></pre>"},{"location":"interfaces/model/extras/#onnxmodel","title":"OnnxModel","text":"<p>OnnxModel is a pydantic class that is used to store converted onnx models. In the case of a BYO onnx model, you will need to supply an <code>OnnxModel</code> object to the <code>ModelInterface</code> class.</p> <pre><code>from opsml import OnnxModel, TorchModel\nimport onnx\nimport onnxruntime as ort\n\n# Super Resolution model definition in PyTorch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torch.onnx\nimport torch.utils.model_zoo as model_zoo\nfrom torch import nn\n\nclass SuperResolutionNet(nn.Module):\n    def __init__(self, upscale_factor, inplace=False):\n        super(SuperResolutionNet, self).__init__()\n\n        self.relu = nn.ReLU(inplace=inplace)\n        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n        self.conv4 = nn.Conv2d(32, upscale_factor**2, (3, 3), (1, 1), (1, 1))\n        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n\n        self._initialize_weights()\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.pixel_shuffle(self.conv4(x))\n        return x\n\n    def _initialize_weights(self):\n        init.orthogonal_(self.conv1.weight, init.calculate_gain(\"relu\"))\n        init.orthogonal_(self.conv2.weight, init.calculate_gain(\"relu\"))\n        init.orthogonal_(self.conv3.weight, init.calculate_gain(\"relu\"))\n        init.orthogonal_(self.conv4.weight)\n\n# Create the super-resolution model by using the above model definition.\ntorch_model = SuperResolutionNet(upscale_factor=3)\n\n# Load pretrained model weights\nmodel_url = \"https://s3.amazonaws.com/pytorch/test_data/export/superres_epoch100-44c6958e.pth\"\nbatch_size = 1  # just a random number\n\n# Initialize model with the pretrained weights\ndef map_location(storage, loc):\n    return storage\n\nif torch.cuda.is_available():\n    map_location = None\ntorch_model.load_state_dict(model_zoo.load_url(model_url, map_location=map_location))\n\n# set the model to inference mode\ntorch_model.eval()\n\n# Input to the model\nx = torch.randn(batch_size, 1, 224, 224, requires_grad=True)\ntorch_model(x)\n\nwith tempfile.TemporaryDirectory() as tmpdir:\n    onnx_path = f\"{tmpdir}/super_resolution.onnx\"\n    # Export the model\n    torch.onnx.export(\n        torch_model,  # model being run\n        x,  # model input (or a tuple for multiple inputs)\n        onnx_path,  # where to save the model (can be a file or file-like object)\n        export_params=True,  # store the trained parameter weights inside the model file\n        opset_version=10,  # the ONNX version to export the model to\n        do_constant_folding=True,  # whether to execute constant folding for optimization\n        input_names=[\"input\"],  # the model's input names\n        output_names=[\"output\"],  # the model's output names\n        dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}},  # variable length axes\n    )\n\n    onnx_model = onnx.load(onnx_path)\n\n    ort_sess = ort.InferenceSession(onnx_model.SerializeToString())\n\nonnx_model = OnnxModel(onnx_version=\"1.14.0\", sess=ort_sess)\n\ninterface = TorchModel(\n    model=torch_model,\n    sample_data=x,\n    onnx_model=onnx_model,\n    save_args={\"as_state_dict\": True},\n)\n</code></pre>"},{"location":"interfaces/model/extras/#opsml.types.OnnxModel","title":"<code>opsml.types.OnnxModel</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>opsml/types/model.py</code> <pre><code>class OnnxModel(BaseModel):\n    onnx_version: str = Field(..., description=\"Version of onnx model used to create proto\")\n    sess: Union[OnnxInferenceSession, ORTModel, Pipeline] = Field(default=None, description=\"Onnx model session\")  # type: ignore\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    def sess_to_path(self, path: Path) -&gt; None:\n        \"\"\"Helper method for taking existing onnx model session and saving to path\n\n        Args:\n            path:\n                Path to save onnx model\n        \"\"\"\n\n        if not isinstance(self.sess, rt.InferenceSession):\n            return\n\n        logger.info(\"Saving existing onnx model\")\n\n        if self.sess._model_bytes:  # pylint: disable=protected-access\n            path.write_bytes(self.sess._model_bytes)  # pylint: disable=protected-access\n\n        else:\n            # copy model path to new path\n            from fsspec.implementations.local import LocalFileSystem\n\n            file_sys = LocalFileSystem()\n            lpath = self.sess._model_path  # pylint: disable=protected-access\n            file_sys.copy(lpath, str(path))\n\n        return\n</code></pre>"},{"location":"interfaces/model/extras/#opsml.types.OnnxModel.sess_to_path","title":"<code>sess_to_path(path)</code>","text":"<p>Helper method for taking existing onnx model session and saving to path</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to save onnx model</p> required Source code in <code>opsml/types/model.py</code> <pre><code>def sess_to_path(self, path: Path) -&gt; None:\n    \"\"\"Helper method for taking existing onnx model session and saving to path\n\n    Args:\n        path:\n            Path to save onnx model\n    \"\"\"\n\n    if not isinstance(self.sess, rt.InferenceSession):\n        return\n\n    logger.info(\"Saving existing onnx model\")\n\n    if self.sess._model_bytes:  # pylint: disable=protected-access\n        path.write_bytes(self.sess._model_bytes)  # pylint: disable=protected-access\n\n    else:\n        # copy model path to new path\n        from fsspec.implementations.local import LocalFileSystem\n\n        file_sys = LocalFileSystem()\n        lpath = self.sess._model_path  # pylint: disable=protected-access\n        file_sys.copy(lpath, str(path))\n\n    return\n</code></pre>"},{"location":"interfaces/model/interfaces/","title":"Model Interface","text":"<p>The <code>ModelInterface</code> is the primary interface for working with models in <code>Opsml</code>. It is designed to be subclassed and can be used to store models in a variety of formats depending on the library. Out of the box the following subclasses are available:</p> <ul> <li><code>SklearnModel</code>: Stores data from a sklearn model</li> <li><code>TorchModel</code>: Stores data from a pytorch model</li> <li><code>LightningModel</code>: Stores data from a pytorch lightning model</li> <li><code>HuggingFaceModel</code>: Stores data from a huggingface model</li> <li><code>TensorFlowModel</code>: Stores data from a tensorflow model</li> <li><code>XGBoostModel</code>: Stores data from a xgboost model</li> <li><code>LightGBMModel</code>: Stores data from a lightgbm model</li> <li><code>CatBoostModel</code>: Stores data from a catboost model</li> </ul>"},{"location":"interfaces/model/interfaces/#required-arguments","title":"Required Arguments","text":"<code>model</code> Model to save. See subclasses for supported model types <code>sample_data</code> Sample of data that is fed to the model at inference time. As an example, if you are using a <code>SklearnModel</code> you would provide a numpy array at prediction time, so <code>sample_data</code> should be a numpy array for X features."},{"location":"interfaces/model/interfaces/#optional-arguments","title":"Optional Arguments","text":"<code>onnx_model</code> <code>OnnxModel</code> object. This is typically auto-generated when creating a <code>ModelCard</code> with <code>to_onnx=True</code>. You can also BYO <code>OnnxModel</code> object. See OnnxModel for more information. <code>task_type</code> Task type of the model. This is mainly used for <code>HuggingFaceModel</code>, but can be supplied for any model interface if the user chooses."},{"location":"interfaces/model/interfaces/#sklearnmodel","title":"SklearnModel","text":"<p>Interface for saving an Sklearn model</p> Model Type <code>sklearn.base.BaseEstimator</code> Save Format <code>joblib</code> Source <code>SklearnModel</code> Example <code>Link</code>"},{"location":"interfaces/model/interfaces/#arguments","title":"Arguments","text":"<code>model</code>: <code>BaseEstimator</code> Sklearn model <code>preprocessor</code>: <code>Optional[Any]</code> Optional preprocessor <code>sample_data</code>: <code>Union[pd.DataFrame, NDArray[Any]]</code> Sample data to be used for model inference. For sklearn models this should be a pandas DataFrame or numpy array. This should match exactly what the model expects as input."},{"location":"interfaces/model/interfaces/#example","title":"Example","text":"<pre><code>from opsml import SklearnModel, CardInfo, ModelCard, CardRegistry\nfrom sklearn.linear_model import LinearRegression\n\ninfo = CardInfo(name=\"model\", repository=\"opsml\", contact=\"user@email.com\")\nmodel_registry = CardRegistry(\"model\")\n\n# Skipping data step\n...\n\nreg = LinearRegression()\nreg.fit(X_train, y_train)\n\n# create model interface\ninterface = SklearnModel(model=reg,sample_data=X_train)\n\n# create modelcard\nmodelcard = ModelCard(\n    interface=interface,\n    info=info,\n    to_onnx=True,  # lets convert onnx\n    datacard_uid=datacard.uid,\n)\n\nmodel_registry.register_card(card=modelcard)\n</code></pre>"},{"location":"interfaces/model/interfaces/#lightgbmmodel","title":"LightGBMModel","text":"<p>Interface for saving a LightGBM booster or sklearn flavor model</p> Model Type <code>Booster</code> or <code>LGBMModel</code> Save Format <code>text</code> or <code>joblib</code> Source <code>LightGBMModel</code> Example 1 <code>Link</code> Example 2 <code>Link</code>"},{"location":"interfaces/model/interfaces/#arguments_1","title":"Arguments","text":"<code>model</code>: <code>Union[Booster, LGBMModel]</code> LightGBM booster or Sklearn flavor model <code>preprocessor</code>: <code>Optional[Any]</code> Optional preprocessor <code>sample_data</code>: <code>Union[pd.DataFrame, NDArray[Any]]</code> Sample data to be used for model inference."},{"location":"interfaces/model/interfaces/#example_1","title":"Example","text":"<pre><code>from opsml import LightGBMModel, CardInfo, ModelCard, CardRegistry\nfrom sklearn.preprocessing import StandardScaler\nimport lightgbm as lgb\n\ninfo = CardInfo(name=\"model\", repository=\"opsml\", contact=\"user@email.com\")\nmodel_registry = CardRegistry(\"model\")\n\n# Skipping data step\n...\n\nscaler = StandardScaler()\nX_train = scaler.transform(X)\nX_test = scaler.transform(X)\n\nlgb_train = lgb.Dataset(X_train, y_train)\nlgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n\n# train model\ngbm = lgb.train(params, lgb_train, ...)\n\n# fit model\ninterface = LightGBMModel(model=gbm, sample_data=X_train[:100], preprocessor=scaler)\n\n# create modelcard\nmodelcard = ModelCard(\n    interface=interface,\n    info=info,\n    to_onnx=True,\n    datacard_uid=datacard.uid,\n)\nmodel_registry.register_card(card=modelcard)\n</code></pre>"},{"location":"interfaces/model/interfaces/#xgboostmodel","title":"XGBoostModel","text":"<p>Interface for saving a XGBoost model. Only sklearn flavor is currently supported. <code>XGBoostModel</code> is a subclass of <code>SklearnModel</code>.</p> Model Type <code>XGBModel</code> Save Format <code>joblib</code> Source <code>XGBoostModel</code> Example <code>Link</code>"},{"location":"interfaces/model/interfaces/#arguments_2","title":"Arguments","text":"<code>model</code>: <code>XGBModel</code> XGBoost model <code>preprocessor</code>: <code>Optional[Any]</code> Optional preprocessor <code>sample_data</code>: <code>Union[pd.DataFrame, NDArray[Any]]</code> Sample data to be used for model inference. For xgboost models this should be a pandas DataFrame or numpy array. This should match exactly what the model expects as input. See example below."},{"location":"interfaces/model/interfaces/#example_2","title":"Example","text":"<pre><code>from opsml import XGBoostModel, CardInfo, ModelCard, CardRegistry\nimport xgboost as xgb\n\ninfo = CardInfo(name=\"model\", repository=\"opsml\", contact=\"user@email.com\")\nmodel_registry = CardRegistry(\"model\")\n\n# Skipping data step\n...\n\nreg = xgb.XGBRegressor(n_estimators=3, max_depth=3)\nreg.fit(X_train, y_train)\n\n# create model interface\ninterface = XGBoostModel(model=reg, sample_data=data[\"train\"].X.to_numpy()[:, 0:5])\n\n# create modelcard\nmodelcard = ModelCard(info=info, interface=interface, datacard_uid=datacard.uid)\n\n# register\nmodel_registry.register_card(card=modelcard)\n</code></pre>"},{"location":"interfaces/model/interfaces/#catboostmodel","title":"CatBoostModel","text":"<p>Interface for saving a CatBoost model.</p> Model Type <code>CatBoost</code> Save Format <code>cbm</code> Source <code>CatBoostModel</code> Example <code>Link</code>"},{"location":"interfaces/model/interfaces/#arguments_3","title":"Arguments","text":"<code>model</code>: <code>CatBoost</code> CatBoost Regressor, Classifier or Ranker <code>preprocessor</code>: <code>Optional[Any]</code> Optional preprocessor <code>sample_data</code>: <code>Union[List[Any], NDArray[Any]]</code> Sample data to be used for model inference. For catboost models this is either a list or numpy array."},{"location":"interfaces/model/interfaces/#example_3","title":"Example","text":"<pre><code>from opsml import CatBoostModel, CardInfo, ModelCard, CardRegistry\nimport catboost\n\ninfo = CardInfo(name=\"model\", repository=\"opsml\", contact=\"user@email.com\")\nmodel_registry = CardRegistry(\"model\")\n\n# Skipping data step\n...\n\nclf = catboost.CatBoostClassifier()\nclf.fit(X_train, y_train)\n\n# create model interface\ninterface = CatBoostModel(model=clf, sample_data=X_train)\n\n# create modelcard\nmodelcard = ModelCard(info=info, interface=interface, datacard_uid=datacard.uid)\n\n# register\nmodel_registry.register_card(card=modelcard)\n</code></pre>"},{"location":"interfaces/model/interfaces/#torchmodel","title":"TorchModel","text":"<p>Interface for saving a PyTorch model.</p> Model Type <code>torch.nn.Module</code> Save Format <code>torch</code> Source <code>TorchModel</code> Example <code>Link</code>"},{"location":"interfaces/model/interfaces/#arguments_4","title":"Arguments","text":"<code>model</code>: <code>torch.nn.Module</code> A pytorch model that subclasses <code>torch.nn.Module</code> <code>preprocessor</code>: <code>Optional[Any]</code> Optional preprocessor <code>sample_data</code>: <code>Union[torch.Tensor, Dict[str, torch.Tensor], List[torch.Tensor], Tuple[torch.Tensor]]</code> Sample data to be used for model inference. <code>save_args</code>: `Optional[TorchSaveArgs] Optional arguments for saving the model. See TorchSaveArgs for more information. <code>onnx_args</code>: <code>Optional[TorchOnnxArgs]</code> Optional arguments for converting to onnx. See TorchOnnxArgs for more information."},{"location":"interfaces/model/interfaces/#note-on-saving-and-loading","title":"Note On Saving and Loading","text":"<p>If you wish to save the model's state dict, as is recommended by pytorch, you will need to specify <code>save_args=TorchSaveArgs(as_state_dict=True)</code> or <code>save_args{\"as_state_dict\": True}</code> to the <code>TorchModel</code> interface. This will save the model's learned parameters ONLY. If you wish to load the state dict back into the model during loading, you can supply an optional <code>model_arch</code> named attr to <code>load_model</code> that will be used to load the state dict (<code>load_model(model_arch=model)</code>). If you do not supply a <code>model_arch</code> only the state dict will be loaded into the model. If you do not specify <code>save_args</code>, pytorch will attempt to save the model architecture which may raise a <code>local object pickle error</code>.</p>"},{"location":"interfaces/model/interfaces/#example_4","title":"Example","text":"<pre><code>from opsml import TorchModel, CardInfo, ModelCard, CardRegistry\nfrom examples.torch.polynomial_nn import Polynomial3 # see examples/torch/polynomial_nn.py\n\ninfo = CardInfo(name=\"model\", repository=\"opsml\", contact=\"user@email.com\")\nmodel_registry = CardRegistry(\"model\")\n\n# Skipping data step\n...\n\n# instantiate model\nmodel = Polynomial3()\nmodel.train_model(X, y)\n\n# torch interface\ninterface = TorchModel(\n    model=model, \n    sample_data=X, \n    save_args= TorchSaveArgs(as_state_dict=True),\n)\n\n# create modelcard\nmodelcard = ModelCard(\n    interface=interface,\n    info=info,\n    to_onnx=True, \n    datacard_uid=datacard.uid,  \n)\n\n# register\nmodel_registry.register_card(card=modelcard)\n\n# load card\nmodelcard = model_registry.load_card()\nmodelcard.load_model(model_arch=model)\n</code></pre>"},{"location":"interfaces/model/interfaces/#lightningmodel","title":"LightningModel","text":"<p>Interface for saving a PyTorch Lightning model.</p> Model Type <code>Trainer</code> Save Format <code>ckpt</code> Source <code>LightningModel</code> Example <code>Link</code>"},{"location":"interfaces/model/interfaces/#arguments_5","title":"Arguments","text":"<code>model</code>: <code>Trainer</code> A pytorch lightning <code>Trainer</code> object <code>preprocessor</code>: <code>Optional[Any]</code> Optional preprocessor <code>sample_data</code>: <code>Union[torch.Tensor, Dict[str, torch.Tensor], List[torch.Tensor], Tuple[torch.Tensor]]</code> Sample data to be used for model inference. <code>onnx_args</code>: <code>Optional[TorchOnnxArgs]</code> Optional arguments for converting to onnx. See TorchOnnxArgs for more information."},{"location":"interfaces/model/interfaces/#note-on-saving-and-loading_1","title":"Note on Saving and Loading","text":"<p>During saving, <code>LightningModel</code> will extract the model from the trainer and save a checkpoint. Upon loading, you can supply an optional <code>model_arch</code> argument to <code>load_model</code> (e.g. <code>load_model(model_arch=model)</code>) to load the model from a checkpoint. If no model architecture is provided, the checkpoint will be loaded from the path object via <code>torch.load</code>.</p>"},{"location":"interfaces/model/interfaces/#example_5","title":"Example","text":"<pre><code>from opsml import LightningModel, TorchOnnxArgs, CardInfo, ModelCard, CardRegistry\nfrom examples.torch.lightning_module import RegressionModel # see examples/torch/\nimport lightning as L\n\ninfo = CardInfo(name=\"model\", repository=\"opsml\", contact=\"user@email.com\")\nmodel_registry = CardRegistry(\"model\")\n\n# Skipping data step\n...\n\n# fit model\nmodel = RegressionModel()\ntrainer = L.Trainer(max_epochs=10)\ntrainer.fit(model)\n\n\n# lightning interface\ninterface = LightningModel(\n    model=trainer,\n    sample_data=X,\n    onnx_args=TorchOnnxArgs(\n        input_names=[\"predict\"],\n        output_names=[\"output\"],\n        dynamic_axes={\"predict\": {0: \"batch_size\"}},  # allow for &gt;=1 batch size\n    ),\n)\n\n# create modelcard\nmodelcard = ModelCard(\n    interface=interface,\n    info=info,\n    to_onnx=True, \n    datacard_uid=datacard.uid,  \n)\n\n# register\nmodel_registry.register_card(card=modelcard)\n\n# load\nmodelcard = model_registry.load_card()\nmodelcard.load_model(model_arch=model)\n</code></pre>"},{"location":"interfaces/model/interfaces/#tensorflowmodel","title":"TensorFlowModel","text":"<p>Interface for saving a tensorflow model.</p> Model Type <code>tf.keras.Model</code> Save Format <code>tensorflow</code> Source <code>TensorFlowModel</code> Example <code>Link</code>"},{"location":"interfaces/model/interfaces/#arguments_6","title":"Arguments","text":"<code>model</code>: <code>tf.keras.Model</code> A tensorflow model that subclasses <code>tf.keras.Model</code> <code>preprocessor</code>: <code>Optional[Any]</code> Optional preprocessor <code>sample_data</code>: <code>Union[ArrayType, Dict[str, ArrayType], List[ArrayType], Tuple[ArrayType]]</code> (ArrayType= <code>Union[NDArray[Any], tf.Tensor]</code>) Sample data to be used for model inference."},{"location":"interfaces/model/interfaces/#example_6","title":"Example","text":"<pre><code>from opsml import TensorFlowModel, CardInfo, ModelCard, CardRegistry\nimport tensorflow as tf \n\ninfo = CardInfo(name=\"model\", repository=\"opsml\", contact=\"user@email.com\")\nmodel_registry = CardRegistry(\"model\")\n\n# Skipping data step\n...\n\n# build and compile model\nmodel = tf.keras.Sequential(\n    [\n        keras.layers.Dense(64, activation=\"relu\"),\n        keras.layers.Dense(64, activation=\"relu\"),\n        keras.layers.Dense(1),\n    ]\n)\nmodel.compile(loss=\"mean_absolute_error\", optimizer=tf.keras.optimizers.Adam(0.001))\nmodel.fit(X, y, epochs=10)\n\n# tensorflow interface\ninterface = TensorFlowModel(model=model, sample_data=X)\n\n# create modelcard\nmodelcard = ModelCard(\n    interface=interface,\n    info=info,\n    to_onnx=True, \n    datacard_uid=datacard.uid,  \n)\n\n# register\nmodel_registry.register_card(card=modelcard)\n</code></pre>"},{"location":"interfaces/model/interfaces/#huggingfacemodel","title":"HuggingFaceModel","text":"<p>Interface for saving a huggingface model.</p> Model Type <code>Union[Pipeline, PreTrainedModel, TFPreTrainedModel]</code> Save Format <code>huggingface</code> Source <code>HuggingFaceModel</code> Example <code>Link</code>"},{"location":"interfaces/model/interfaces/#arguments_7","title":"Arguments","text":"<code>model</code>: <code>Union[Pipeline, PreTrainedModel, TFPreTrainedModel]</code> A huggingface model that subclasses <code>Pipeline</code>, <code>PreTrainedModel</code> or <code>TFPreTrainedModel</code> <code>tokenizer</code>: <code>Optional[Union[PreTrainedTokenizer, PreTrainedTokenizerFast]]</code> Optional huggingface tokenizer <code>feature_extractor</code>: <code>Optional[Union[FeatureExtractionMixin, ImageProcessingMixin]]</code> Optional huggingface feature extractor <code>sample_data</code>: <code>Union[list, tuple, dict, BatchEncoding, BatchFeature, str, ImageFile]</code> Sample data to be used for model inference. <code>onnx_args</code>: <code>Optional[HuggingFaceOnnxArgs]</code> Optional arguments for converting to onnx. See HuggingFaceOnnxArgs for more information. <code>task_type</code>: <code>str</code> Model task. Must be task from <code>HuggingFaceTask</code>. See HuggingFaceTask for more information."},{"location":"interfaces/model/interfaces/#example_7","title":"Example","text":"<pre><code>from opsml import HuggingFaceModel, HuggingFaceOnnxArgs, HuggingFaceORTModel, HuggingFaceTask, CardInfo, ModelCard, CardRegistry\nfrom transformers import BartModel, BartTokenizer\n\ninfo = CardInfo(name=\"model\", repository=\"opsml\", contact=\"user@email.com\")\nmodel_registry = CardRegistry(\"model\")\n\n# Skipping data step\n...\n\ntokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\nmodel = BartModel.from_pretrained(\"facebook/bart-base\")\ninputs = tokenizer([\"Hello. How are you\"], return_tensors=\"pt\")\n\n# huggingface interface\nmodel = HuggingFaceModel(\n    model=model,\n    tokenizer=tokenizer,\n    sample_data=inputs,\n    task_type=HuggingFaceTask.FEATURE_EXTRACTION.value,\n    onnx_args=HuggingFaceOnnxArgs(\n        ort_type=HuggingFaceORTModel.ORT_FEATURE_EXTRACTION.value,\n    ),\n)\n\n# create modelcard\nmodelcard = ModelCard(\n    interface=interface,\n    info=info,\n    to_onnx=True, \n    datacard_uid=datacard.uid,  \n)\n\n# register\nmodel_registry.register_card(card=modelcard)\n</code></pre>"},{"location":"interfaces/model/interfaces/#vowpalwabbitmodel","title":"VowpalWabbitModel","text":"<p>Interface for saving a Vowpal Wabbit model.</p> Model Type <code>Workspace</code> Save Format <code>.model</code> Source <code>VowpalWabbitModel</code> Example <code>Link</code>"},{"location":"interfaces/model/interfaces/#arguments_8","title":"Arguments","text":"<code>model</code>: <code>Workspace</code> Vowpal Wabbit workspace <code>sample_data</code>: <code>str</code> Sample data to be used for type inference. For vowpal wabbit models this should be a string. <code>arguments</code>: <code>Optional[HuggingFaceOnnxArgs]</code> Optional Vowpal Wabbit arguments. This will be inferred automatically from the workspace"},{"location":"interfaces/model/interfaces/#example_8","title":"Example","text":"<pre><code>from opsml import VowpalWabbitModel, CardInfo, ModelCard, CardRegistry\nimport vowpalwabbit\n\ninfo = CardInfo(name=\"model\", repository=\"opsml\", contact=\"user@email.com\")\nmodel_registry = CardRegistry(\"model\")\n\n# Skipping data step\n...\n\nvw = vowpalwabbit.Workspace(\"--cb 4 --quiet\")\n\nfor record in data:\n    vw.learn(learn_example)\nvw.finish()\n\n# vowpal wabbit interface\nmodel = VowpalWabbitModel(model=vw, sample_data=learn_example)\n\n# create modelcard\nmodelcard = ModelCard(interface=interface, info=info, datacard_uid=datacard.uid)\n\n# register\nmodel_registry.register_card(card=modelcard)\n</code></pre>"},{"location":"interfaces/model/interfaces/#subclassing-modelinterface","title":"Subclassing <code>ModelInterface</code>","text":"<p>In the event that the currently supported <code>ModelInterfaces</code> do not meet your needs, you can subclass the parent <code>ModelInterface</code> and implement your own interface. However, there are a few requirements:</p> <ul> <li><code>_get_sample_data</code> Helper that returns a single sample of data to be used for inference. This is used to validate the model during saving and loading.</li> <li><code>get_sample_prediction</code> Will use the model to make a prediction on the sample data and returns a <code>SamplePrediction</code> class.</li> <li><code>model_class</code> Returns a string value with your model class name.</li> <li><code>save_model</code> Logic for saving the model from a <code>Path</code> object.</li> <li><code>load_model</code> Logic for loading the model from a <code>Path</code> object.</li> <li><code>model_suffix</code> The suffix to be used when saving the model. This is used to determine the file extension when saving the model.</li> <li><code>save_onnx</code> If you plan to save your model via onnx, you will also need to specify your onnx conversion logic. (Optional, but to_onnx must be set to False if you don't plan on using onnx). Must return a <code>ModelReturn</code> class.</li> </ul> <p>These requirements are necessary for <code>Opsml</code> to properly save and load your model, as these are called during either saving or loading via the <code>ModelCard</code>.</p>"},{"location":"interfaces/model/interfaces/#example_9","title":"Example","text":"<pre><code>from opsml import ModelInterface, CardInfo, DataCard, CardRegistry\n\ninfo = CardInfo(name=\"model\", repository=\"opsml\", contact=\"opsml_user\")\nregistry = CardRegistry(\"model\")\n\n# ModelInterface is a pydantic BaseModel\nclass MyModelInterface(ModelInterface):\n\n    model: ModelType\n\n    @property\n    def model_class(self) -&gt; str:\n        return \"MyModel\"\n\n    def save_model(self, path: Path) -&gt; None:\n        # save logic here\n\n    def load_model(self, path: Path, **kwargs: Any) -&gt; None:\n        # load logic here\n\n    @classmethod\n    def _get_sample_data(cls, sample_data: Any) -&gt; Any:\n        # sample data logic here\n        # return 1 record of sample_data\n\n    def get_sample_prediction(self) -&gt; SamplePrediction:\n        # prediction logic here\n        # return SamplePrediction class\n\n    @property\n    def model_suffix(self) -&gt; str:\n        \"\"\"Returns suffix for storage\"\"\"\n        return \".my_model\"\n\n    # optional\n    def save_onnx(self, path: Path) -&gt; ModelReturn:\n        # onnx save logic here\n\n    # optional\n    def load_onnx_model(self, path: Path) -&gt; None:\n        # onnx load logic here\n\ninterface = MyModelInterface(model={{my_model}})\n\n# Create and register datacard\nmodelcard = ModelCard(interface=interface, info=info)\nregistry.register_card(card=modelcard)\n\n# Now you can load your model via the registry\n# you will need to supply the interface subclass\nmodelcard = registry.load_card(uid=modelcard.uid, interface=MyModelInterface)\n</code></pre>"},{"location":"interfaces/model/interfaces/#final-note","title":"Final Note","text":"<p>It is up to you to make sure your subclass works as expected and is compatible with the <code>ModelCard</code> class. If you feel your subclass is useful to others, please consider contributing it to the <code>Opsml</code> library. In addition, if using a custom subclass, others will not be able to load/use your <code>card</code> unless they have access to the custom subclass.</p>"},{"location":"interfaces/model/onnx/","title":"Onnx Args","text":"<p>Some model interfaces require extra arguments when converting to onnx. These arguments can be passed to the <code>onnx_args</code> argument of the <code>ModelInterface</code> class.</p>"},{"location":"interfaces/model/onnx/#torchonnxargs","title":"TorchOnnxArgs","text":"<p><code>TorchOnnxArgs</code> is the optional onnx args class for <code>TorchModel</code> and <code>LightningModel</code>. When not supplied, a default <code>TorchOnnxArgs</code> class is used. For more information on the arguments, please refer to the torch.onnx documentation.</p>"},{"location":"interfaces/model/onnx/#opsml.TorchOnnxArgs","title":"<code>opsml.TorchOnnxArgs</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Optional arguments to pass to torch when converting to onnx</p> <p>Parameters:</p> Name Type Description Default <code>input_names</code> <p>Optional list containing input names for model inputs.</p> required <code>output_names</code> <p>Optional list containing output names for model outputs.</p> required <code>dynamic_axes</code> <p>Optional PyTorch attribute that defines dynamic axes</p> required <code>constant_folding</code> <p>Whether to use constant folding optimization. Default is True</p> required Source code in <code>opsml/types/model.py</code> <pre><code>class TorchOnnxArgs(BaseModel):\n    \"\"\"Optional arguments to pass to torch when converting to onnx\n\n    Args:\n        input_names:\n            Optional list containing input names for model inputs.\n        output_names:\n            Optional list containing output names for model outputs.\n        dynamic_axes:\n            Optional PyTorch attribute that defines dynamic axes\n        constant_folding:\n            Whether to use constant folding optimization. Default is True\n    \"\"\"\n\n    input_names: List[str]\n    output_names: List[str]\n    dynamic_axes: Optional[Dict[str, Dict[int, str]]] = None\n    do_constant_folding: bool = True\n    export_params: bool = True\n    verbose: bool = False\n    options: Optional[Dict[str, Any]] = None\n</code></pre>"},{"location":"interfaces/model/onnx/#huggingfaceonnxargs","title":"HuggingFaceOnnxArgs","text":"<p><code>HuggingFaceOnnxArgs</code> is the REQUIRED onnx args class for <code>HuggingFaceModel</code> when converting a model to onnx format. <code>HuggingFaceOnnxArgs</code> is a custom object that allows you to specify how <code>optimum</code> should convert your model to onnx. </p>"},{"location":"interfaces/model/onnx/#required-arguments","title":"Required Arguments","text":"<code>ort_type</code> Optimum onnx class name as defined in <code>HuggingFaceORTModel</code> <code>provider</code> Onnx runtime provider to user. Defaults to <code>CPUExecutionProvider</code> <code>quantize</code> Whether or not to quantize the model. Defaults to <code>False</code>. If <code>True</code> a <code>quantization</code> config is required. <code>config</code> Optional config for conversion. Can be one of <code>AutoQuantizationConfig</code>, <code>ORTConfig</code> or <code>QuantizationConfig</code>. See <code>optimum</code> for more details."},{"location":"interfaces/model/onnx/#opsml.HuggingFaceOnnxArgs","title":"<code>opsml.HuggingFaceOnnxArgs</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Optional Args to use with a huggingface model</p> <p>Parameters:</p> Name Type Description Default <code>ort_type</code> <p>Optimum onnx class name</p> required <code>provider</code> <p>Onnx runtime provider to use</p> required <code>config</code> <p>Optional optimum config to use</p> required Source code in <code>opsml/types/model.py</code> <pre><code>class HuggingFaceOnnxArgs(BaseModel):\n    \"\"\"Optional Args to use with a huggingface model\n\n    Args:\n        ort_type:\n            Optimum onnx class name\n        provider:\n            Onnx runtime provider to use\n        config:\n            Optional optimum config to use\n    \"\"\"\n\n    ort_type: str\n    provider: str = \"CPUExecutionProvider\"\n    quantize: bool = False\n    config: Optional[Any] = None\n\n    @field_validator(\"ort_type\", mode=\"before\")\n    @classmethod\n    def check_ort_type(cls, ort_type: str) -&gt; str:\n        \"\"\"Validates onnx runtime model type\"\"\"\n        if ort_type not in list(HuggingFaceORTModel):\n            raise ValueError(f\"Optimum model type {ort_type} is not supported\")\n        return ort_type\n\n    @field_validator(\"config\", mode=\"before\")\n    @classmethod\n    def check_config(cls, config: Optional[Any] = None) -&gt; Optional[Any]:\n        \"\"\"Check that optimum config is valid\"\"\"\n\n        if config is None:\n            return config\n\n        from optimum.onnxruntime import (\n            AutoQuantizationConfig,\n            ORTConfig,\n            QuantizationConfig,\n        )\n\n        assert isinstance(\n            config,\n            (\n                AutoQuantizationConfig,\n                ORTConfig,\n                QuantizationConfig,\n            ),\n        ), \"config must be a valid optimum config\"\n\n        return config\n</code></pre>"},{"location":"interfaces/model/onnx/#opsml.HuggingFaceOnnxArgs.check_config","title":"<code>check_config(config=None)</code>  <code>classmethod</code>","text":"<p>Check that optimum config is valid</p> Source code in <code>opsml/types/model.py</code> <pre><code>@field_validator(\"config\", mode=\"before\")\n@classmethod\ndef check_config(cls, config: Optional[Any] = None) -&gt; Optional[Any]:\n    \"\"\"Check that optimum config is valid\"\"\"\n\n    if config is None:\n        return config\n\n    from optimum.onnxruntime import (\n        AutoQuantizationConfig,\n        ORTConfig,\n        QuantizationConfig,\n    )\n\n    assert isinstance(\n        config,\n        (\n            AutoQuantizationConfig,\n            ORTConfig,\n            QuantizationConfig,\n        ),\n    ), \"config must be a valid optimum config\"\n\n    return config\n</code></pre>"},{"location":"interfaces/model/onnx/#opsml.HuggingFaceOnnxArgs.check_ort_type","title":"<code>check_ort_type(ort_type)</code>  <code>classmethod</code>","text":"<p>Validates onnx runtime model type</p> Source code in <code>opsml/types/model.py</code> <pre><code>@field_validator(\"ort_type\", mode=\"before\")\n@classmethod\ndef check_ort_type(cls, ort_type: str) -&gt; str:\n    \"\"\"Validates onnx runtime model type\"\"\"\n    if ort_type not in list(HuggingFaceORTModel):\n        raise ValueError(f\"Optimum model type {ort_type} is not supported\")\n    return ort_type\n</code></pre>"}]}